from dataclasses import dataclass
from typing import DefaultDict

default_stop = DefaultDict(list)
@dataclass
class llmConfig:
   stream: bool = True                    # Нужно ли использовать потоковую передачу данных.
   keep_alive: bool = True                # Нужно ли поддерживать активное соединение после выполнения запроса. 
   num_keep: int = 5                      # Количество предложений или вариантов ответа, которые модель должна сохранить перед выбором одного из них.
   seed: int = 42                         # Задает начальное состояние для генератора случайных чисел, что позволяет получать повторяемые результаты при одинаковых условиях.
   num_predict: int = 100                 # Количество предсказываемых токенов при генерации текста.
   top_k: int = 20                        # Параметр, используемый для ограничения выбора токенов только на основе топ-K наиболее вероятных токенов.
   top_p: float = 0.9                     # Параметр, используемый для ограничения выбора токенов только на основе токенов с накопленной вероятностью до достижения заданного порога.
   tfs_z: float = 0.5                     # Настройка, связанная с температурой в теории мягкого максимума.
   typical_p: float = 0.7                 # Типичная вероятность токена.
   repeat_last_n: int = 33                # Количество последних предсказанных токенов, которые модель будет учитывать для обнаружения повторяющихся фрагментов
   temperature: float = 0.8               # Параметр, управляющий разнообразием генерируемого текста. Более высокая температура приводит к более случайному выбору токенов.
   repeat_penalty: float = 1.2            # Штраф за повторение фрагментов текста.
   presence_penalty: float = 1.5          # Штраф за повторение уже существующих ответов.
   frequency_penalty: float = 1.0         # Штраф за повторение ответов, основанный на частоте использования.
   mirostat: int = 1                      # Включение механизма miRoStaT для управления температурой и разнообразием генерации.
   mirostat_tau: float = 0.8              # Параметр miRoStaT, связанный с температурой.
   mirostat_eta: float = 0.6              # Параметр miRoStaT, связанный с разнообразием генерации.
   penalize_newline: bool = True          # Включение штрафа за генерацию символа новой строки.
   #stop: DefaultDict[str, list] = ["\n", "user:"]       # Список строк, при обнаружении которых модель должна завершить генерацию текста.
   numa: bool = False                     # Включение NUMA-оптимизации для работы с несколькими узлами памяти.
   num_ctx: int = 1024                    # Размер контекста, который модель может использовать.
   num_batch: int = 2                     # Количество запросов, обрабатываемых моделью одновременно.
   num_gpu: int = 1                       # Количество GPU, используемых моделью.
   main_gpu: int = 0                      # Основной GPU, используемый моделью.
   low_vram: bool = False                 # Оптимизация для работы на GPU с ограниченным объемом памяти.
   f16_kv: bool = True                    # Использование половинной точности для некоторых операций с ключами.
   vocab_only: bool = False               # Использование только словаря для запросов.
   use_mmap: bool = True                  # Использование mmap для доступа к данным.
   use_mlock: bool = False                # Использование mlock для защиты памяти от страницирования.
   num_thread: int = 8                    # Количество потоков для обработки запросов.