{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "import nltk.data\n",
    "import os\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from pdfrw import PdfReader\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_PAR_LEN = 200\n",
    "MIN_SENTENCE_LEN = 100\n",
    "PDFS_DIR = '/home/dzigen/Desktop/ITMO/DialogueSystem/DialogueSearchSystem/data/sci_pdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdfpages(pdf_path):\n",
    "    text = []\n",
    "    with pymupdf.open(pdf_path) as doc:\n",
    "        title = doc.metadata['title']\n",
    "        for page in doc:\n",
    "            for tab in page.find_tables():\n",
    "                # process the content of table 'tab'\n",
    "                page.add_redact_annot(tab.bbox)  # wrap table in a redaction annotation\n",
    "\n",
    "            for img in page.get_images():\n",
    "                # process the content of table 'tab'\n",
    "                page.delete_image(img[0]) # wrap table in a redaction annotation\n",
    "\n",
    "            page.apply_redactions()  # erase all table text\n",
    "            text.append(page.get_text(\"blocks\", sort=True))\n",
    "\n",
    "    return text, title\n",
    "\n",
    "def filter_pdfblocks(pages):\n",
    "    filtered_pages = []\n",
    "    for page in pages:\n",
    "        filtered_block = []\n",
    "        flag = False\n",
    "        for block in page:\n",
    "            txt = block[4]\n",
    "\n",
    "            if len(txt) >= MIN_PAR_LEN:\n",
    "                txt = txt.replace('-\\n','').replace('\\n',' ')\n",
    "\n",
    "                if txt.startswith(\"Figure\") or txt.startswith(\"Table\"):\n",
    "                    continue\n",
    "\n",
    "                sentences = list(filter(lambda x: len(x) >= MIN_SENTENCE_LEN, tokenizer.tokenize(txt)))\n",
    "                filtered_block.append(sentences)\n",
    "            \n",
    "            else:\n",
    "                if len(re.findall('references', txt.lower())) > 0:\n",
    "                    #print(\"find references!\")\n",
    "                    flag = True\n",
    "                    break\n",
    "\n",
    "        filtered_pages.append(filtered_block)\n",
    "\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    return filtered_pages\n",
    "\n",
    "def prepare_sci_corpus(pdfs_dir):\n",
    "    pdfs = os.listdir(pdfs_dir)\n",
    "    #print(pdfs)\n",
    "\n",
    "    tmp_data = []\n",
    "    for id, file in tqdm(enumerate(pdfs)):\n",
    "        #print(file) \n",
    "        path = f\"{pdfs_dir}/{file}\"\n",
    "\n",
    "        print(\"extracting text...\")\n",
    "        gc.collect()\n",
    "        pages_info, title = get_pdfpages(path)\n",
    "        print(title)\n",
    "        gc.collect()\n",
    "        print(\"filtering text...\")\n",
    "        filtered_info = filter_pdfblocks(pages_info)\n",
    "\n",
    "        blocks = reduce(lambda acc, x: acc + x, filtered_info, [])\n",
    "        paragraphs = reduce(lambda acc, x: acc + x, blocks, [])\n",
    "\n",
    "        tmp_data += [(title, sent, {'path': path, 'id': id}) for sent in paragraphs]\n",
    "\n",
    "    df = pd.DataFrame(tmp_data, columns=['title','text', 'metadata'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_sci_corpus(PDFS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generative models for open domain question ans...</td>\n",
       "      <td>{'title': '', 'path': '/home/dzigen/Desktop/IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While promising, this approach requires to use...</td>\n",
       "      <td>{'title': '', 'path': '/home/dzigen/Desktop/IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this paper, we investigate how much these m...</td>\n",
       "      <td>{'title': '', 'path': '/home/dzigen/Desktop/IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interestingly, we observe that the performance...</td>\n",
       "      <td>{'title': '', 'path': '/home/dzigen/Desktop/IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is evidence that sequence-to-sequence mod...</td>\n",
       "      <td>{'title': '', 'path': '/home/dzigen/Desktop/IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>Expansion allows to enrich documents, either b...</td>\n",
       "      <td>{'title': 'SPLADE: Sparse Lexical and Expansio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>Recently, dense retrieval based on BERT has de...</td>\n",
       "      <td>{'title': 'SPLADE: Sparse Lexical and Expansio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>Our approach relies on in-batch negatives, log...</td>\n",
       "      <td>{'title': 'SPLADE: Sparse Lexical and Expansio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>SPLADE is an appealing candidate for initial r...</td>\n",
       "      <td>{'title': 'SPLADE: Sparse Lexical and Expansio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>In reason of its simplicity, SPLADE is a solid...</td>\n",
       "      <td>{'title': 'SPLADE: Sparse Lexical and Expansio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4268 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     Generative models for open domain question ans...   \n",
       "1     While promising, this approach requires to use...   \n",
       "2     In this paper, we investigate how much these m...   \n",
       "3     Interestingly, we observe that the performance...   \n",
       "4     This is evidence that sequence-to-sequence mod...   \n",
       "...                                                 ...   \n",
       "4263  Expansion allows to enrich documents, either b...   \n",
       "4264  Recently, dense retrieval based on BERT has de...   \n",
       "4265  Our approach relies on in-batch negatives, log...   \n",
       "4266  SPLADE is an appealing candidate for initial r...   \n",
       "4267  In reason of its simplicity, SPLADE is a solid...   \n",
       "\n",
       "                                               metadata  \n",
       "0     {'title': '', 'path': '/home/dzigen/Desktop/IT...  \n",
       "1     {'title': '', 'path': '/home/dzigen/Desktop/IT...  \n",
       "2     {'title': '', 'path': '/home/dzigen/Desktop/IT...  \n",
       "3     {'title': '', 'path': '/home/dzigen/Desktop/IT...  \n",
       "4     {'title': '', 'path': '/home/dzigen/Desktop/IT...  \n",
       "...                                                 ...  \n",
       "4263  {'title': 'SPLADE: Sparse Lexical and Expansio...  \n",
       "4264  {'title': 'SPLADE: Sparse Lexical and Expansio...  \n",
       "4265  {'title': 'SPLADE: Sparse Lexical and Expansio...  \n",
       "4266  {'title': 'SPLADE: Sparse Lexical and Expansio...  \n",
       "4267  {'title': 'SPLADE: Sparse Lexical and Expansio...  \n",
       "\n",
       "[4268 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
