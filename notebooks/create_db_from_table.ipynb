{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полезные материалы:\n",
    "# https://api.python.langchain.com/en/latest/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html\n",
    "# https://medium.com/@milana.shxanukova15/embeddings-normalisation-b279e32ca958\n",
    "# https://api.python.langchain.com/en/latest/vectorstores/langchain_community.vectorstores.faiss.FAISS.html\n",
    "# https://medium.com/@pankaj_pandey/faiss-efficient-similarity-search-and-clustering-of-dense-vectors-dace1df1e235\n",
    "# https://sbert.net/docs/package_reference/sentence_transformer/SentenceTransformer.html#sentence_transformers.SentenceTransformer.encode\n",
    "# https://github.com/facebookresearch/faiss/wiki/MetricType-and-distances\n",
    "# https://github.com/langchain-ai/langchain/discussions/16224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/aisummer/mikhail_workspace/nlp-service\")\n",
    "\n",
    "from src.DocumentsParser.utils import INFO_FILE, TABLES_DIR_TABLE_NAME, DBS_DIR_DENSE_VECTORDB_NAME, DBS_DIR_SPARSE_VECTORDB_NAME\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "import pickle\n",
    "import ast\n",
    "\n",
    "# Есть 2 варианта формирования базы данных:\n",
    "# 1. C использованием нормализации векторов. \n",
    "#    Тогда 'normalize_embeddings' = True и 'distance_strategy' = DistanceStrategy.MAX_INNER_PRODUCT\n",
    "# 2. Без нормализации векторов.\n",
    "#    Тогда 'normalize_embeddings' = False и 'distance_strategy' = DistanceStrategy.EUCLIDEAN_DISTANCE\n",
    "\n",
    "# !!! BELOW TO CHANGE !!! \n",
    "LOAD_DIR = \"../data/infsec_gosts/tables/v1/\"\n",
    "DATASET_PATH = f'{LOAD_DIR}/{TABLES_DIR_TABLE_NAME}'\n",
    "SAVE_DIR = '../data/infsec_gosts/dbs/v2/'\n",
    "DENSE_DB_SAVE_PATH = f'{SAVE_DIR}/{DBS_DIR_DENSE_VECTORDB_NAME}'\n",
    "SPARSE_DB_SAVE_PATH = f'{SAVE_DIR}/{DBS_DIR_SPARSE_VECTORDB_NAME}'\n",
    "DB_LOG_PATH = f'{SAVE_DIR}/{INFO_FILE}'\n",
    "\n",
    "EMBEDDING_MODEL_PATH = '../models/intfloat/multilingual-e5-small'\n",
    "MODEL_KWARGS = {'device': 'cuda'}\n",
    "ENCODE_KWARGS = {'normalize_embeddings': True, 'prompt': 'passage: '}\n",
    "FAISS_KWARGS = {'distance_strategy': DistanceStrategy.MAX_INNER_PRODUCT}\n",
    "# !!! ABOVE TO CHANGE !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aisummer/.nlp_env/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No sentence-transformers model found with name ../models/intfloat/multilingual-e5-small. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "# Loading Embedder-model\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_PATH,\n",
    "    model_kwargs=MODEL_KWARGS,\n",
    "    encode_kwargs=ENCODE_KWARGS \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH, sep=';')\n",
    "df['metadata'] = df['metadata'].map(lambda v: ast.literal_eval(v)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dense DataBase\n",
    "\n",
    "faiss = FAISS.from_texts(df['chunks'].to_list(), embeddings, df['metadata'].to_list(), **FAISS_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sparse DataBase\n",
    "\n",
    "retriever_BM25 = BM25Retriever.from_texts(df['chunks'].to_list(), df['metadata'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Logs\n",
    "with open(DB_LOG_PATH, 'w') as fd:\n",
    "    fd.write(json.dumps({\n",
    "        \"load_dir\": LOAD_DIR,\n",
    "        \"save_dir\": SAVE_DIR, \"model_name\": EMBEDDING_MODEL_PATH,\n",
    "        \"encode_kwargs\": ENCODE_KWARGS, \"faiss_kwargs\": FAISS_KWARGS}, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dense DataBase\n",
    "faiss.save_local(DENSE_DB_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving sparse DataBase\n",
    "filehandler = open(SPARSE_DB_SAVE_PATH,\"wb\")\n",
    "pickle.dump(retriever_BM25,filehandler)\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp_env",
   "language": "python",
   "name": ".nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
