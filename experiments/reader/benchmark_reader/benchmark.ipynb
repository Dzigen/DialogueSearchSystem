{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/aisummer/mikhail_workspace/nlp_service\")\n",
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from src.DocumentsParser.utils import DBS_DIR_DENSE_VECTORDB_NAME, DBS_DIR_SPARSE_VECTORDB_NAME\n",
    "from src.evaluation_metrics import ReaderMetrics\n",
    "from src.DocumentsSummarizer.Summarizer import SummarizerModule\n",
    "from src.DocumentsSummarizer.utils import SummarizerConfig\n",
    "from src.utils import DialogueState\n",
    "from src.logger import Logger\n",
    "from langchain_core.documents.base import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Создаём объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /home/aisummer/nlp_models/model_llm/blobs/sha256-6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4437.80 MiB\n",
      ".......................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   258.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '2', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(False)\n",
    "log = logger.get_logger(__name__)\n",
    "\n",
    "config = SummarizerConfig.load('/home/aisummer/ssemenov_workspace/nlp-service/config.yaml')\n",
    "reader = SummarizerModule(config, log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Указываем инфо для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS_INFO = {'sberquad': 'v1', 'squadv2': 'v1'}\n",
    "MODEL_PATH = '/home/aisummer/nlp_models/model_llm/blobs/sha256-6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa'\n",
    "BENCHES_SIZE = 5\n",
    "SAVE_LOGFILE = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/logs/trial1.json'\n",
    "SAVE_CSVFILE_1 = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/csv_log/sberquad_trial1_.csv'\n",
    "SAVE_CSVFILE_2 = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/csv_log/squadv2_trial1.csv'\n",
    "\n",
    "banchmark_paths = {}\n",
    "for name, version in BENCHMARKS_INFO.items():\n",
    "    banchmark_paths[name] = {\n",
    "        'table': f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/tables/{version}/benchmark.csv\",\n",
    "        'dense_db': f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/dbs/{version}/{DBS_DIR_DENSE_VECTORDB_NAME}\",\n",
    "        'sparse_db':  f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/dbs/{version}/{DBS_DIR_SPARSE_VECTORDB_NAME}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteor...\n",
      "Loading ExactMatch\n"
     ]
    }
   ],
   "source": [
    "# загрузить benchmark-датасет\n",
    "benchmarks_df = {}\n",
    "for name, bench_path in banchmark_paths.items():\n",
    "    benchmarks_df[name] = pd.read_csv(banchmark_paths[name]['table'], sep=';')\n",
    "\n",
    "# инициализировать класс с метриками\n",
    "base_dir = '/home/aisummer/ssemenov_workspace/nlp-service'\n",
    "metrics = ReaderMetrics(base_dir)\n",
    "\n",
    "# logging\n",
    "logger = Logger(False)\n",
    "log = logger.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_ids</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>чем представлены органические остатки?</td>\n",
       "      <td>известковыми выделениями сине-зелёных водорослей</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>что найдено в кремнистых сланцах железорудной ...</td>\n",
       "      <td>нитевидные водоросли, грибные нити</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>что встречается в протерозойских отложениях?</td>\n",
       "      <td>органические остатки</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что относится к числу древнейших растительных ...</td>\n",
       "      <td>скопления графито-углистого вещества</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как образовалось графито-углистое вещество?</td>\n",
       "      <td>в результате разложения Corycium enigmaticum</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>Где используется классическая трёхуровневая си...</td>\n",
       "      <td>в рубиновом лазере.</td>\n",
       "      <td>[1898313107]</td>\n",
       "      <td>['Классическая трёхуровневая система накачки р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74252</th>\n",
       "      <td>какой инвестиционный банк входил в состав Amer...</td>\n",
       "      <td>Lehman Brothers</td>\n",
       "      <td>[4929086505]</td>\n",
       "      <td>['Первая платёжная карта American Express появ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74253</th>\n",
       "      <td>С каким альбомом был созвучен альбом Дэвида Бо...</td>\n",
       "      <td>Low</td>\n",
       "      <td>[1303094225]</td>\n",
       "      <td>['Следующий альбом Heroes был во многом созвуч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74254</th>\n",
       "      <td>В каком техасском оркестре выступал гитарист Л...</td>\n",
       "      <td>Light Crust Doughboys</td>\n",
       "      <td>[934655466]</td>\n",
       "      <td>['Одним из тех, на кого игра Данна произвела н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74255</th>\n",
       "      <td>Когда произошло зарождение банковского дела на...</td>\n",
       "      <td>в III веке до нашей эры</td>\n",
       "      <td>[1466134820]</td>\n",
       "      <td>['Банковское дело на территории Италии зародил...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74256 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0                 чем представлены органические остатки?   \n",
       "1      что найдено в кремнистых сланцах железорудной ...   \n",
       "2           что встречается в протерозойских отложениях?   \n",
       "3      что относится к числу древнейших растительных ...   \n",
       "4            как образовалось графито-углистое вещество?   \n",
       "...                                                  ...   \n",
       "74251  Где используется классическая трёхуровневая си...   \n",
       "74252  какой инвестиционный банк входил в состав Amer...   \n",
       "74253  С каким альбомом был созвучен альбом Дэвида Бо...   \n",
       "74254  В каком техасском оркестре выступал гитарист Л...   \n",
       "74255  Когда произошло зарождение банковского дела на...   \n",
       "\n",
       "                                                 answer     chunk_ids  \\\n",
       "0      известковыми выделениями сине-зелёных водорослей  [4974587056]   \n",
       "1                    нитевидные водоросли, грибные нити  [4974587056]   \n",
       "2                                  органические остатки  [4974587056]   \n",
       "3                  скопления графито-углистого вещества  [4974587056]   \n",
       "4          в результате разложения Corycium enigmaticum  [4974587056]   \n",
       "...                                                 ...           ...   \n",
       "74251                               в рубиновом лазере.  [1898313107]   \n",
       "74252                                   Lehman Brothers  [4929086505]   \n",
       "74253                                               Low  [1303094225]   \n",
       "74254                             Light Crust Doughboys   [934655466]   \n",
       "74255                           в III веке до нашей эры  [1466134820]   \n",
       "\n",
       "                                                contexts  \n",
       "0      ['В протерозойских отложениях органические ост...  \n",
       "1      ['В протерозойских отложениях органические ост...  \n",
       "2      ['В протерозойских отложениях органические ост...  \n",
       "3      ['В протерозойских отложениях органические ост...  \n",
       "4      ['В протерозойских отложениях органические ост...  \n",
       "...                                                  ...  \n",
       "74251  ['Классическая трёхуровневая система накачки р...  \n",
       "74252  ['Первая платёжная карта American Express появ...  \n",
       "74253  ['Следующий альбом Heroes был во многом созвуч...  \n",
       "74254  ['Одним из тех, на кого игра Данна произвела н...  \n",
       "74255  ['Банковское дело на территории Италии зародил...  \n",
       "\n",
       "[74256 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df['sberquad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141964</th>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141965</th>\n",
       "      <td>What does not have a metric counterpart?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141966</th>\n",
       "      <td>What is the force exerted by standard gravity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141967</th>\n",
       "      <td>What force leads to a commonly used unit of mass?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141968</th>\n",
       "      <td>What force is part of the modern SI system?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141969 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0                When did Beyonce start becoming popular?   \n",
       "1       What areas did Beyonce compete in when she was...   \n",
       "2       When did Beyonce leave Destiny's Child and bec...   \n",
       "3           In what city and state did Beyonce  grow up?    \n",
       "4              In which decade did Beyonce become famous?   \n",
       "...                                                   ...   \n",
       "141964  What is the seldom used force unit equal to on...   \n",
       "141965           What does not have a metric counterpart?   \n",
       "141966  What is the force exerted by standard gravity ...   \n",
       "141967  What force leads to a commonly used unit of mass?   \n",
       "141968        What force is part of the modern SI system?   \n",
       "\n",
       "                     answer     chunk_ids  \n",
       "0         in the late 1990s   [621329309]  \n",
       "1       singing and dancing   [621329309]  \n",
       "2                      2003   [621329309]  \n",
       "3            Houston, Texas   [621329309]  \n",
       "4                late 1990s   [621329309]  \n",
       "...                     ...           ...  \n",
       "141964               sthène  [2990931136]  \n",
       "141965                  NaN  [2990931136]  \n",
       "141966                  NaN  [2990931136]  \n",
       "141967                  NaN  [2990931136]  \n",
       "141968                  NaN  [2990931136]  \n",
       "\n",
       "[141969 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df['squadv2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Предскажем ответы по вопросам из датасетов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_ans(df: dict, reader: SummarizerModule, cnt: int, contexts: bool) -> list:\n",
    "    relevant_ans = []\n",
    "    questions = []\n",
    "    context = []\n",
    "    question = df['question']\n",
    "    \n",
    "    for i in tqdm.tqdm(range(cnt)):\n",
    "\n",
    "        questions.append(question[i])\n",
    "\n",
    "        if contexts:\n",
    "            context.append(df['contexts'][i].strip('[]').strip(\"'\"))\n",
    "            contexts = df['contexts'][i].strip('[]').strip(\"'\")\n",
    "        else:\n",
    "            contexts = ''\n",
    "\n",
    "        relevant_chunks = [contexts.strip('[]').strip(\"'\")]\n",
    "        state = DialogueState(\n",
    "            query=question[i],\n",
    "            base_relevant_docs = [Document(page_content=chunk) for chunk in relevant_chunks])\n",
    "\n",
    "        \n",
    "        output = reader.create_answer(state)\n",
    "        result=''\n",
    "        for item in output:\n",
    "            try:\n",
    "                result += item['choices'][0]['delta']['content']\n",
    "            except Exception:\n",
    "                continue\n",
    "        relevant_ans.append(result)\n",
    "    return questions, relevant_ans, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sberquad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      26.11 ms /    48 runs   (    0.54 ms per token,  1838.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4949.05 ms /   275 tokens (   18.00 ms per token,    55.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4927.76 ms /    47 runs   (  104.85 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    9931.73 ms /   322 tokens\n",
      " 20%|██        | 1/5 [00:09<00:39,  9.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      16.66 ms /    30 runs   (    0.56 ms per token,  1801.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.74 ms /    26 tokens (   18.26 ms per token,    54.77 tokens per second)\n",
      "llama_print_timings:        eval time =    3051.70 ms /    29 runs   (  105.23 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    3560.02 ms /    55 tokens\n",
      " 40%|████      | 2/5 [00:13<00:18,  6.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      14.64 ms /    28 runs   (    0.52 ms per token,  1912.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     358.11 ms /    19 tokens (   18.85 ms per token,    53.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2796.00 ms /    27 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    3184.62 ms /    46 tokens\n",
      " 60%|██████    | 3/5 [00:16<00:09,  4.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      15.35 ms /    31 runs   (    0.50 ms per token,  2019.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.25 ms /    17 tokens (   19.19 ms per token,    52.11 tokens per second)\n",
      "llama_print_timings:        eval time =    3018.99 ms /    30 runs   (  100.63 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    3377.42 ms /    47 tokens\n",
      " 80%|████████  | 4/5 [00:20<00:04,  4.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      20.66 ms /    37 runs   (    0.56 ms per token,  1790.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.53 ms /    21 tokens (   18.79 ms per token,    53.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3803.31 ms /    36 runs   (  105.65 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    4238.53 ms /    57 tokens\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.86s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time_sberquad = time.time()\n",
    "\n",
    "cnt = BENCHES_SIZE\n",
    "questions_sberquad, predicted_sberquad, context_sberquad = get_relevant_ans(benchmarks_df['sberquad'], reader, cnt, True)\n",
    "targets_sberquad = benchmarks_df['sberquad']['answer'].to_list()[:cnt]\n",
    "\n",
    "time_execute_sberquad = time.time() - start_time_sberquad\n",
    "\n",
    "q_and_a_sberquad = {\n",
    "    'question': questions_sberquad,\n",
    "    'predicted_answer': predicted_sberquad,\n",
    "    'target': targets_sberquad,\n",
    "    'context': context_sberquad\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>чем представлены органические остатки?</td>\n",
       "      <td>Органические остатки в протерозойских отложени...</td>\n",
       "      <td>известковыми выделениями сине-зелёных водорослей</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>что найдено в кремнистых сланцах железорудной ...</td>\n",
       "      <td>Нитевидные водоросли, грибные нити и формы, бл...</td>\n",
       "      <td>нитевидные водоросли, грибные нити</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>что встречается в протерозойских отложениях?</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>органические остатки</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что относится к числу древнейших растительных ...</td>\n",
       "      <td>Скопления графито-углистого вещества, образова...</td>\n",
       "      <td>скопления графито-углистого вещества</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как образовалось графито-углистое вещество?</td>\n",
       "      <td>Образовалось в результате разложения Corycium ...</td>\n",
       "      <td>в результате разложения Corycium enigmaticum</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             чем представлены органические остатки?   \n",
       "1  что найдено в кремнистых сланцах железорудной ...   \n",
       "2       что встречается в протерозойских отложениях?   \n",
       "3  что относится к числу древнейших растительных ...   \n",
       "4        как образовалось графито-углистое вещество?   \n",
       "\n",
       "                                    predicted_answer  \\\n",
       "0  Органические остатки в протерозойских отложени...   \n",
       "1  Нитевидные водоросли, грибные нити и формы, бл...   \n",
       "2  В протерозойских отложениях органические остат...   \n",
       "3  Скопления графито-углистого вещества, образова...   \n",
       "4  Образовалось в результате разложения Corycium ...   \n",
       "\n",
       "                                             target  \\\n",
       "0  известковыми выделениями сине-зелёных водорослей   \n",
       "1                нитевидные водоросли, грибные нити   \n",
       "2                              органические остатки   \n",
       "3              скопления графито-углистого вещества   \n",
       "4      в результате разложения Corycium enigmaticum   \n",
       "\n",
       "                                             context  \n",
       "0  В протерозойских отложениях органические остат...  \n",
       "1  В протерозойских отложениях органические остат...  \n",
       "2  В протерозойских отложениях органические остат...  \n",
       "3  В протерозойских отложениях органические остат...  \n",
       "4  В протерозойских отложениях органические остат...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sberquad = pd.DataFrame(q_and_a_sberquad)\n",
    "df_sberquad.to_csv(SAVE_CSVFILE_1)\n",
    "df_sberquad.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squadv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      52.28 ms /   100 runs   (    0.52 ms per token,  1912.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     378.49 ms /    18 tokens (   21.03 ms per token,    47.56 tokens per second)\n",
      "llama_print_timings:        eval time =   10335.83 ms /    99 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   10837.97 ms /   117 tokens\n",
      " 20%|██        | 1/5 [00:10<00:43, 10.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      27.07 ms /    53 runs   (    0.51 ms per token,  1958.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.86 ms /    18 tokens (   18.55 ms per token,    53.91 tokens per second)\n",
      "llama_print_timings:        eval time =    5253.16 ms /    52 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    5642.63 ms /    70 tokens\n",
      " 40%|████      | 2/5 [00:16<00:23,  7.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =      22.11 ms /    42 runs   (    0.53 ms per token,  1899.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.68 ms /    19 tokens (   18.77 ms per token,    53.27 tokens per second)\n",
      "llama_print_timings:        eval time =    4165.40 ms /    41 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    4565.49 ms /    60 tokens\n",
      " 60%|██████    | 3/5 [00:21<00:12,  6.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    11 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.09 ms /    18 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1059.10 ms /    10 runs   (  105.91 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1402.53 ms /    28 tokens\n",
      " 80%|████████  | 4/5 [00:22<00:04,  4.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4949.34 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1903.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.09 ms /    13 tokens (   19.55 ms per token,    51.16 tokens per second)\n",
      "llama_print_timings:        eval time =     648.11 ms /     6 runs   (  108.02 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =     909.54 ms /    19 tokens\n",
      "100%|██████████| 5/5 [00:23<00:00,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time_squadv2 = time.time()\n",
    "\n",
    "questions_squadv2, predicted_squadv2, _ = get_relevant_ans(benchmarks_df['squadv2'], reader, cnt, False)\n",
    "targets_squadv2 = benchmarks_df['squadv2']['answer'].to_list()[:cnt]\n",
    "\n",
    "time_execute_squadv2 = time.time() - start_time_squadv2\n",
    "\n",
    "q_and_a_squadv2 = {\n",
    "    'question': questions_squadv2,\n",
    "    'predicted_answer': predicted_squadv2,\n",
    "    'target': targets_squadv2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé started gaining popularity in the earl...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>When Beyoncé was growing up, she competed in t...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé left Destiny's Child in 2000 to pursue...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé grew up in Houston, Texas.</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>The 2000s!</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "\n",
       "                                    predicted_answer               target  \n",
       "0  Beyoncé started gaining popularity in the earl...    in the late 1990s  \n",
       "1  When Beyoncé was growing up, she competed in t...  singing and dancing  \n",
       "2  Beyoncé left Destiny's Child in 2000 to pursue...                 2003  \n",
       "3                 Beyoncé grew up in Houston, Texas.       Houston, Texas  \n",
       "4                                         The 2000s!           late 1990s  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squadv2 = pd.DataFrame(q_and_a_squadv2)\n",
    "df_squadv2.to_csv(SAVE_CSVFILE_2)\n",
    "df_squadv2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sberquad \n",
      "\n",
      "rouge:  0.16\n",
      "bleu:  0.16303\n",
      "meteor:  0.73542\n",
      "exact_match:  0.0 \n",
      "\n",
      "Dataset squadv2 \n",
      "\n",
      "rouge:  0.13246\n",
      "bleu:  0.00432\n",
      "meteor:  0.23382\n",
      "exact_match:  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmarks_score = {}\n",
    "def metric(predicted: list[str], targets: list[str], name:str) -> None:\n",
    "    \n",
    "    length = len(predicted)\n",
    "\n",
    "    print('Dataset', name, '\\n')\n",
    "    rouge_score = metrics.rouge(predicted, targets[:length])\n",
    "    print(\"rouge: \", rouge_score)\n",
    "\n",
    "    bleu_score = metrics.bleu(predicted, targets[:length])\n",
    "    print(\"bleu: \", bleu_score)\n",
    "\n",
    "    meteor = metrics.meteor(predicted, targets[:length])\n",
    "    print(\"meteor: \", meteor)\n",
    "\n",
    "    exact_match = metrics.exact_match(predicted, targets[:length])\n",
    "    print(\"exact_match: \", exact_match, '\\n')\n",
    "\n",
    "    # посчитать метрики \n",
    "    score = {\n",
    "        'rouge': float(rouge_score),\n",
    "        'bleu': float(bleu_score),\n",
    "        'meteor': float(meteor),\n",
    "        'exact_match': float(exact_match)\n",
    "    }\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "score = metric(predicted_sberquad, targets_sberquad,'sberquad')\n",
    "benchmarks_score['sberquad'] = score\n",
    "\n",
    "score = metric(predicted_squadv2, targets_squadv2, 'squadv2')\n",
    "benchmarks_score['squadv2'] = score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# сохранить результат\n",
    "if os.path.exists(SAVE_LOGFILE):\n",
    "    print(\"Файл существует!\")\n",
    "    raise ValueError\n",
    "\n",
    "log_data = {'info': BENCHMARKS_INFO,\n",
    "            'hyperp': {\n",
    "                'model_path': MODEL_PATH, \n",
    "                'tech_params': config.tech_config.__dict__, 'hyper_params': config.strat_config.__dict__,'benchmark_sizes': BENCHES_SIZE},\n",
    "                'scores': benchmarks_score}\n",
    "\n",
    "with open(SAVE_LOGFILE, 'w', encoding='utf-8') as fd:\n",
    "    fd.write(json.dumps(log_data, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
