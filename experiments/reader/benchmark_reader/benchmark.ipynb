{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/aisummer/mikhail_workspace/nlp_service\")\n",
    "import pandas as pd \n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from src.DocumentsParser.utils import DBS_DIR_DENSE_VECTORDB_NAME, DBS_DIR_SPARSE_VECTORDB_NAME\n",
    "from src.evaluation_metrics import ReaderMetrics\n",
    "from src.DocumentsSummarizer.Summarizer import SummarizerModule\n",
    "from src.DocumentsSummarizer.utils import SummarizerConfig\n",
    "from src.utils import DialogueState\n",
    "from src.logger import Logger\n",
    "from langchain_core.documents.base import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Создаём объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /home/aisummer/nlp_models/model_llm/blobs/sha256-6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4437.80 MiB\n",
      ".......................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   560.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '2', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(False)\n",
    "log = logger.get_logger(__name__)\n",
    "\n",
    "config = SummarizerConfig.load('/home/aisummer/ssemenov_workspace/nlp-service/config.yaml')\n",
    "reader = SummarizerModule(config, log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Указываем инфо для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS_INFO = {'sberquad': 'v1', 'squadv2': 'v1'}\n",
    "MODEL_PATH = '/home/aisummer/nlp_models/model_llm/blobs/sha256-6a0746a1ec1aef3e7ec53868f220ff6e389f6f8ef87a01d77c96807de94ca2aa'\n",
    "BENCHES_SIZE = 500\n",
    "SAVE_LOGFILE = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/logs/trial5.json'\n",
    "SAVE_CSVFILE_1 = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/csv_log/sberquad_trial5_.csv'\n",
    "SAVE_CSVFILE_2 = '/home/aisummer/ssemenov_workspace/nlp-service/experiments/reader/benchmark_reader/csv_log/squadv2_trial5.csv'\n",
    "\n",
    "banchmark_paths = {}\n",
    "for name, version in BENCHMARKS_INFO.items():\n",
    "    banchmark_paths[name] = {\n",
    "        'table': f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/tables/{version}/benchmark.csv\",\n",
    "        'dense_db': f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/dbs/{version}/{DBS_DIR_DENSE_VECTORDB_NAME}\",\n",
    "        'sparse_db':  f\"/home/aisummer/ssemenov_workspace/nlp-service/data/{name}/dbs/{version}/{DBS_DIR_SPARSE_VECTORDB_NAME}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteor...\n",
      "Loading ExactMatch\n"
     ]
    }
   ],
   "source": [
    "# загрузить benchmark-датасет\n",
    "benchmarks_df = {}\n",
    "for name, bench_path in banchmark_paths.items():\n",
    "    benchmarks_df[name] = pd.read_csv(banchmark_paths[name]['table'], sep=';')\n",
    "\n",
    "# инициализировать класс с метриками\n",
    "base_dir = '/home/aisummer/ssemenov_workspace/nlp-service'\n",
    "metrics = ReaderMetrics(base_dir)\n",
    "\n",
    "# logging\n",
    "logger = Logger(False)\n",
    "log = logger.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_ids</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>чем представлены органические остатки?</td>\n",
       "      <td>известковыми выделениями сине-зелёных водорослей</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>что найдено в кремнистых сланцах железорудной ...</td>\n",
       "      <td>нитевидные водоросли, грибные нити</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>что встречается в протерозойских отложениях?</td>\n",
       "      <td>органические остатки</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что относится к числу древнейших растительных ...</td>\n",
       "      <td>скопления графито-углистого вещества</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как образовалось графито-углистое вещество?</td>\n",
       "      <td>в результате разложения Corycium enigmaticum</td>\n",
       "      <td>[4974587056]</td>\n",
       "      <td>['В протерозойских отложениях органические ост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>Где используется классическая трёхуровневая си...</td>\n",
       "      <td>в рубиновом лазере.</td>\n",
       "      <td>[1898313107]</td>\n",
       "      <td>['Классическая трёхуровневая система накачки р...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74252</th>\n",
       "      <td>какой инвестиционный банк входил в состав Amer...</td>\n",
       "      <td>Lehman Brothers</td>\n",
       "      <td>[4929086505]</td>\n",
       "      <td>['Первая платёжная карта American Express появ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74253</th>\n",
       "      <td>С каким альбомом был созвучен альбом Дэвида Бо...</td>\n",
       "      <td>Low</td>\n",
       "      <td>[1303094225]</td>\n",
       "      <td>['Следующий альбом Heroes был во многом созвуч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74254</th>\n",
       "      <td>В каком техасском оркестре выступал гитарист Л...</td>\n",
       "      <td>Light Crust Doughboys</td>\n",
       "      <td>[934655466]</td>\n",
       "      <td>['Одним из тех, на кого игра Данна произвела н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74255</th>\n",
       "      <td>Когда произошло зарождение банковского дела на...</td>\n",
       "      <td>в III веке до нашей эры</td>\n",
       "      <td>[1466134820]</td>\n",
       "      <td>['Банковское дело на территории Италии зародил...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74256 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "0                 чем представлены органические остатки?   \n",
       "1      что найдено в кремнистых сланцах железорудной ...   \n",
       "2           что встречается в протерозойских отложениях?   \n",
       "3      что относится к числу древнейших растительных ...   \n",
       "4            как образовалось графито-углистое вещество?   \n",
       "...                                                  ...   \n",
       "74251  Где используется классическая трёхуровневая си...   \n",
       "74252  какой инвестиционный банк входил в состав Amer...   \n",
       "74253  С каким альбомом был созвучен альбом Дэвида Бо...   \n",
       "74254  В каком техасском оркестре выступал гитарист Л...   \n",
       "74255  Когда произошло зарождение банковского дела на...   \n",
       "\n",
       "                                                 answer     chunk_ids  \\\n",
       "0      известковыми выделениями сине-зелёных водорослей  [4974587056]   \n",
       "1                    нитевидные водоросли, грибные нити  [4974587056]   \n",
       "2                                  органические остатки  [4974587056]   \n",
       "3                  скопления графито-углистого вещества  [4974587056]   \n",
       "4          в результате разложения Corycium enigmaticum  [4974587056]   \n",
       "...                                                 ...           ...   \n",
       "74251                               в рубиновом лазере.  [1898313107]   \n",
       "74252                                   Lehman Brothers  [4929086505]   \n",
       "74253                                               Low  [1303094225]   \n",
       "74254                             Light Crust Doughboys   [934655466]   \n",
       "74255                           в III веке до нашей эры  [1466134820]   \n",
       "\n",
       "                                                contexts  \n",
       "0      ['В протерозойских отложениях органические ост...  \n",
       "1      ['В протерозойских отложениях органические ост...  \n",
       "2      ['В протерозойских отложениях органические ост...  \n",
       "3      ['В протерозойских отложениях органические ост...  \n",
       "4      ['В протерозойских отложениях органические ост...  \n",
       "...                                                  ...  \n",
       "74251  ['Классическая трёхуровневая система накачки р...  \n",
       "74252  ['Первая платёжная карта American Express появ...  \n",
       "74253  ['Следующий альбом Heroes был во многом созвуч...  \n",
       "74254  ['Одним из тех, на кого игра Данна произвела н...  \n",
       "74255  ['Банковское дело на территории Италии зародил...  \n",
       "\n",
       "[74256 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df['sberquad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2003</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>[621329309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141964</th>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>sthène</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141965</th>\n",
       "      <td>What does not have a metric counterpart?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141966</th>\n",
       "      <td>What is the force exerted by standard gravity ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141967</th>\n",
       "      <td>What force leads to a commonly used unit of mass?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141968</th>\n",
       "      <td>What force is part of the modern SI system?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2990931136]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141969 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 question  \\\n",
       "0                When did Beyonce start becoming popular?   \n",
       "1       What areas did Beyonce compete in when she was...   \n",
       "2       When did Beyonce leave Destiny's Child and bec...   \n",
       "3           In what city and state did Beyonce  grow up?    \n",
       "4              In which decade did Beyonce become famous?   \n",
       "...                                                   ...   \n",
       "141964  What is the seldom used force unit equal to on...   \n",
       "141965           What does not have a metric counterpart?   \n",
       "141966  What is the force exerted by standard gravity ...   \n",
       "141967  What force leads to a commonly used unit of mass?   \n",
       "141968        What force is part of the modern SI system?   \n",
       "\n",
       "                     answer     chunk_ids  \n",
       "0         in the late 1990s   [621329309]  \n",
       "1       singing and dancing   [621329309]  \n",
       "2                      2003   [621329309]  \n",
       "3            Houston, Texas   [621329309]  \n",
       "4                late 1990s   [621329309]  \n",
       "...                     ...           ...  \n",
       "141964               sthène  [2990931136]  \n",
       "141965                  NaN  [2990931136]  \n",
       "141966                  NaN  [2990931136]  \n",
       "141967                  NaN  [2990931136]  \n",
       "141968                  NaN  [2990931136]  \n",
       "\n",
       "[141969 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df['squadv2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Предскажем ответы по вопросам из датасетов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_ans(df: dict, reader: SummarizerModule, cnt: int, contexts: bool) -> list:\n",
    "    relevant_ans = []\n",
    "    questions = []\n",
    "    context = []\n",
    "    question = df['question']\n",
    "    \n",
    "    for i in tqdm.tqdm(range(cnt)):\n",
    "\n",
    "        questions.append(question[i])\n",
    "\n",
    "        if contexts:\n",
    "            context.append(df['contexts'][i].strip('[]').strip(\"'\"))\n",
    "            contexts = df['contexts'][i].strip('[]').strip(\"'\")\n",
    "        else:\n",
    "            contexts = ''\n",
    "\n",
    "        relevant_chunks = [contexts.strip('[]').strip(\"'\")]\n",
    "        state = DialogueState(\n",
    "            query=question[i],\n",
    "            base_relevant_docs = [Document(page_content=chunk) for chunk in relevant_chunks])\n",
    "\n",
    "        \n",
    "        output = reader.create_answer(state)\n",
    "        result=''\n",
    "        for item in output:\n",
    "            try:\n",
    "                result += item['choices'][0]['delta']['content']\n",
    "            except Exception:\n",
    "                continue\n",
    "        relevant_ans.append(result)\n",
    "    return questions, relevant_ans, context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sberquad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.00 ms /    48 runs   (    0.54 ms per token,  1846.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4946.50 ms /   275 tokens (   17.99 ms per token,    55.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4899.06 ms /    47 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    9902.34 ms /   322 tokens\n",
      "  0%|          | 1/500 [00:09<1:22:23,  9.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    30 runs   (    0.55 ms per token,  1830.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     476.44 ms /    26 tokens (   18.32 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =    3079.28 ms /    29 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    3588.50 ms /    55 tokens\n",
      "  0%|          | 2/500 [00:13<51:23,  6.19s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    28 runs   (    0.52 ms per token,  1924.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     359.23 ms /    19 tokens (   18.91 ms per token,    52.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2886.79 ms /    27 runs   (  106.92 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    3276.67 ms /    46 tokens\n",
      "  1%|          | 3/500 [00:16<40:16,  4.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.13 ms /    31 runs   (    0.49 ms per token,  2048.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.28 ms /    17 tokens (   19.13 ms per token,    52.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3090.85 ms /    30 runs   (  103.03 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    3448.10 ms /    47 tokens\n",
      "  1%|          | 4/500 [00:20<35:35,  4.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.63 ms /    90 runs   (    0.53 ms per token,  1889.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.52 ms /    21 tokens (   18.79 ms per token,    53.23 tokens per second)\n",
      "llama_print_timings:        eval time =    9057.10 ms /    89 runs   (  101.77 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    9555.93 ms /   110 tokens\n",
      "  1%|          | 5/500 [00:29<51:09,  6.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    20 runs   (    0.53 ms per token,  1892.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5003.88 ms /   282 tokens (   17.74 ms per token,    56.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1993.07 ms /    19 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    7018.48 ms /   301 tokens\n",
      "  1%|          | 6/500 [00:36<53:20,  6.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.26 ms /    28 runs   (    0.55 ms per token,  1834.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     500.59 ms /    27 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2777.57 ms /    27 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3309.40 ms /    54 tokens\n",
      "  1%|▏         | 7/500 [00:40<44:43,  5.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    15 runs   (    0.55 ms per token,  1834.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.34 ms /    19 tokens (   18.97 ms per token,    52.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1451.12 ms /    14 runs   (  103.65 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1828.88 ms /    33 tokens\n",
      "  2%|▏         | 8/500 [00:41<35:12,  4.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.09 ms /    39 runs   (    0.52 ms per token,  1940.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     539.92 ms /    29 tokens (   18.62 ms per token,    53.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3931.51 ms /    38 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    4516.03 ms /    67 tokens\n",
      "  2%|▏         | 9/500 [00:46<35:42,  4.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.56 ms /    27 runs   (    0.54 ms per token,  1853.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     441.09 ms /    24 tokens (   18.38 ms per token,    54.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2601.21 ms /    26 runs   (  100.05 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    3072.33 ms /    50 tokens\n",
      "  2%|▏         | 10/500 [00:49<32:23,  3.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     7 runs   (    0.54 ms per token,  1837.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4389.54 ms /   247 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time =     565.68 ms /     6 runs   (   94.28 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =    4962.12 ms /   253 tokens\n",
      "  2%|▏         | 11/500 [00:54<34:49,  4.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.75 ms /    58 runs   (    0.53 ms per token,  1886.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     359.55 ms /    19 tokens (   18.92 ms per token,    52.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5880.52 ms /    57 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    6303.88 ms /    76 tokens\n",
      "  2%|▏         | 12/500 [01:00<39:46,  4.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.06 ms /    29 runs   (    0.48 ms per token,  2062.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     512.86 ms /    28 tokens (   18.32 ms per token,    54.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2900.65 ms /    28 runs   (  103.59 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    3443.80 ms /    56 tokens\n",
      "  3%|▎         | 13/500 [01:04<36:08,  4.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     9 runs   (    0.51 ms per token,  1976.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.08 ms /    24 tokens (   18.34 ms per token,    54.54 tokens per second)\n",
      "llama_print_timings:        eval time =     830.51 ms /     8 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1281.22 ms /    32 tokens\n",
      "  3%|▎         | 14/500 [01:05<28:19,  3.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     8 runs   (    0.53 ms per token,  1888.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     500.29 ms /    27 tokens (   18.53 ms per token,    53.97 tokens per second)\n",
      "llama_print_timings:        eval time =     660.03 ms /     7 runs   (   94.29 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =    1168.73 ms /    34 tokens\n",
      "  3%|▎         | 15/500 [01:06<22:35,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    18 runs   (    0.54 ms per token,  1868.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.64 ms /    14 tokens (   19.12 ms per token,    52.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1781.08 ms /    17 runs   (  104.77 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    2068.34 ms /    31 tokens\n",
      "  3%|▎         | 16/500 [01:08<20:47,  2.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    26 runs   (    0.52 ms per token,  1931.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.85 ms /    22 tokens (   18.49 ms per token,    54.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2476.88 ms /    25 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    2911.80 ms /    47 tokens\n",
      "  3%|▎         | 17/500 [01:11<21:33,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1820.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.71 ms /    24 tokens (   18.32 ms per token,    54.58 tokens per second)\n",
      "llama_print_timings:        eval time =     497.64 ms /     5 runs   (   99.53 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     943.84 ms /    29 tokens\n",
      "  4%|▎         | 18/500 [01:12<17:20,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     8 runs   (    0.52 ms per token,  1932.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.93 ms /    29 tokens (   18.51 ms per token,    54.01 tokens per second)\n",
      "llama_print_timings:        eval time =     662.29 ms /     7 runs   (   94.61 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =    1208.03 ms /    36 tokens\n",
      "  4%|▍         | 19/500 [01:13<15:01,  1.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.59 ms /    40 runs   (    0.51 ms per token,  1942.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.83 ms /    13 tokens (   19.76 ms per token,    50.62 tokens per second)\n",
      "llama_print_timings:        eval time =    3962.27 ms /    39 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    4262.30 ms /    52 tokens\n",
      "  4%|▍         | 20/500 [01:18<20:44,  2.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    17 runs   (    0.51 ms per token,  1943.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.58 ms /    14 tokens (   19.18 ms per token,    52.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1577.38 ms /    16 runs   (   98.59 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =    1863.99 ms /    30 tokens\n",
      "  4%|▍         | 21/500 [01:20<18:57,  2.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1854.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     335.18 ms /    18 tokens (   18.62 ms per token,    53.70 tokens per second)\n",
      "llama_print_timings:        eval time =     490.59 ms /     5 runs   (   98.12 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     832.23 ms /    23 tokens\n",
      "  4%|▍         | 22/500 [01:20<15:14,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.96 ms /    58 runs   (    0.53 ms per token,  1873.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.67 ms /    20 tokens (   18.63 ms per token,    53.67 tokens per second)\n",
      "llama_print_timings:        eval time =    5939.59 ms /    57 runs   (  104.20 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    6380.62 ms /    77 tokens\n",
      "  5%|▍         | 23/500 [01:27<25:52,  3.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.17 ms /    42 runs   (    0.48 ms per token,  2082.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.58 ms /    38 tokens (   17.99 ms per token,    55.59 tokens per second)\n",
      "llama_print_timings:        eval time =    4362.52 ms /    41 runs   (  106.40 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    5090.91 ms /    79 tokens\n",
      "  5%|▍         | 24/500 [01:32<30:11,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.32 ms /    34 runs   (    0.51 ms per token,  1962.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.82 ms /    17 tokens (   19.22 ms per token,    52.02 tokens per second)\n",
      "llama_print_timings:        eval time =    3468.98 ms /    33 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    3831.41 ms /    50 tokens\n",
      "  5%|▌         | 25/500 [01:36<30:12,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    22 runs   (    0.52 ms per token,  1929.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.04 ms /    21 tokens (   18.76 ms per token,    53.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2106.91 ms /    21 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2523.31 ms /    42 tokens\n",
      "  5%|▌         | 26/500 [01:38<27:05,  3.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.85 ms /    21 runs   (    0.52 ms per token,  1935.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.47 ms /    13 tokens (   19.81 ms per token,    50.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2069.38 ms /    20 runs   (  103.47 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2349.87 ms /    33 tokens\n",
      "  5%|▌         | 27/500 [01:41<24:28,  3.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    21 runs   (    0.53 ms per token,  1886.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.85 ms /    15 tokens (   19.52 ms per token,    51.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2080.53 ms /    20 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2396.52 ms /    35 tokens\n",
      "  6%|▌         | 28/500 [01:43<22:45,  2.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.03 ms /    33 runs   (    0.55 ms per token,  1829.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5263.19 ms /   295 tokens (   17.84 ms per token,    56.05 tokens per second)\n",
      "llama_print_timings:        eval time =    3237.92 ms /    32 runs   (  101.18 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    8538.47 ms /   327 tokens\n",
      "  6%|▌         | 29/500 [01:51<36:00,  4.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.13 ms /    48 runs   (    0.50 ms per token,  1988.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.33 ms /    25 tokens (   18.53 ms per token,    53.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4709.36 ms /    47 runs   (  100.20 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    5224.29 ms /    72 tokens\n",
      "  6%|▌         | 30/500 [01:57<37:26,  4.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /     8 runs   (    0.56 ms per token,  1783.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.60 ms /    21 tokens (   18.74 ms per token,    53.35 tokens per second)\n",
      "llama_print_timings:        eval time =     671.39 ms /     7 runs   (   95.91 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    1074.05 ms /    28 tokens\n",
      "  6%|▌         | 31/500 [01:58<28:40,  3.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.56 ms /    42 runs   (    0.54 ms per token,  1861.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.40 ms /    27 tokens (   18.50 ms per token,    54.07 tokens per second)\n",
      "llama_print_timings:        eval time =    4160.07 ms /    41 runs   (  101.47 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    4704.87 ms /    68 tokens\n",
      "  6%|▋         | 32/500 [02:02<31:02,  3.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.07 ms /    41 runs   (    0.54 ms per token,  1857.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.15 ms /    15 tokens (   19.48 ms per token,    51.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4071.75 ms /    40 runs   (  101.79 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    4408.62 ms /    55 tokens\n",
      "  7%|▋         | 33/500 [02:07<31:59,  4.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1944.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4074.13 ms /   229 tokens (   17.79 ms per token,    56.21 tokens per second)\n",
      "llama_print_timings:        eval time =     606.93 ms /     6 runs   (  101.16 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    4688.20 ms /   235 tokens\n",
      "  7%|▋         | 34/500 [02:12<33:16,  4.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.46 ms /    35 runs   (    0.53 ms per token,  1896.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.03 ms /    20 tokens (   18.55 ms per token,    53.90 tokens per second)\n",
      "llama_print_timings:        eval time =    3477.82 ms /    34 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    3887.21 ms /    54 tokens\n",
      "  7%|▋         | 35/500 [02:15<32:17,  4.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.07 ms /    28 runs   (    0.54 ms per token,  1857.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.70 ms /    20 tokens (   18.63 ms per token,    53.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2734.00 ms /    27 runs   (  101.26 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3136.89 ms /    47 tokens\n",
      "  7%|▋         | 36/500 [02:19<29:50,  3.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    11 runs   (    0.54 ms per token,  1860.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.48 ms /    21 tokens (   18.83 ms per token,    53.10 tokens per second)\n",
      "llama_print_timings:        eval time =     990.48 ms /    10 runs   (   99.05 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    1397.12 ms /    31 tokens\n",
      "  7%|▋         | 37/500 [02:20<24:05,  3.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    13 runs   (    0.52 ms per token,  1924.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.97 ms /    18 tokens (   18.72 ms per token,    53.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.76 ms /    12 runs   (   95.98 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =    1501.88 ms /    30 tokens\n",
      "  8%|▊         | 38/500 [02:22<20:17,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     3 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3546.67 ms /   200 tokens (   17.73 ms per token,    56.39 tokens per second)\n",
      "llama_print_timings:        eval time =     192.45 ms /     2 runs   (   96.22 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =    3742.31 ms /   202 tokens\n",
      "  8%|▊         | 39/500 [02:25<22:48,  2.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.62 ms /    32 runs   (    0.52 ms per token,  1925.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.96 ms /    31 tokens (   18.32 ms per token,    54.58 tokens per second)\n",
      "llama_print_timings:        eval time =    3131.92 ms /    31 runs   (  101.03 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    3734.15 ms /    62 tokens\n",
      "  8%|▊         | 40/500 [02:29<24:31,  3.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    22 runs   (    0.55 ms per token,  1829.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.04 ms /    14 tokens (   19.22 ms per token,    52.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2099.53 ms /    21 runs   (   99.98 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    2394.38 ms /    35 tokens\n",
      "  8%|▊         | 41/500 [02:31<22:38,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    15 runs   (    0.54 ms per token,  1842.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.47 ms /    20 tokens (   18.52 ms per token,    53.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.44 ms /    14 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    1854.96 ms /    34 tokens\n",
      "  8%|▊         | 42/500 [02:33<20:03,  2.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.06 ms /    35 runs   (    0.52 ms per token,  1937.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7671.58 ms /   425 tokens (   18.05 ms per token,    55.40 tokens per second)\n",
      "llama_print_timings:        eval time =    3581.30 ms /    34 runs   (  105.33 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   11293.80 ms /   459 tokens\n",
      "  9%|▊         | 43/500 [02:45<39:49,  5.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      32.26 ms /    65 runs   (    0.50 ms per token,  2015.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     552.78 ms /    30 tokens (   18.43 ms per token,    54.27 tokens per second)\n",
      "llama_print_timings:        eval time =    6524.23 ms /    64 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    7149.82 ms /    94 tokens\n",
      "  9%|▉         | 44/500 [02:52<44:07,  5.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.96 ms /    37 runs   (    0.49 ms per token,  2059.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.67 ms /    37 tokens (   18.37 ms per token,    54.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3725.60 ms /    36 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    4444.15 ms /    73 tokens\n",
      "  9%|▉         | 45/500 [02:56<40:56,  5.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /     5 runs   (    0.56 ms per token,  1798.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.13 ms /    15 tokens (   19.68 ms per token,    50.83 tokens per second)\n",
      "llama_print_timings:        eval time =     430.85 ms /     4 runs   (  107.71 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =     731.94 ms /    19 tokens\n",
      "  9%|▉         | 46/500 [02:57<30:15,  4.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /     9 runs   (    0.55 ms per token,  1802.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     375.51 ms /    20 tokens (   18.78 ms per token,    53.26 tokens per second)\n",
      "llama_print_timings:        eval time =     857.31 ms /     8 runs   (  107.16 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    1242.76 ms /    28 tokens\n",
      "  9%|▉         | 47/500 [02:58<23:57,  3.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.63 ms /    27 runs   (    0.50 ms per token,  1981.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4365.73 ms /   246 tokens (   17.75 ms per token,    56.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2616.12 ms /    26 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    7010.43 ms /   272 tokens\n",
      " 10%|▉         | 48/500 [03:05<32:35,  4.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.52 ms /    37 runs   (    0.53 ms per token,  1895.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     512.49 ms /    28 tokens (   18.30 ms per token,    54.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3761.39 ms /    36 runs   (  104.48 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    4315.81 ms /    64 tokens\n",
      " 10%|▉         | 49/500 [03:09<32:29,  4.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    27 runs   (    0.51 ms per token,  1976.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     512.73 ms /    28 tokens (   18.31 ms per token,    54.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2615.41 ms /    26 runs   (  100.59 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    3156.21 ms /    54 tokens\n",
      " 10%|█         | 50/500 [03:13<29:48,  3.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     5 runs   (    0.56 ms per token,  1794.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     464.79 ms /    25 tokens (   18.59 ms per token,    53.79 tokens per second)\n",
      "llama_print_timings:        eval time =     372.29 ms /     4 runs   (   93.07 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =     841.64 ms /    29 tokens\n",
      " 10%|█         | 51/500 [03:13<22:42,  3.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.07 ms /    25 runs   (    0.52 ms per token,  1912.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.57 ms /    22 tokens (   18.44 ms per token,    54.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2484.30 ms /    24 runs   (  103.51 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2917.37 ms /    46 tokens\n",
      " 10%|█         | 52/500 [03:16<22:24,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     8 runs   (    0.47 ms per token,  2139.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4516.99 ms /   254 tokens (   17.78 ms per token,    56.23 tokens per second)\n",
      "llama_print_timings:        eval time =     729.23 ms /     7 runs   (  104.18 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    5254.24 ms /   261 tokens\n",
      " 11%|█         | 53/500 [03:22<27:23,  3.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /    58 runs   (    0.52 ms per token,  1914.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.65 ms /    33 tokens (   18.32 ms per token,    54.58 tokens per second)\n",
      "llama_print_timings:        eval time =    5821.43 ms /    57 runs   (  102.13 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    6491.13 ms /    90 tokens\n",
      " 11%|█         | 54/500 [03:28<33:37,  4.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.53 ms /    34 runs   (    0.55 ms per token,  1834.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.42 ms /    27 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3383.07 ms /    33 runs   (  102.52 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    3920.14 ms /    60 tokens\n",
      " 11%|█         | 55/500 [03:32<32:12,  4.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      43.68 ms /    83 runs   (    0.53 ms per token,  1900.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     546.05 ms /    30 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =    8460.44 ms /    82 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    9102.25 ms /   112 tokens\n",
      " 11%|█         | 56/500 [03:41<42:42,  5.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.19 ms /    31 runs   (    0.55 ms per token,  1803.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.51 ms /    15 tokens (   19.43 ms per token,    51.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3143.43 ms /    30 runs   (  104.78 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    3470.83 ms /    45 tokens\n",
      " 11%|█▏        | 57/500 [03:45<37:31,  5.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.87 ms /    43 runs   (    0.53 ms per token,  1880.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3375.89 ms /   190 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =    4210.90 ms /    42 runs   (  100.26 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    7634.13 ms /   232 tokens\n",
      " 12%|█▏        | 58/500 [03:52<43:05,  5.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.43 ms /    38 runs   (    0.51 ms per token,  1955.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     408.41 ms /    22 tokens (   18.56 ms per token,    53.87 tokens per second)\n",
      "llama_print_timings:        eval time =    3786.34 ms /    37 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    4236.83 ms /    59 tokens\n",
      " 12%|█▏        | 59/500 [03:57<39:26,  5.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    20 runs   (    0.55 ms per token,  1833.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     510.07 ms /    28 tokens (   18.22 ms per token,    54.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1926.07 ms /    19 runs   (  101.37 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    2459.08 ms /    47 tokens\n",
      " 12%|█▏        | 60/500 [03:59<32:57,  4.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /     9 runs   (    0.48 ms per token,  2070.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     638.93 ms /    35 tokens (   18.26 ms per token,    54.78 tokens per second)\n",
      "llama_print_timings:        eval time =     840.32 ms /     8 runs   (  105.04 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1488.26 ms /    43 tokens\n",
      " 12%|█▏        | 61/500 [04:00<26:17,  3.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    11 runs   (    0.57 ms per token,  1767.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.08 ms /    19 tokens (   19.11 ms per token,    52.33 tokens per second)\n",
      "llama_print_timings:        eval time =     997.98 ms /    10 runs   (   99.80 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    1373.59 ms /    29 tokens\n",
      " 12%|█▏        | 62/500 [04:02<21:22,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      44.13 ms /    84 runs   (    0.53 ms per token,  1903.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3584.81 ms /   202 tokens (   17.75 ms per token,    56.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8615.08 ms /    83 runs   (  103.80 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   12294.06 ms /   285 tokens\n",
      " 13%|█▎        | 63/500 [04:14<41:47,  5.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.58 ms /    65 runs   (    0.52 ms per token,  1935.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.95 ms /     9 tokens (   20.88 ms per token,    47.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6458.36 ms /    64 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    6718.34 ms /    73 tokens\n",
      " 13%|█▎        | 64/500 [04:21<43:50,  6.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      45.74 ms /    90 runs   (    0.51 ms per token,  1967.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     614.38 ms /    34 tokens (   18.07 ms per token,    55.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9383.36 ms /    89 runs   (  105.43 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =   10098.30 ms /   123 tokens\n",
      " 13%|█▎        | 65/500 [04:31<52:35,  7.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.83 ms /    90 runs   (    0.52 ms per token,  1921.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.32 ms /    20 tokens (   18.57 ms per token,    53.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9293.85 ms /    89 runs   (  104.43 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    9769.15 ms /   109 tokens\n",
      " 13%|█▎        | 66/500 [04:41<57:56,  8.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.04 ms /    90 runs   (    0.52 ms per token,  1913.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.96 ms /    25 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =    9157.26 ms /    89 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    9722.32 ms /   114 tokens\n",
      " 13%|█▎        | 67/500 [04:50<1:01:30,  8.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      34.51 ms /    64 runs   (    0.54 ms per token,  1854.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.69 ms /    13 tokens (   19.82 ms per token,    50.45 tokens per second)\n",
      "llama_print_timings:        eval time =    6590.38 ms /    63 runs   (  104.61 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    6920.55 ms /    76 tokens\n",
      " 14%|█▎        | 68/500 [04:57<57:55,  8.04s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.43 ms /    36 runs   (    0.51 ms per token,  1953.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.69 ms /    24 tokens (   18.36 ms per token,    54.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3670.94 ms /    35 runs   (  104.88 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    4149.73 ms /    59 tokens\n",
      " 14%|█▍        | 69/500 [05:02<49:23,  6.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.47 ms /    41 runs   (    0.52 ms per token,  1909.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.41 ms /    19 tokens (   18.97 ms per token,    52.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4029.84 ms /    40 runs   (  100.75 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    4434.44 ms /    59 tokens\n",
      " 14%|█▍        | 70/500 [05:06<44:02,  6.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    10 runs   (    0.55 ms per token,  1828.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5088.39 ms /   285 tokens (   17.85 ms per token,    56.01 tokens per second)\n",
      "llama_print_timings:        eval time =     891.95 ms /     9 runs   (   99.11 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    5990.23 ms /   294 tokens\n",
      " 14%|█▍        | 71/500 [05:12<43:36,  6.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.53 ms /    37 runs   (    0.53 ms per token,  1894.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.22 ms /    17 tokens (   19.25 ms per token,    51.95 tokens per second)\n",
      "llama_print_timings:        eval time =    3732.06 ms /    36 runs   (  103.67 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    4099.55 ms /    53 tokens\n",
      " 14%|█▍        | 72/500 [05:16<39:14,  5.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.27 ms /    28 runs   (    0.51 ms per token,  1962.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.25 ms /    21 tokens (   18.82 ms per token,    53.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2931.26 ms /    27 runs   (  108.57 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    3355.75 ms /    48 tokens\n",
      " 15%|█▍        | 73/500 [05:19<34:34,  4.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    29 runs   (    0.54 ms per token,  1861.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     407.11 ms /    22 tokens (   18.50 ms per token,    54.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2790.83 ms /    28 runs   (   99.67 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    3229.61 ms /    50 tokens\n",
      " 15%|█▍        | 74/500 [05:23<31:01,  4.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    12 runs   (    0.48 ms per token,  2104.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3578.74 ms /   201 tokens (   17.80 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1075.28 ms /    11 runs   (   97.75 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    4665.40 ms /   212 tokens\n",
      " 15%|█▌        | 75/500 [05:27<31:35,  4.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    30 runs   (    0.50 ms per token,  1984.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     477.38 ms /    26 tokens (   18.36 ms per token,    54.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3210.13 ms /    29 runs   (  110.69 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =    3720.94 ms /    55 tokens\n",
      " 15%|█▌        | 76/500 [05:31<29:57,  4.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    12 runs   (    0.51 ms per token,  1952.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     543.59 ms /    30 tokens (   18.12 ms per token,    55.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.57 ms /    11 runs   (  103.05 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    1690.16 ms /    41 tokens\n",
      " 15%|█▌        | 77/500 [05:33<24:29,  3.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    12 runs   (    0.50 ms per token,  2005.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.50 ms /    31 tokens (   18.40 ms per token,    54.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1071.94 ms /    11 runs   (   97.45 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    1654.49 ms /    42 tokens\n",
      " 16%|█▌        | 78/500 [05:34<20:36,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.92 ms /    24 runs   (    0.50 ms per token,  2012.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.37 ms /    25 tokens (   18.53 ms per token,    53.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2444.32 ms /    23 runs   (  106.27 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    2933.09 ms /    48 tokens\n",
      " 16%|█▌        | 79/500 [05:37<20:34,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     2 runs   (    0.53 ms per token,  1879.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.44 ms /    26 tokens (   18.25 ms per token,    54.80 tokens per second)\n",
      "llama_print_timings:        eval time =      94.01 ms /     1 runs   (   94.01 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =     571.08 ms /    27 tokens\n",
      " 16%|█▌        | 80/500 [05:38<15:34,  2.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.10 ms /    29 runs   (    0.49 ms per token,  2057.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     335.60 ms /    18 tokens (   18.64 ms per token,    53.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2929.91 ms /    28 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    3296.07 ms /    46 tokens\n",
      " 16%|█▌        | 81/500 [05:41<17:47,  2.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      29.43 ms /    58 runs   (    0.51 ms per token,  1970.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     601.25 ms /    33 tokens (   18.22 ms per token,    54.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5972.80 ms /    57 runs   (  104.79 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    6637.37 ms /    90 tokens\n",
      " 16%|█▋        | 82/500 [05:48<26:17,  3.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    14 runs   (    0.53 ms per token,  1884.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4182.17 ms /   236 tokens (   17.72 ms per token,    56.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1314.90 ms /    13 runs   (  101.15 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    5511.21 ms /   249 tokens\n",
      " 17%|█▋        | 83/500 [05:53<29:51,  4.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     6 runs   (    0.55 ms per token,  1820.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     476.28 ms /    26 tokens (   18.32 ms per token,    54.59 tokens per second)\n",
      "llama_print_timings:        eval time =     526.74 ms /     5 runs   (  105.35 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1008.76 ms /    31 tokens\n",
      " 17%|█▋        | 84/500 [05:54<22:57,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.89 ms /    40 runs   (    0.52 ms per token,  1914.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.19 ms /    33 tokens (   18.31 ms per token,    54.62 tokens per second)\n",
      "llama_print_timings:        eval time =    3971.67 ms /    39 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    4618.76 ms /    72 tokens\n",
      " 17%|█▋        | 85/500 [05:59<25:37,  3.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    17 runs   (    0.53 ms per token,  1871.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.65 ms /    17 tokens (   19.21 ms per token,    52.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1672.53 ms /    16 runs   (  104.53 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2017.85 ms /    33 tokens\n",
      " 17%|█▋        | 86/500 [06:01<22:04,  3.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1850.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     510.65 ms /    28 tokens (   18.24 ms per token,    54.83 tokens per second)\n",
      "llama_print_timings:        eval time =     450.19 ms /     5 runs   (   90.04 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =     966.93 ms /    33 tokens\n",
      " 17%|█▋        | 87/500 [06:02<17:25,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    16 runs   (    0.53 ms per token,  1902.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4653.20 ms /   261 tokens (   17.83 ms per token,    56.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1494.09 ms /    15 runs   (   99.61 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    6164.12 ms /   276 tokens\n",
      " 18%|█▊        | 88/500 [06:08<24:52,  3.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1819.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.43 ms /    19 tokens (   19.02 ms per token,    52.57 tokens per second)\n",
      "llama_print_timings:        eval time =     494.94 ms /     5 runs   (   98.99 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     863.08 ms /    24 tokens\n",
      " 18%|█▊        | 89/500 [06:09<19:08,  2.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    10 runs   (    0.55 ms per token,  1806.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.24 ms /    17 tokens (   19.25 ms per token,    51.95 tokens per second)\n",
      "llama_print_timings:        eval time =     868.45 ms /     9 runs   (   96.49 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =    1207.24 ms /    26 tokens\n",
      " 18%|█▊        | 90/500 [06:10<15:50,  2.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.29 ms /    42 runs   (    0.51 ms per token,  1973.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.67 ms /    22 tokens (   18.49 ms per token,    54.10 tokens per second)\n",
      "llama_print_timings:        eval time =    4238.17 ms /    41 runs   (  103.37 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    4691.36 ms /    63 tokens\n",
      " 18%|█▊        | 91/500 [06:15<20:40,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.72 ms /    48 runs   (    0.51 ms per token,  1941.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     892.50 ms /    49 tokens (   18.21 ms per token,    54.90 tokens per second)\n",
      "llama_print_timings:        eval time =    4904.86 ms /    47 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    5850.49 ms /    96 tokens\n",
      " 18%|█▊        | 92/500 [06:21<26:22,  3.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.23 ms /    60 runs   (    0.50 ms per token,  1984.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     537.31 ms /    29 tokens (   18.53 ms per token,    53.97 tokens per second)\n",
      "llama_print_timings:        eval time =    6009.94 ms /    59 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    6614.63 ms /    88 tokens\n",
      " 19%|█▊        | 93/500 [06:27<31:53,  4.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /    36 runs   (    0.51 ms per token,  1959.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     571.65 ms /    31 tokens (   18.44 ms per token,    54.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3658.75 ms /    35 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    4271.08 ms /    66 tokens\n",
      " 19%|█▉        | 94/500 [06:32<30:56,  4.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.38 ms /    34 runs   (    0.51 ms per token,  1956.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.79 ms /    24 tokens (   18.32 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =    3391.23 ms /    33 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    3868.89 ms /    57 tokens\n",
      " 19%|█▉        | 95/500 [06:36<29:26,  4.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.72 ms /    30 runs   (    0.49 ms per token,  2038.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.71 ms /    24 tokens (   18.36 ms per token,    54.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2984.90 ms /    29 runs   (  102.93 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3457.69 ms /    53 tokens\n",
      " 19%|█▉        | 96/500 [06:39<27:33,  4.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.28 ms /    33 runs   (    0.52 ms per token,  1909.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4656.26 ms /   262 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3205.56 ms /    32 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    7897.31 ms /   294 tokens\n",
      " 19%|█▉        | 97/500 [06:47<35:09,  5.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     8 runs   (    0.55 ms per token,  1827.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     430.24 ms /    23 tokens (   18.71 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =     654.84 ms /     7 runs   (   93.55 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =    1093.16 ms /    30 tokens\n",
      " 20%|█▉        | 98/500 [06:48<26:45,  3.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    24 runs   (    0.52 ms per token,  1939.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.13 ms /    20 tokens (   18.61 ms per token,    53.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2479.60 ms /    23 runs   (  107.81 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    2878.02 ms /    43 tokens\n",
      " 20%|█▉        | 99/500 [06:51<24:27,  3.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    14 runs   (    0.55 ms per token,  1830.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     535.39 ms /    29 tokens (   18.46 ms per token,    54.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.15 ms /    13 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1905.39 ms /    42 tokens\n",
      " 20%|██        | 100/500 [06:53<20:53,  3.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    19 runs   (    0.56 ms per token,  1795.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     511.81 ms /    28 tokens (   18.28 ms per token,    54.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1806.60 ms /    18 runs   (  100.37 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    2339.93 ms /    46 tokens\n",
      " 20%|██        | 101/500 [06:55<19:15,  2.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /     8 runs   (    0.56 ms per token,  1799.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5519.47 ms /   310 tokens (   17.80 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =     727.75 ms /     7 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    6256.35 ms /   317 tokens\n",
      " 20%|██        | 102/500 [07:01<25:54,  3.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.36 ms /    21 runs   (    0.54 ms per token,  1848.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.99 ms /    22 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2068.36 ms /    20 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    2499.01 ms /    42 tokens\n",
      " 21%|██        | 103/500 [07:04<23:03,  3.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.99 ms /    45 runs   (    0.49 ms per token,  2046.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     686.79 ms /    38 tokens (   18.07 ms per token,    55.33 tokens per second)\n",
      "llama_print_timings:        eval time =    4480.98 ms /    44 runs   (  101.84 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    5216.27 ms /    82 tokens\n",
      " 21%|██        | 104/500 [07:09<26:26,  4.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    18 runs   (    0.55 ms per token,  1822.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     328.76 ms /    17 tokens (   19.34 ms per token,    51.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1718.48 ms /    17 runs   (  101.09 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    2067.78 ms /    34 tokens\n",
      " 21%|██        | 105/500 [07:11<22:32,  3.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.03 ms /    32 runs   (    0.50 ms per token,  1996.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3573.72 ms /   201 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3132.06 ms /    31 runs   (  101.03 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    6739.70 ms /   232 tokens\n",
      " 21%|██        | 106/500 [07:18<29:01,  4.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.06 ms /    19 runs   (    0.53 ms per token,  1888.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.48 ms /    20 tokens (   18.57 ms per token,    53.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1840.62 ms /    18 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    2232.69 ms /    38 tokens\n",
      " 21%|██▏       | 107/500 [07:20<24:39,  3.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.73 ms /    35 runs   (    0.54 ms per token,  1869.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.86 ms /    19 tokens (   19.15 ms per token,    52.22 tokens per second)\n",
      "llama_print_timings:        eval time =    3451.23 ms /    34 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    3853.80 ms /    53 tokens\n",
      " 22%|██▏       | 108/500 [07:24<24:46,  3.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     7 runs   (    0.56 ms per token,  1775.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     464.31 ms /    25 tokens (   18.57 ms per token,    53.84 tokens per second)\n",
      "llama_print_timings:        eval time =     604.39 ms /     6 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1076.80 ms /    31 tokens\n",
      " 22%|██▏       | 109/500 [07:25<19:24,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.98 ms /    29 runs   (    0.52 ms per token,  1936.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.19 ms /    24 tokens (   18.30 ms per token,    54.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2908.68 ms /    28 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    3379.53 ms /    52 tokens\n",
      " 22%|██▏       | 110/500 [07:28<20:08,  3.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    10 runs   (    0.53 ms per token,  1887.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3615.13 ms /   203 tokens (   17.81 ms per token,    56.15 tokens per second)\n",
      "llama_print_timings:        eval time =     924.73 ms /     9 runs   (  102.75 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    4550.66 ms /   212 tokens\n",
      " 22%|██▏       | 111/500 [07:33<22:55,  3.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    12 runs   (    0.56 ms per token,  1792.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     750.73 ms /    42 tokens (   17.87 ms per token,    55.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.02 ms /    11 runs   (   99.18 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =    1855.53 ms /    53 tokens\n",
      " 22%|██▏       | 112/500 [07:35<19:36,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    10 runs   (    0.55 ms per token,  1825.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     742.46 ms /    41 tokens (   18.11 ms per token,    55.22 tokens per second)\n",
      "llama_print_timings:        eval time =     903.00 ms /     9 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1656.24 ms /    50 tokens\n",
      " 23%|██▎       | 113/500 [07:37<16:54,  2.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    11 runs   (    0.56 ms per token,  1770.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1053.21 ms /    58 tokens (   18.16 ms per token,    55.07 tokens per second)\n",
      "llama_print_timings:        eval time =     988.67 ms /    10 runs   (   98.87 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    2054.36 ms /    68 tokens\n",
      " 23%|██▎       | 114/500 [07:39<15:46,  2.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.71 ms /    41 runs   (    0.53 ms per token,  1888.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1005.57 ms /    55 tokens (   18.28 ms per token,    54.70 tokens per second)\n",
      "llama_print_timings:        eval time =    4159.14 ms /    40 runs   (  103.98 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    5208.18 ms /    95 tokens\n",
      " 23%|██▎       | 115/500 [07:44<21:02,  3.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     5 runs   (    0.52 ms per token,  1911.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3469.91 ms /   195 tokens (   17.79 ms per token,    56.20 tokens per second)\n",
      "llama_print_timings:        eval time =     378.45 ms /     4 runs   (   94.61 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =    3852.90 ms /   199 tokens\n",
      " 23%|██▎       | 116/500 [07:48<22:05,  3.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      44.03 ms /    90 runs   (    0.49 ms per token,  2044.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     543.33 ms /    30 tokens (   18.11 ms per token,    55.21 tokens per second)\n",
      "llama_print_timings:        eval time =    9248.47 ms /    89 runs   (  103.92 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    9890.38 ms /   119 tokens\n",
      " 23%|██▎       | 117/500 [07:58<34:22,  5.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.68 ms /    44 runs   (    0.52 ms per token,  1939.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     438.25 ms /    24 tokens (   18.26 ms per token,    54.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4649.71 ms /    43 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    5136.71 ms /    67 tokens\n",
      " 24%|██▎       | 118/500 [08:03<33:48,  5.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.53 ms /    24 runs   (    0.52 ms per token,  1916.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     498.38 ms /    27 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2408.90 ms /    23 runs   (  104.73 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2932.83 ms /    50 tokens\n",
      " 24%|██▍       | 119/500 [08:06<29:12,  4.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.72 ms /    24 runs   (    0.53 ms per token,  1886.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.03 ms /    21 tokens (   18.76 ms per token,    53.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2561.95 ms /    23 runs   (  111.39 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =    2982.73 ms /    44 tokens\n",
      " 24%|██▍       | 120/500 [08:09<26:03,  4.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     8 runs   (    0.57 ms per token,  1756.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3367.27 ms /   189 tokens (   17.82 ms per token,    56.13 tokens per second)\n",
      "llama_print_timings:        eval time =     687.97 ms /     7 runs   (   98.28 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =    4064.71 ms /   196 tokens\n",
      " 24%|██▍       | 121/500 [08:13<25:54,  4.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.76 ms /    32 runs   (    0.52 ms per token,  1909.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.53 ms /    26 tokens (   18.25 ms per token,    54.79 tokens per second)\n",
      "llama_print_timings:        eval time =    3216.26 ms /    31 runs   (  103.75 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    3725.22 ms /    57 tokens\n",
      " 24%|██▍       | 122/500 [08:16<25:07,  3.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.02 ms /    24 runs   (    0.54 ms per token,  1843.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.04 ms /    16 tokens (   18.88 ms per token,    52.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2421.54 ms /    23 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2749.73 ms /    39 tokens\n",
      " 25%|██▍       | 123/500 [08:19<22:44,  3.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.90 ms /    30 runs   (    0.50 ms per token,  2013.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.87 ms /    19 tokens (   18.99 ms per token,    52.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2917.23 ms /    29 runs   (  100.59 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    3309.41 ms /    48 tokens\n",
      " 25%|██▍       | 124/500 [08:23<22:05,  3.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    32 runs   (    0.54 ms per token,  1835.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.38 ms /    15 tokens (   19.43 ms per token,    51.48 tokens per second)\n",
      "llama_print_timings:        eval time =    3167.80 ms /    31 runs   (  102.19 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    3495.19 ms /    46 tokens\n",
      " 25%|██▌       | 125/500 [08:26<21:59,  3.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    29 runs   (    0.53 ms per token,  1871.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7580.41 ms /   421 tokens (   18.01 ms per token,    55.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2860.68 ms /    28 runs   (  102.17 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =   10473.51 ms /   449 tokens\n",
      " 25%|██▌       | 126/500 [08:36<34:56,  5.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      39.55 ms /    76 runs   (    0.52 ms per token,  1921.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.32 ms /    17 tokens (   19.55 ms per token,    51.16 tokens per second)\n",
      "llama_print_timings:        eval time =    7888.41 ms /    75 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    8305.04 ms /    92 tokens\n",
      " 25%|██▌       | 127/500 [08:45<39:53,  6.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    23 runs   (    0.51 ms per token,  1971.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     551.97 ms /    30 tokens (   18.40 ms per token,    54.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2414.28 ms /    22 runs   (  109.74 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    2991.50 ms /    52 tokens\n",
      " 26%|██▌       | 128/500 [08:48<33:25,  5.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     8 runs   (    0.47 ms per token,  2138.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     376.18 ms /    20 tokens (   18.81 ms per token,    53.17 tokens per second)\n",
      "llama_print_timings:        eval time =     754.13 ms /     7 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1138.49 ms /    27 tokens\n",
      " 26%|██▌       | 129/500 [08:49<25:26,  4.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    20 runs   (    0.51 ms per token,  1969.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3721.16 ms /   210 tokens (   17.72 ms per token,    56.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.84 ms /    19 runs   (  105.73 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    5751.74 ms /   229 tokens\n",
      " 26%|██▌       | 130/500 [08:55<28:24,  4.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.43 ms /    30 runs   (    0.51 ms per token,  1944.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.59 ms /    22 tokens (   18.44 ms per token,    54.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2976.92 ms /    29 runs   (  102.65 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    3414.28 ms /    51 tokens\n",
      " 26%|██▌       | 131/500 [08:58<26:08,  4.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.04 ms /    28 runs   (    0.54 ms per token,  1861.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.01 ms /    33 tokens (   18.30 ms per token,    54.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2769.70 ms /    27 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    3405.07 ms /    60 tokens\n",
      " 26%|██▋       | 132/500 [09:02<24:31,  4.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.92 ms /    50 runs   (    0.54 ms per token,  1857.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     509.80 ms /    28 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5086.99 ms /    49 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    5654.64 ms /    77 tokens\n",
      " 27%|██▋       | 133/500 [09:07<27:29,  4.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.88 ms /    28 runs   (    0.53 ms per token,  1881.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.49 ms /    25 tokens (   18.62 ms per token,    53.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2744.66 ms /    27 runs   (  101.65 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3242.33 ms /    52 tokens\n",
      " 27%|██▋       | 134/500 [09:10<25:08,  4.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    20 runs   (    0.53 ms per token,  1888.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.19 ms /    21 tokens (   18.82 ms per token,    53.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1841.26 ms /    19 runs   (   96.91 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =    2257.29 ms /    40 tokens\n",
      " 27%|██▋       | 135/500 [09:13<21:40,  3.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    16 runs   (    0.52 ms per token,  1906.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.41 ms /    20 tokens (   18.52 ms per token,    53.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1495.85 ms /    15 runs   (   99.72 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    1883.04 ms /    35 tokens\n",
      " 27%|██▋       | 136/500 [09:15<18:33,  3.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.73 ms /    43 runs   (    0.51 ms per token,  1979.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.60 ms /    17 tokens (   19.15 ms per token,    52.21 tokens per second)\n",
      "llama_print_timings:        eval time =    4330.56 ms /    42 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    4704.55 ms /    59 tokens\n",
      " 27%|██▋       | 137/500 [09:19<21:29,  3.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.28 ms /    90 runs   (    0.53 ms per token,  1903.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.90 ms /    23 tokens (   18.65 ms per token,    53.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9028.68 ms /    89 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    9558.42 ms /   112 tokens\n",
      " 28%|██▊       | 138/500 [09:29<32:18,  5.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      27.94 ms /    53 runs   (    0.53 ms per token,  1897.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.46 ms /    15 tokens (   19.43 ms per token,    51.46 tokens per second)\n",
      "llama_print_timings:        eval time =    5352.12 ms /    52 runs   (  102.93 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    5702.90 ms /    67 tokens\n",
      " 28%|██▊       | 139/500 [09:35<32:51,  5.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.27 ms /    30 runs   (    0.51 ms per token,  1965.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.29 ms /    17 tokens (   19.19 ms per token,    52.10 tokens per second)\n",
      "llama_print_timings:        eval time =    3143.14 ms /    29 runs   (  108.38 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    3502.08 ms /    46 tokens\n",
      " 28%|██▊       | 140/500 [09:38<29:14,  4.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    13 runs   (    0.52 ms per token,  1913.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.23 ms /    23 tokens (   18.66 ms per token,    53.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1258.14 ms /    12 runs   (  104.84 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    1700.90 ms /    35 tokens\n",
      " 28%|██▊       | 141/500 [09:40<23:28,  3.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /    38 runs   (    0.52 ms per token,  1938.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8152.35 ms /   452 tokens (   18.04 ms per token,    55.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3752.07 ms /    37 runs   (  101.41 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =   11947.19 ms /   489 tokens\n",
      " 28%|██▊       | 142/500 [09:52<37:46,  6.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.25 ms /    38 runs   (    0.51 ms per token,  1974.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     476.01 ms /    25 tokens (   19.04 ms per token,    52.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3705.32 ms /    37 runs   (  100.14 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    4223.29 ms /    62 tokens\n",
      " 29%|██▊       | 143/500 [09:56<33:54,  5.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.25 ms /    90 runs   (    0.51 ms per token,  1945.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     578.11 ms /    31 tokens (   18.65 ms per token,    53.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9061.35 ms /    89 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    9744.56 ms /   120 tokens\n",
      " 29%|██▉       | 144/500 [10:06<41:01,  6.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.80 ms /    38 runs   (    0.49 ms per token,  2021.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     470.36 ms /    25 tokens (   18.81 ms per token,    53.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3673.12 ms /    37 runs   (   99.27 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    4184.58 ms /    62 tokens\n",
      " 29%|██▉       | 145/500 [10:10<36:04,  6.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.28 ms /    50 runs   (    0.53 ms per token,  1902.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     715.32 ms /    39 tokens (   18.34 ms per token,    54.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4984.85 ms /    49 runs   (  101.73 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    5755.88 ms /    88 tokens\n",
      " 29%|██▉       | 146/500 [10:16<35:22,  6.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.88 ms /    90 runs   (    0.52 ms per token,  1919.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     823.07 ms /    45 tokens (   18.29 ms per token,    54.67 tokens per second)\n",
      "llama_print_timings:        eval time =    9143.92 ms /    89 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =   10069.61 ms /   134 tokens\n",
      " 29%|██▉       | 147/500 [10:26<42:28,  7.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     5 runs   (    0.55 ms per token,  1830.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     761.98 ms /    42 tokens (   18.14 ms per token,    55.12 tokens per second)\n",
      "llama_print_timings:        eval time =     405.34 ms /     4 runs   (  101.33 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1172.26 ms /    46 tokens\n",
      " 30%|██▉       | 148/500 [10:27<31:42,  5.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.43 ms /    41 runs   (    0.50 ms per token,  2007.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     411.24 ms /    22 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4228.89 ms /    40 runs   (  105.72 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    4685.27 ms /    62 tokens\n",
      " 30%|██▉       | 149/500 [10:32<30:22,  5.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.25 ms /    51 runs   (    0.51 ms per token,  1942.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4824.65 ms /   271 tokens (   17.80 ms per token,    56.17 tokens per second)\n",
      "llama_print_timings:        eval time =    5143.93 ms /    50 runs   (  102.88 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =   10023.91 ms /   321 tokens\n",
      " 30%|███       | 150/500 [10:42<38:44,  6.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      45.81 ms /    90 runs   (    0.51 ms per token,  1964.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.79 ms /    21 tokens (   18.85 ms per token,    53.06 tokens per second)\n",
      "llama_print_timings:        eval time =    9467.58 ms /    89 runs   (  106.38 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    9964.85 ms /   110 tokens\n",
      " 30%|███       | 151/500 [10:52<44:26,  7.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    15 runs   (    0.54 ms per token,  1863.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.99 ms /    18 tokens (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1392.01 ms /    14 runs   (   99.43 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =    1745.05 ms /    32 tokens\n",
      " 30%|███       | 152/500 [10:53<34:03,  5.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.08 ms /    90 runs   (    0.51 ms per token,  1952.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.21 ms /    23 tokens (   18.75 ms per token,    53.34 tokens per second)\n",
      "llama_print_timings:        eval time =    9059.07 ms /    89 runs   (  101.79 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    9590.25 ms /   112 tokens\n",
      " 31%|███       | 153/500 [11:03<40:25,  6.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    23 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5483.68 ms /   308 tokens (   17.80 ms per token,    56.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2210.31 ms /    22 runs   (  100.47 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    7718.56 ms /   330 tokens\n",
      " 31%|███       | 154/500 [11:11<41:34,  7.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    24 runs   (    0.52 ms per token,  1907.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.82 ms /    31 tokens (   18.41 ms per token,    54.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2347.64 ms /    23 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    2944.10 ms /    54 tokens\n",
      " 31%|███       | 155/500 [11:14<34:06,  5.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    19 runs   (    0.54 ms per token,  1836.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     639.40 ms /    35 tokens (   18.27 ms per token,    54.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1816.99 ms /    18 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    2477.59 ms /    53 tokens\n",
      " 31%|███       | 156/500 [11:16<28:04,  4.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.27 ms /    90 runs   (    0.51 ms per token,  1945.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     616.59 ms /    34 tokens (   18.14 ms per token,    55.14 tokens per second)\n",
      "llama_print_timings:        eval time =    9245.29 ms /    89 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    9964.22 ms /   123 tokens\n",
      " 31%|███▏      | 157/500 [11:26<36:41,  6.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      23.62 ms /    45 runs   (    0.52 ms per token,  1905.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     584.70 ms /    32 tokens (   18.27 ms per token,    54.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4747.09 ms /    44 runs   (  107.89 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    5382.40 ms /    76 tokens\n",
      " 32%|███▏      | 158/500 [11:31<34:48,  6.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.99 ms /    35 runs   (    0.51 ms per token,  1945.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3679.47 ms /   207 tokens (   17.78 ms per token,    56.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3512.24 ms /    34 runs   (  103.30 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    7229.54 ms /   241 tokens\n",
      " 32%|███▏      | 159/500 [11:39<36:37,  6.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.09 ms /    23 runs   (    0.53 ms per token,  1902.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.16 ms /    23 tokens (   18.66 ms per token,    53.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2413.72 ms /    22 runs   (  109.71 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    2867.68 ms /    45 tokens\n",
      " 32%|███▏      | 160/500 [11:42<30:26,  5.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    13 runs   (    0.55 ms per token,  1806.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     509.82 ms /    28 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.48 ms /    12 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1768.83 ms /    40 tokens\n",
      " 32%|███▏      | 161/500 [11:43<24:15,  4.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.70 ms /    38 runs   (    0.52 ms per token,  1928.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     789.09 ms /    44 tokens (   17.93 ms per token,    55.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3771.04 ms /    37 runs   (  101.92 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    4602.16 ms /    81 tokens\n",
      " 32%|███▏      | 162/500 [11:48<24:42,  4.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     4 runs   (    0.55 ms per token,  1817.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     602.43 ms /    33 tokens (   18.26 ms per token,    54.78 tokens per second)\n",
      "llama_print_timings:        eval time =     290.66 ms /     3 runs   (   96.89 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =     897.62 ms /    36 tokens\n",
      " 33%|███▎      | 163/500 [11:49<18:45,  3.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    21 runs   (    0.53 ms per token,  1880.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3291.68 ms /   186 tokens (   17.70 ms per token,    56.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2028.34 ms /    20 runs   (  101.42 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    5342.87 ms /   206 tokens\n",
      " 33%|███▎      | 164/500 [11:54<22:04,  3.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    26 runs   (    0.51 ms per token,  1946.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     884.09 ms /    49 tokens (   18.04 ms per token,    55.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2508.54 ms /    25 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    3419.98 ms /    74 tokens\n",
      " 33%|███▎      | 165/500 [11:58<21:08,  3.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.20 ms /    32 runs   (    0.44 ms per token,  2253.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     534.66 ms /    29 tokens (   18.44 ms per token,    54.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3187.66 ms /    31 runs   (  102.83 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3754.44 ms /    60 tokens\n",
      " 33%|███▎      | 166/500 [12:01<21:01,  3.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     5 runs   (    0.52 ms per token,  1931.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     475.48 ms /    26 tokens (   18.29 ms per token,    54.68 tokens per second)\n",
      "llama_print_timings:        eval time =     413.57 ms /     4 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     893.44 ms /    30 tokens\n",
      " 33%|███▎      | 167/500 [12:02<16:10,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    15 runs   (    0.55 ms per token,  1823.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     670.38 ms /    37 tokens (   18.12 ms per token,    55.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1422.68 ms /    14 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2108.87 ms /    51 tokens\n",
      " 34%|███▎      | 168/500 [12:04<14:47,  2.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     6 runs   (    0.54 ms per token,  1853.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3480.64 ms /   195 tokens (   17.85 ms per token,    56.02 tokens per second)\n",
      "llama_print_timings:        eval time =     469.36 ms /     5 runs   (   93.87 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =    3956.15 ms /   200 tokens\n",
      " 34%|███▍      | 169/500 [12:08<16:52,  3.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    22 runs   (    0.51 ms per token,  1968.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     464.10 ms /    25 tokens (   18.56 ms per token,    53.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2178.33 ms /    21 runs   (  103.73 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2665.28 ms /    46 tokens\n",
      " 34%|███▍      | 170/500 [12:11<16:10,  2.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    18 runs   (    0.54 ms per token,  1839.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.78 ms /    31 tokens (   18.32 ms per token,    54.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1772.08 ms /    17 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2360.08 ms /    48 tokens\n",
      " 34%|███▍      | 171/500 [12:13<15:10,  2.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1896.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.96 ms /    18 tokens (   18.72 ms per token,    53.42 tokens per second)\n",
      "llama_print_timings:        eval time =     540.73 ms /     5 runs   (  108.15 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =     883.63 ms /    23 tokens\n",
      " 34%|███▍      | 172/500 [12:14<12:02,  2.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     6 runs   (    0.54 ms per token,  1857.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     475.63 ms /    26 tokens (   18.29 ms per token,    54.66 tokens per second)\n",
      "llama_print_timings:        eval time =     501.91 ms /     5 runs   (  100.38 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =     984.45 ms /    31 tokens\n",
      " 35%|███▍      | 173/500 [12:15<10:01,  1.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.14 ms /    40 runs   (    0.53 ms per token,  1892.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4115.96 ms /   232 tokens (   17.74 ms per token,    56.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4075.00 ms /    39 runs   (  104.49 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    8235.30 ms /   271 tokens\n",
      " 35%|███▍      | 174/500 [12:23<20:25,  3.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      48.09 ms /    90 runs   (    0.53 ms per token,  1871.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.28 ms /    20 tokens (   18.66 ms per token,    53.58 tokens per second)\n",
      "llama_print_timings:        eval time =    9005.04 ms /    89 runs   (  101.18 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    9480.17 ms /   109 tokens\n",
      " 35%|███▌      | 175/500 [12:33<29:39,  5.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      36.90 ms /    71 runs   (    0.52 ms per token,  1923.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.38 ms /    16 tokens (   18.96 ms per token,    52.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7100.76 ms /    70 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    7484.17 ms /    86 tokens\n",
      " 35%|███▌      | 176/500 [12:40<32:49,  6.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.12 ms /    60 runs   (    0.55 ms per token,  1811.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.23 ms /    14 tokens (   19.23 ms per token,    52.00 tokens per second)\n",
      "llama_print_timings:        eval time =    6089.03 ms /    59 runs   (  103.20 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    6426.95 ms /    73 tokens\n",
      " 35%|███▌      | 177/500 [12:47<33:17,  6.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.20 ms /    35 runs   (    0.52 ms per token,  1922.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.95 ms /    21 tokens (   18.81 ms per token,    53.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3579.18 ms /    34 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    4012.11 ms /    55 tokens\n",
      " 36%|███▌      | 178/500 [12:51<29:41,  5.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    29 runs   (    0.53 ms per token,  1904.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6631.77 ms /   370 tokens (   17.92 ms per token,    55.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2793.40 ms /    28 runs   (   99.76 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    9456.45 ms /   398 tokens\n",
      " 36%|███▌      | 179/500 [13:00<35:54,  6.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.26 ms /    30 runs   (    0.51 ms per token,  1966.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     501.62 ms /    27 tokens (   18.58 ms per token,    53.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2992.64 ms /    29 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    3526.21 ms /    56 tokens\n",
      " 36%|███▌      | 180/500 [13:04<30:42,  5.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    22 runs   (    0.52 ms per token,  1905.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     444.87 ms /    24 tokens (   18.54 ms per token,    53.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2236.45 ms /    21 runs   (  106.50 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    2705.58 ms /    45 tokens\n",
      " 36%|███▌      | 181/500 [13:07<25:44,  4.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    15 runs   (    0.56 ms per token,  1782.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     759.41 ms /    42 tokens (   18.08 ms per token,    55.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1424.68 ms /    14 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    2201.54 ms /    56 tokens\n",
      " 36%|███▋      | 182/500 [13:09<21:28,  4.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.31 ms /    40 runs   (    0.51 ms per token,  1969.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3152.95 ms /   178 tokens (   17.71 ms per token,    56.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4049.24 ms /    39 runs   (  103.83 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    7244.96 ms /   217 tokens\n",
      " 37%|███▋      | 183/500 [13:16<26:28,  5.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    15 runs   (    0.54 ms per token,  1852.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.15 ms /    22 tokens (   18.42 ms per token,    54.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1394.23 ms /    14 runs   (   99.59 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    1816.02 ms /    36 tokens\n",
      " 37%|███▋      | 184/500 [13:18<21:20,  4.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    24 runs   (    0.46 ms per token,  2165.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.44 ms /    21 tokens (   18.74 ms per token,    53.38 tokens per second)\n",
      "llama_print_timings:        eval time =    2338.71 ms /    23 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    2756.17 ms /    44 tokens\n",
      " 37%|███▋      | 185/500 [13:21<19:14,  3.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.74 ms /    28 runs   (    0.53 ms per token,  1899.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.40 ms /    20 tokens (   18.52 ms per token,    54.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2754.62 ms /    27 runs   (  102.02 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    3155.49 ms /    47 tokens\n",
      " 37%|███▋      | 186/500 [13:24<18:23,  3.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.41 ms /    26 runs   (    0.52 ms per token,  1939.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.11 ms /    26 tokens (   18.23 ms per token,    54.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2551.61 ms /    25 runs   (  102.06 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    3053.02 ms /    51 tokens\n",
      " 37%|███▋      | 187/500 [13:27<17:36,  3.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     4 runs   (    0.53 ms per token,  1894.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3857.06 ms /   218 tokens (   17.69 ms per token,    56.52 tokens per second)\n",
      "llama_print_timings:        eval time =     305.91 ms /     3 runs   (  101.97 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    4166.51 ms /   221 tokens\n",
      " 38%|███▊      | 188/500 [13:31<18:47,  3.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.09 ms /    44 runs   (    0.50 ms per token,  1991.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     407.03 ms /    22 tokens (   18.50 ms per token,    54.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4232.31 ms /    43 runs   (   98.43 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    4686.43 ms /    65 tokens\n",
      " 38%|███▊      | 189/500 [13:36<20:24,  3.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    16 runs   (    0.54 ms per token,  1848.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     324.18 ms /    17 tokens (   19.07 ms per token,    52.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1497.29 ms /    15 runs   (   99.82 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    1839.16 ms /    32 tokens\n",
      " 38%|███▊      | 190/500 [13:37<17:05,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    13 runs   (    0.50 ms per token,  2011.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.86 ms /    17 tokens (   19.23 ms per token,    52.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.04 ms /    12 runs   (  104.34 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1592.51 ms /    29 tokens\n",
      " 38%|███▊      | 191/500 [13:39<14:23,  2.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.10 ms /    29 runs   (    0.52 ms per token,  1920.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.78 ms /    11 tokens (   20.25 ms per token,    49.38 tokens per second)\n",
      "llama_print_timings:        eval time =    2998.29 ms /    28 runs   (  107.08 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    3251.64 ms /    39 tokens\n",
      " 38%|███▊      | 192/500 [13:42<15:03,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1869.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4152.73 ms /   234 tokens (   17.75 ms per token,    56.35 tokens per second)\n",
      "llama_print_timings:        eval time =     480.32 ms /     5 runs   (   96.06 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =    4639.22 ms /   239 tokens\n",
      " 39%|███▊      | 193/500 [13:47<17:37,  3.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    10 runs   (    0.55 ms per token,  1824.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     567.76 ms /    31 tokens (   18.31 ms per token,    54.60 tokens per second)\n",
      "llama_print_timings:        eval time =     938.34 ms /     9 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    1517.15 ms /    40 tokens\n",
      " 39%|███▉      | 194/500 [13:48<14:37,  2.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    18 runs   (    0.53 ms per token,  1878.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.12 ms /    27 tokens (   18.49 ms per token,    54.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1767.41 ms /    17 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2285.24 ms /    44 tokens\n",
      " 39%|███▉      | 195/500 [13:51<13:41,  2.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /     8 runs   (    0.56 ms per token,  1794.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     464.19 ms /    25 tokens (   18.57 ms per token,    53.86 tokens per second)\n",
      "llama_print_timings:        eval time =     728.15 ms /     7 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1201.03 ms /    32 tokens\n",
      " 39%|███▉      | 196/500 [13:52<11:23,  2.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.84 ms /    29 runs   (    0.51 ms per token,  1954.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     498.50 ms /    27 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2896.24 ms /    28 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    3425.13 ms /    55 tokens\n",
      " 39%|███▉      | 197/500 [13:55<13:08,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    32 runs   (    0.52 ms per token,  1931.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3855.99 ms /   217 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =    3158.88 ms /    31 runs   (  101.90 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    7050.13 ms /   248 tokens\n",
      " 40%|███▉      | 198/500 [14:02<19:48,  3.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /     9 runs   (    0.54 ms per token,  1835.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.29 ms /    18 tokens (   18.68 ms per token,    53.53 tokens per second)\n",
      "llama_print_timings:        eval time =     851.78 ms /     8 runs   (  106.47 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    1197.13 ms /    26 tokens\n",
      " 40%|███▉      | 199/500 [14:04<15:37,  3.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      31.40 ms /    58 runs   (    0.54 ms per token,  1846.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     816.15 ms /    45 tokens (   18.14 ms per token,    55.14 tokens per second)\n",
      "llama_print_timings:        eval time =    5860.14 ms /    57 runs   (  102.81 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    6741.35 ms /   102 tokens\n",
      " 40%|████      | 200/500 [14:10<21:01,  4.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    17 runs   (    0.52 ms per token,  1924.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.44 ms /    20 tokens (   18.67 ms per token,    53.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1598.96 ms /    16 runs   (   99.93 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    1989.81 ms /    36 tokens\n",
      " 40%|████      | 201/500 [14:12<17:38,  3.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.95 ms /    49 runs   (    0.51 ms per token,  1963.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4320.49 ms /   243 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4945.25 ms /    48 runs   (  103.03 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    9318.95 ms /   291 tokens\n",
      " 40%|████      | 202/500 [14:22<26:12,  5.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    12 runs   (    0.54 ms per token,  1837.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     466.64 ms /    25 tokens (   18.67 ms per token,    53.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.37 ms /    11 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1615.90 ms /    36 tokens\n",
      " 41%|████      | 203/500 [14:23<20:40,  4.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    29 runs   (    0.54 ms per token,  1861.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.19 ms /    19 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2916.38 ms /    28 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    3310.49 ms /    47 tokens\n",
      " 41%|████      | 204/500 [14:27<19:19,  3.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    12 runs   (    0.52 ms per token,  1906.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     430.60 ms /    23 tokens (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.05 ms /    11 runs   (  101.00 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1553.56 ms /    34 tokens\n",
      " 41%|████      | 205/500 [14:28<15:47,  3.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    18 runs   (    0.50 ms per token,  1996.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.02 ms /    13 tokens (   19.85 ms per token,    50.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1753.81 ms /    17 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2030.65 ms /    30 tokens\n",
      " 41%|████      | 206/500 [14:30<13:59,  2.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     3 runs   (    0.53 ms per token,  1883.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4585.60 ms /   258 tokens (   17.77 ms per token,    56.26 tokens per second)\n",
      "llama_print_timings:        eval time =     198.73 ms /     2 runs   (   99.37 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =    4787.53 ms /   260 tokens\n",
      " 41%|████▏     | 207/500 [14:35<16:47,  3.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.18 ms /    29 runs   (    0.52 ms per token,  1910.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.11 ms /    16 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2850.65 ms /    28 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    3184.56 ms /    44 tokens\n",
      " 42%|████▏     | 208/500 [14:38<16:21,  3.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    18 runs   (    0.53 ms per token,  1896.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.47 ms /    21 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1736.68 ms /    17 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    2149.33 ms /    38 tokens\n",
      " 42%|████▏     | 209/500 [14:40<14:32,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     5 runs   (    0.53 ms per token,  1888.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     550.67 ms /    30 tokens (   18.36 ms per token,    54.48 tokens per second)\n",
      "llama_print_timings:        eval time =     414.81 ms /     4 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     970.74 ms /    34 tokens\n",
      " 42%|████▏     | 210/500 [14:41<11:33,  2.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     5 runs   (    0.55 ms per token,  1804.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.30 ms /    19 tokens (   18.96 ms per token,    52.73 tokens per second)\n",
      "llama_print_timings:        eval time =     409.71 ms /     4 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =     775.51 ms /    23 tokens\n",
      " 42%|████▏     | 211/500 [14:42<09:11,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.24 ms /    34 runs   (    0.54 ms per token,  1863.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     408.68 ms /    22 tokens (   18.58 ms per token,    53.83 tokens per second)\n",
      "llama_print_timings:        eval time =    3437.65 ms /    33 runs   (  104.17 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    3884.45 ms /    55 tokens\n",
      " 42%|████▏     | 212/500 [14:46<12:00,  2.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     3 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.02 ms /    19 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =     204.03 ms /     2 runs   (  102.01 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =     567.78 ms /    21 tokens\n",
      " 43%|████▎     | 213/500 [14:47<09:11,  1.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     3 runs   (    0.53 ms per token,  1886.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     476.50 ms /    26 tokens (   18.33 ms per token,    54.56 tokens per second)\n",
      "llama_print_timings:        eval time =     207.26 ms /     2 runs   (  103.63 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     687.06 ms /    28 tokens\n",
      " 43%|████▎     | 214/500 [14:47<07:23,  1.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /     5 runs   (    0.56 ms per token,  1795.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4318.48 ms /   243 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time =     428.19 ms /     4 runs   (  107.05 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    4751.52 ms /   247 tokens\n",
      " 43%|████▎     | 215/500 [14:52<11:56,  2.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    13 runs   (    0.54 ms per token,  1850.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.64 ms /    15 tokens (   19.44 ms per token,    51.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1179.28 ms /    12 runs   (   98.27 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =    1484.72 ms /    27 tokens\n",
      " 43%|████▎     | 216/500 [14:54<10:26,  2.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    19 runs   (    0.55 ms per token,  1822.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.84 ms /    17 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1833.69 ms /    18 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    2179.37 ms /    35 tokens\n",
      " 43%|████▎     | 217/500 [14:56<10:22,  2.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     8 runs   (    0.55 ms per token,  1827.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     477.17 ms /    26 tokens (   18.35 ms per token,    54.49 tokens per second)\n",
      "llama_print_timings:        eval time =     726.91 ms /     7 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1212.89 ms /    33 tokens\n",
      " 44%|████▎     | 218/500 [14:57<08:56,  1.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.44 ms /    36 runs   (    0.54 ms per token,  1851.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.97 ms /    21 tokens (   18.76 ms per token,    53.30 tokens per second)\n",
      "llama_print_timings:        eval time =    3507.88 ms /    35 runs   (  100.23 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    3941.45 ms /    56 tokens\n",
      " 44%|████▍     | 219/500 [15:01<11:46,  2.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      45.31 ms /    90 runs   (    0.50 ms per token,  1986.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4651.42 ms /   261 tokens (   17.82 ms per token,    56.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9101.90 ms /    89 runs   (  102.27 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =   13853.32 ms /   350 tokens\n",
      " 44%|████▍     | 220/500 [15:15<27:37,  5.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.38 ms /    37 runs   (    0.50 ms per token,  2012.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.87 ms /    20 tokens (   18.69 ms per token,    53.49 tokens per second)\n",
      "llama_print_timings:        eval time =    3736.61 ms /    36 runs   (  103.79 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    4150.41 ms /    56 tokens\n",
      " 44%|████▍     | 221/500 [15:19<25:03,  5.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      36.95 ms /    73 runs   (    0.51 ms per token,  1975.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     514.57 ms /    28 tokens (   18.38 ms per token,    54.41 tokens per second)\n",
      "llama_print_timings:        eval time =    7263.04 ms /    72 runs   (  100.88 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    7859.77 ms /   100 tokens\n",
      " 44%|████▍     | 222/500 [15:27<28:24,  6.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.91 ms /    37 runs   (    0.51 ms per token,  1956.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.30 ms /    20 tokens (   18.61 ms per token,    53.72 tokens per second)\n",
      "llama_print_timings:        eval time =    3579.62 ms /    36 runs   (   99.43 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =    3991.81 ms /    56 tokens\n",
      " 45%|████▍     | 223/500 [15:31<25:20,  5.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.60 ms /    90 runs   (    0.52 ms per token,  1931.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.92 ms /    18 tokens (   18.77 ms per token,    53.27 tokens per second)\n",
      "llama_print_timings:        eval time =    9115.50 ms /    89 runs   (  102.42 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    9555.21 ms /   107 tokens\n",
      " 45%|████▍     | 224/500 [15:40<30:52,  6.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    21 runs   (    0.54 ms per token,  1867.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4463.43 ms /   251 tokens (   17.78 ms per token,    56.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2006.35 ms /    20 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    6493.21 ms /   271 tokens\n",
      " 45%|████▌     | 225/500 [15:47<30:27,  6.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.32 ms /    32 runs   (    0.51 ms per token,  1961.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.78 ms /    22 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =    3287.76 ms /    31 runs   (  106.06 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    3729.31 ms /    53 tokens\n",
      " 45%|████▌     | 226/500 [15:51<26:21,  5.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.79 ms /    35 runs   (    0.51 ms per token,  1967.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     409.17 ms /    22 tokens (   18.60 ms per token,    53.77 tokens per second)\n",
      "llama_print_timings:        eval time =    3571.17 ms /    34 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    4017.83 ms /    56 tokens\n",
      " 45%|████▌     | 227/500 [15:55<23:52,  5.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    18 runs   (    0.53 ms per token,  1869.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     304.40 ms /    16 tokens (   19.03 ms per token,    52.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1880.62 ms /    17 runs   (  110.62 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =    2204.79 ms /    33 tokens\n",
      " 46%|████▌     | 228/500 [15:57<19:39,  4.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.41 ms /    31 runs   (    0.50 ms per token,  2012.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     467.72 ms /    25 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3098.57 ms /    30 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    3599.64 ms /    55 tokens\n",
      " 46%|████▌     | 229/500 [16:00<18:35,  4.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    22 runs   (    0.53 ms per token,  1895.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3253.80 ms /   183 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2196.20 ms /    21 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    5472.96 ms /   204 tokens\n",
      " 46%|████▌     | 230/500 [16:06<20:21,  4.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     8 runs   (    0.49 ms per token,  2059.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     369.44 ms /    20 tokens (   18.47 ms per token,    54.14 tokens per second)\n",
      "llama_print_timings:        eval time =     676.44 ms /     7 runs   (   96.63 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =    1053.24 ms /    27 tokens\n",
      " 46%|████▌     | 231/500 [16:07<15:37,  3.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    14 runs   (    0.47 ms per token,  2121.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.49 ms /    21 tokens (   18.83 ms per token,    53.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1391.18 ms /    13 runs   (  107.01 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    1800.77 ms /    34 tokens\n",
      " 46%|████▋     | 232/500 [16:09<13:18,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.44 ms /    56 runs   (    0.51 ms per token,  1968.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.96 ms /    15 tokens (   19.33 ms per token,    51.73 tokens per second)\n",
      "llama_print_timings:        eval time =    5497.48 ms /    55 runs   (   99.95 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    5847.81 ms /    70 tokens\n",
      " 47%|████▋     | 233/500 [16:15<17:05,  3.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.23 ms /    28 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.83 ms /    24 tokens (   18.33 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2746.54 ms /    27 runs   (  101.72 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    3216.73 ms /    51 tokens\n",
      " 47%|████▋     | 234/500 [16:18<16:12,  3.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    39 runs   (    0.52 ms per token,  1912.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5047.16 ms /   284 tokens (   17.77 ms per token,    56.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3969.47 ms /    38 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    9059.36 ms /   322 tokens\n",
      " 47%|████▋     | 235/500 [16:27<23:18,  5.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      31.24 ms /    56 runs   (    0.56 ms per token,  1792.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.60 ms /    19 tokens (   18.98 ms per token,    52.69 tokens per second)\n",
      "llama_print_timings:        eval time =    5749.47 ms /    55 runs   (  104.54 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    6174.76 ms /    74 tokens\n",
      " 47%|████▋     | 236/500 [16:33<24:24,  5.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      39.61 ms /    74 runs   (    0.54 ms per token,  1868.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.78 ms /    14 tokens (   19.27 ms per token,    51.89 tokens per second)\n",
      "llama_print_timings:        eval time =    7517.22 ms /    73 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    7871.29 ms /    87 tokens\n",
      " 47%|████▋     | 237/500 [16:41<27:22,  6.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.13 ms /    33 runs   (    0.55 ms per token,  1820.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     396.41 ms /    21 tokens (   18.88 ms per token,    52.97 tokens per second)\n",
      "llama_print_timings:        eval time =    3371.92 ms /    32 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    3804.73 ms /    53 tokens\n",
      " 48%|████▊     | 238/500 [16:45<24:04,  5.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      49.57 ms /    90 runs   (    0.55 ms per token,  1815.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.97 ms /    11 tokens (   20.36 ms per token,    49.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9367.53 ms /    89 runs   (  105.25 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    9695.74 ms /   100 tokens\n",
      " 48%|████▊     | 239/500 [16:54<29:26,  6.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.17 ms /    47 runs   (    0.54 ms per token,  1867.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5894.16 ms /   329 tokens (   17.92 ms per token,    55.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4730.88 ms /    46 runs   (  102.85 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =   10676.26 ms /   375 tokens\n",
      " 48%|████▊     | 240/500 [17:05<34:25,  7.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     374.60 ms /    20 tokens (   18.73 ms per token,    53.39 tokens per second)\n",
      "llama_print_timings:        eval time =     507.17 ms /     5 runs   (  101.43 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =     887.51 ms /    25 tokens\n",
      " 48%|████▊     | 241/500 [17:06<25:09,  5.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      40.97 ms /    78 runs   (    0.53 ms per token,  1903.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     407.95 ms /    22 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =    8003.09 ms /    77 runs   (  103.94 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    8498.49 ms /    99 tokens\n",
      " 48%|████▊     | 242/500 [17:14<28:30,  6.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     3 runs   (    0.54 ms per token,  1839.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     537.97 ms /    29 tokens (   18.55 ms per token,    53.91 tokens per second)\n",
      "llama_print_timings:        eval time =     209.64 ms /     2 runs   (  104.82 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =     750.75 ms /    31 tokens\n",
      " 49%|████▊     | 243/500 [17:15<20:50,  4.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    16 runs   (    0.55 ms per token,  1810.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3551.54 ms /   199 tokens (   17.85 ms per token,    56.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1574.70 ms /    15 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5143.28 ms /   214 tokens\n",
      " 49%|████▉     | 244/500 [17:20<21:07,  4.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.59 ms /    48 runs   (    0.53 ms per token,  1875.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     512.17 ms /    28 tokens (   18.29 ms per token,    54.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4988.49 ms /    47 runs   (  106.14 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    5554.21 ms /    75 tokens\n",
      " 49%|████▉     | 245/500 [17:26<21:48,  5.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.24 ms /    32 runs   (    0.51 ms per token,  1970.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.26 ms /    24 tokens (   18.34 ms per token,    54.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3151.79 ms /    31 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3624.97 ms /    55 tokens\n",
      " 49%|████▉     | 246/500 [17:30<19:49,  4.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /     5 runs   (    0.56 ms per token,  1801.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.42 ms /    21 tokens (   18.83 ms per token,    53.11 tokens per second)\n",
      "llama_print_timings:        eval time =     407.13 ms /     4 runs   (  101.78 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =     807.88 ms /    25 tokens\n",
      " 49%|████▉     | 247/500 [17:30<14:50,  3.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    33 runs   (    0.52 ms per token,  1928.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.41 ms /    21 tokens (   18.78 ms per token,    53.24 tokens per second)\n",
      "llama_print_timings:        eval time =    3336.24 ms /    32 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3766.72 ms /    53 tokens\n",
      " 50%|████▉     | 248/500 [17:34<15:05,  3.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    10 runs   (    0.55 ms per token,  1825.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6622.91 ms /   369 tokens (   17.95 ms per token,    55.72 tokens per second)\n",
      "llama_print_timings:        eval time =     971.05 ms /     9 runs   (  107.89 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    7604.59 ms /   378 tokens\n",
      " 50%|████▉     | 249/500 [17:42<20:04,  4.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.32 ms /    34 runs   (    0.51 ms per token,  1963.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     408.86 ms /    22 tokens (   18.58 ms per token,    53.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3338.90 ms /    33 runs   (  101.18 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3784.50 ms /    55 tokens\n",
      " 50%|█████     | 250/500 [17:46<18:43,  4.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     5 runs   (    0.51 ms per token,  1942.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     538.79 ms /    29 tokens (   18.58 ms per token,    53.82 tokens per second)\n",
      "llama_print_timings:        eval time =     375.03 ms /     4 runs   (   93.76 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     918.49 ms /    33 tokens\n",
      " 50%|█████     | 251/500 [17:46<14:12,  3.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    22 runs   (    0.49 ms per token,  2023.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     375.21 ms /    20 tokens (   18.76 ms per token,    53.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2212.30 ms /    21 runs   (  105.35 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    2609.69 ms /    41 tokens\n",
      " 50%|█████     | 252/500 [17:49<13:08,  3.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /     8 runs   (    0.52 ms per token,  1925.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3754.81 ms /   211 tokens (   17.80 ms per token,    56.19 tokens per second)\n",
      "llama_print_timings:        eval time =     696.92 ms /     7 runs   (   99.56 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    4460.75 ms /   218 tokens\n",
      " 51%|█████     | 253/500 [17:54<14:40,  3.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    15 runs   (    0.51 ms per token,  1977.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     635.86 ms /    35 tokens (   18.17 ms per token,    55.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1453.13 ms /    14 runs   (  103.79 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    2104.06 ms /    49 tokens\n",
      " 51%|█████     | 254/500 [17:56<12:49,  3.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.74 ms /    57 runs   (    0.50 ms per token,  1983.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     902.23 ms /    50 tokens (   18.04 ms per token,    55.42 tokens per second)\n",
      "llama_print_timings:        eval time =    6039.65 ms /    56 runs   (  107.85 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =    7004.83 ms /   106 tokens\n",
      " 51%|█████     | 255/500 [18:03<17:31,  4.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /     8 runs   (    0.52 ms per token,  1909.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     716.03 ms /    40 tokens (   17.90 ms per token,    55.86 tokens per second)\n",
      "llama_print_timings:        eval time =     707.38 ms /     7 runs   (  101.05 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1431.27 ms /    47 tokens\n",
      " 51%|█████     | 256/500 [18:04<13:58,  3.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    13 runs   (    0.55 ms per token,  1808.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8439.98 ms /   467 tokens (   18.07 ms per token,    55.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.27 ms /    12 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    9702.18 ms /   479 tokens\n",
      " 51%|█████▏    | 257/500 [18:14<21:31,  5.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.00 ms /    42 runs   (    0.50 ms per token,  2000.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     697.00 ms /    38 tokens (   18.34 ms per token,    54.52 tokens per second)\n",
      "llama_print_timings:        eval time =    4273.54 ms /    41 runs   (  104.23 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    5016.40 ms /    79 tokens\n",
      " 52%|█████▏    | 258/500 [18:19<21:05,  5.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.95 ms /    27 runs   (    0.52 ms per token,  1934.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.68 ms /    35 tokens (   18.51 ms per token,    54.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2659.45 ms /    26 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    3336.56 ms /    61 tokens\n",
      " 52%|█████▏    | 259/500 [18:22<18:43,  4.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /     8 runs   (    0.56 ms per token,  1779.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     645.27 ms /    35 tokens (   18.44 ms per token,    54.24 tokens per second)\n",
      "llama_print_timings:        eval time =     682.31 ms /     7 runs   (   97.47 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    1336.57 ms /    42 tokens\n",
      " 52%|█████▏    | 260/500 [18:23<14:39,  3.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    13 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     911.36 ms /    50 tokens (   18.23 ms per token,    54.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.32 ms /    12 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2177.04 ms /    62 tokens\n",
      " 52%|█████▏    | 261/500 [18:26<12:49,  3.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     5 runs   (    0.55 ms per token,  1826.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     505.54 ms /    27 tokens (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:        eval time =     409.17 ms /     4 runs   (  102.29 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     920.10 ms /    31 tokens\n",
      " 52%|█████▏    | 262/500 [18:27<10:02,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /     8 runs   (    0.56 ms per token,  1781.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     649.14 ms /    35 tokens (   18.55 ms per token,    53.92 tokens per second)\n",
      "llama_print_timings:        eval time =     704.17 ms /     7 runs   (  100.60 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    1362.02 ms /    42 tokens\n",
      " 53%|█████▎    | 263/500 [18:28<08:37,  2.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    13 runs   (    0.54 ms per token,  1858.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     609.94 ms /    33 tokens (   18.48 ms per token,    54.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.97 ms /    12 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1838.14 ms /    45 tokens\n",
      " 53%|█████▎    | 264/500 [18:30<08:10,  2.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.75 ms /    26 runs   (    0.53 ms per token,  1890.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.54 ms /    21 tokens (   19.12 ms per token,    52.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2626.83 ms /    25 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    3057.13 ms /    46 tokens\n",
      " 53%|█████▎    | 265/500 [18:33<09:17,  2.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.28 ms /    30 runs   (    0.51 ms per token,  1962.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     647.95 ms /    35 tokens (   18.51 ms per token,    54.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2979.25 ms /    29 runs   (  102.73 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    3660.33 ms /    64 tokens\n",
      " 53%|█████▎    | 266/500 [18:37<10:46,  2.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.61 ms /    59 runs   (    0.52 ms per token,  1927.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4260.80 ms /   240 tokens (   17.75 ms per token,    56.33 tokens per second)\n",
      "llama_print_timings:        eval time =    6096.02 ms /    58 runs   (  105.10 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   10424.57 ms /   298 tokens\n",
      " 53%|█████▎    | 267/500 [18:47<19:39,  5.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.67 ms /    29 runs   (    0.54 ms per token,  1850.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.61 ms /    25 tokens (   18.62 ms per token,    53.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2876.61 ms /    28 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    3374.35 ms /    53 tokens\n",
      " 54%|█████▎    | 268/500 [18:50<17:36,  4.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      23.65 ms /    45 runs   (    0.53 ms per token,  1902.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.93 ms /    17 tokens (   19.23 ms per token,    52.00 tokens per second)\n",
      "llama_print_timings:        eval time =    4505.42 ms /    44 runs   (  102.40 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    4881.50 ms /    61 tokens\n",
      " 54%|█████▍    | 269/500 [18:55<17:55,  4.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.13 ms /    57 runs   (    0.53 ms per token,  1891.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.09 ms /    19 tokens (   19.11 ms per token,    52.33 tokens per second)\n",
      "llama_print_timings:        eval time =    5877.76 ms /    56 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    6306.02 ms /    75 tokens\n",
      " 54%|█████▍    | 270/500 [19:02<19:44,  5.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.14 ms /    37 runs   (    0.52 ms per token,  1933.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.98 ms /    27 tokens (   18.52 ms per token,    54.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3758.45 ms /    36 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    4298.21 ms /    63 tokens\n",
      " 54%|█████▍    | 271/500 [19:06<18:41,  4.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     6 runs   (    0.56 ms per token,  1779.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3943.11 ms /   222 tokens (   17.76 ms per token,    56.30 tokens per second)\n",
      "llama_print_timings:        eval time =     533.33 ms /     5 runs   (  106.67 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    4482.85 ms /   227 tokens\n",
      " 54%|█████▍    | 272/500 [19:10<18:08,  4.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.57 ms per token,  1740.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.91 ms /    21 tokens (   18.81 ms per token,    53.18 tokens per second)\n",
      "llama_print_timings:        eval time =     526.81 ms /     5 runs   (  105.36 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =     929.10 ms /    26 tokens\n",
      " 55%|█████▍    | 273/500 [19:11<13:41,  3.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1864.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.70 ms /    20 tokens (   18.53 ms per token,    53.95 tokens per second)\n",
      "llama_print_timings:        eval time =     497.40 ms /     5 runs   (   99.48 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     874.71 ms /    25 tokens\n",
      " 55%|█████▍    | 274/500 [19:12<10:32,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.31 ms /    34 runs   (    0.51 ms per token,  1964.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.16 ms /    22 tokens (   18.46 ms per token,    54.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3346.16 ms /    33 runs   (  101.40 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    3789.81 ms /    55 tokens\n",
      " 55%|█████▌    | 275/500 [19:16<11:36,  3.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.19 ms /    46 runs   (    0.53 ms per token,  1901.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.91 ms /    27 tokens (   18.52 ms per token,    54.01 tokens per second)\n",
      "llama_print_timings:        eval time =    4626.26 ms /    45 runs   (  102.81 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    5175.89 ms /    72 tokens\n",
      " 55%|█████▌    | 276/500 [19:21<13:53,  3.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.18 ms /    40 runs   (    0.53 ms per token,  1889.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.30 ms /    21 tokens (   18.78 ms per token,    53.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3955.59 ms /    39 runs   (  101.43 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    4393.48 ms /    60 tokens\n",
      " 55%|█████▌    | 277/500 [19:25<14:34,  3.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.02 ms /    34 runs   (    0.50 ms per token,  1997.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.30 ms /    25 tokens (   18.61 ms per token,    53.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3353.97 ms /    33 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3855.92 ms /    58 tokens\n",
      " 56%|█████▌    | 278/500 [19:29<14:26,  3.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    18 runs   (    0.54 ms per token,  1840.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3820.39 ms /   215 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1725.92 ms /    17 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    5566.48 ms /   232 tokens\n",
      " 56%|█████▌    | 279/500 [19:35<16:13,  4.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    13 runs   (    0.55 ms per token,  1815.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.46 ms /    17 tokens (   19.20 ms per token,    52.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.09 ms /    12 runs   (   97.92 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =    1515.72 ms /    29 tokens\n",
      " 56%|█████▌    | 280/500 [19:36<12:58,  3.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.84 ms /    45 runs   (    0.55 ms per token,  1811.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.76 ms /    10 tokens (   19.88 ms per token,    50.31 tokens per second)\n",
      "llama_print_timings:        eval time =    4526.02 ms /    44 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    4775.09 ms /    54 tokens\n",
      " 56%|█████▌    | 281/500 [19:41<14:16,  3.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    14 runs   (    0.55 ms per token,  1825.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5448.88 ms /   306 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1287.69 ms /    13 runs   (   99.05 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    6751.12 ms /   319 tokens\n",
      " 56%|█████▋    | 282/500 [19:48<17:18,  4.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    12 runs   (    0.53 ms per token,  1870.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.19 ms /    25 tokens (   18.61 ms per token,    53.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.46 ms /    11 runs   (  103.77 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1619.43 ms /    36 tokens\n",
      " 57%|█████▋    | 283/500 [19:50<13:49,  3.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    20 runs   (    0.53 ms per token,  1886.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     408.11 ms /    22 tokens (   18.55 ms per token,    53.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1938.91 ms /    19 runs   (  102.05 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    2369.08 ms /    41 tokens\n",
      " 57%|█████▋    | 284/500 [19:52<12:11,  3.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    12 runs   (    0.48 ms per token,  2063.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     511.87 ms /    28 tokens (   18.28 ms per token,    54.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.91 ms /    11 runs   (   98.54 ms per token,    10.15 tokens per second)\n",
      "llama_print_timings:       total time =    1608.13 ms /    39 tokens\n",
      " 57%|█████▋    | 285/500 [19:54<10:13,  2.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /     8 runs   (    0.54 ms per token,  1863.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4124.27 ms /   232 tokens (   17.78 ms per token,    56.25 tokens per second)\n",
      "llama_print_timings:        eval time =     738.24 ms /     7 runs   (  105.46 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    4870.67 ms /   239 tokens\n",
      " 57%|█████▋    | 286/500 [19:58<12:20,  3.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     4 runs   (    0.53 ms per token,  1885.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     788.99 ms /    44 tokens (   17.93 ms per token,    55.77 tokens per second)\n",
      "llama_print_timings:        eval time =     296.20 ms /     3 runs   (   98.73 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    1089.42 ms /    47 tokens\n",
      " 57%|█████▋    | 287/500 [20:00<09:45,  2.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     4 runs   (    0.48 ms per token,  2089.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     718.29 ms /    40 tokens (   17.96 ms per token,    55.69 tokens per second)\n",
      "llama_print_timings:        eval time =     320.59 ms /     3 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    1042.98 ms /    43 tokens\n",
      " 58%|█████▊    | 288/500 [20:01<07:54,  2.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.92 ms /    34 runs   (    0.47 ms per token,  2135.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     684.41 ms /    38 tokens (   18.01 ms per token,    55.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3472.66 ms /    33 runs   (  105.23 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    4192.69 ms /    71 tokens\n",
      " 58%|█████▊    | 289/500 [20:05<09:56,  2.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    11 runs   (    0.54 ms per token,  1858.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3472.34 ms /   195 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =     953.55 ms /    10 runs   (   95.35 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =    4437.71 ms /   205 tokens\n",
      " 58%|█████▊    | 290/500 [20:09<11:35,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    18 runs   (    0.55 ms per token,  1807.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     327.02 ms /    17 tokens (   19.24 ms per token,    51.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1691.29 ms /    17 runs   (   99.49 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    2036.90 ms /    34 tokens\n",
      " 58%|█████▊    | 291/500 [20:11<10:12,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    10 runs   (    0.56 ms per token,  1787.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.38 ms /    20 tokens (   18.57 ms per token,    53.85 tokens per second)\n",
      "llama_print_timings:        eval time =     884.04 ms /     9 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =    1266.11 ms /    29 tokens\n",
      " 58%|█████▊    | 292/500 [20:13<08:25,  2.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.09 ms /    28 runs   (    0.54 ms per token,  1855.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.38 ms /    19 tokens (   18.97 ms per token,    52.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2698.89 ms /    27 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    3089.99 ms /    46 tokens\n",
      " 59%|█████▊    | 293/500 [20:16<09:04,  2.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.69 ms /    38 runs   (    0.52 ms per token,  1929.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.17 ms /    19 tokens (   19.11 ms per token,    52.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3726.83 ms /    37 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    4130.47 ms /    56 tokens\n",
      " 59%|█████▉    | 294/500 [20:20<10:34,  3.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    14 runs   (    0.51 ms per token,  1972.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4726.33 ms /   266 tokens (   17.77 ms per token,    56.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.56 ms /    13 runs   (  104.27 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    6096.32 ms /   279 tokens\n",
      " 59%|█████▉    | 295/500 [20:26<13:37,  3.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /     8 runs   (    0.51 ms per token,  1966.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     778.22 ms /    43 tokens (   18.10 ms per token,    55.25 tokens per second)\n",
      "llama_print_timings:        eval time =     709.46 ms /     7 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1495.71 ms /    50 tokens\n",
      " 59%|█████▉    | 296/500 [20:27<11:00,  3.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     4 runs   (    0.48 ms per token,  2063.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     500.51 ms /    27 tokens (   18.54 ms per token,    53.95 tokens per second)\n",
      "llama_print_timings:        eval time =     278.12 ms /     3 runs   (   92.71 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =     782.15 ms /    30 tokens\n",
      " 59%|█████▉    | 297/500 [20:28<08:28,  2.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.77 ms /    39 runs   (    0.53 ms per token,  1877.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4009.14 ms /   226 tokens (   17.74 ms per token,    56.37 tokens per second)\n",
      "llama_print_timings:        eval time =    3855.44 ms /    38 runs   (  101.46 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    7907.81 ms /   264 tokens\n",
      " 60%|█████▉    | 298/500 [20:36<13:53,  4.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    25 runs   (    0.53 ms per token,  1879.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     547.56 ms /    30 tokens (   18.25 ms per token,    54.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2481.27 ms /    24 runs   (  103.39 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    3055.43 ms /    54 tokens\n",
      " 60%|█████▉    | 299/500 [20:39<12:44,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /     9 runs   (    0.54 ms per token,  1853.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.23 ms /    19 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =     779.37 ms /     8 runs   (   97.42 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    1149.58 ms /    27 tokens\n",
      " 60%|██████    | 300/500 [20:40<10:01,  3.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    23 runs   (    0.53 ms per token,  1893.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.06 ms /    21 tokens (   18.76 ms per token,    53.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2220.60 ms /    22 runs   (  100.94 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    2638.97 ms /    43 tokens\n",
      " 60%|██████    | 301/500 [20:43<09:37,  2.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    10 runs   (    0.57 ms per token,  1765.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4158.62 ms /   233 tokens (   17.85 ms per token,    56.03 tokens per second)\n",
      "llama_print_timings:        eval time =     969.80 ms /     9 runs   (  107.76 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    5139.70 ms /   242 tokens\n",
      " 60%|██████    | 302/500 [20:48<11:47,  3.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      32.05 ms /    63 runs   (    0.51 ms per token,  1965.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.03 ms /    23 tokens (   18.74 ms per token,    53.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6307.05 ms /    62 runs   (  101.73 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    6806.16 ms /    85 tokens\n",
      " 61%|██████    | 303/500 [20:55<14:55,  4.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.48 ms /    65 runs   (    0.52 ms per token,  1941.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     479.59 ms /    26 tokens (   18.45 ms per token,    54.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6663.22 ms /    64 runs   (  104.11 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    7214.19 ms /    90 tokens\n",
      " 61%|██████    | 304/500 [21:02<17:27,  5.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      27.01 ms /    52 runs   (    0.52 ms per token,  1925.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     442.87 ms /    24 tokens (   18.45 ms per token,    54.19 tokens per second)\n",
      "llama_print_timings:        eval time =    5255.69 ms /    51 runs   (  103.05 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    5757.17 ms /    75 tokens\n",
      " 61%|██████    | 305/500 [21:08<17:46,  5.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    17 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     359.95 ms /    19 tokens (   18.95 ms per token,    52.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1562.75 ms /    16 runs   (   97.67 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =    1940.25 ms /    35 tokens\n",
      " 61%|██████    | 306/500 [21:10<14:15,  4.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     5 runs   (    0.56 ms per token,  1792.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5526.12 ms /   309 tokens (   17.88 ms per token,    55.92 tokens per second)\n",
      "llama_print_timings:        eval time =     408.60 ms /     4 runs   (  102.15 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    5939.83 ms /   313 tokens\n",
      " 61%|██████▏   | 307/500 [21:16<15:40,  4.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /     9 runs   (    0.55 ms per token,  1810.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1266.08 ms /    69 tokens (   18.35 ms per token,    54.50 tokens per second)\n",
      "llama_print_timings:        eval time =     825.82 ms /     8 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2101.15 ms /    77 tokens\n",
      " 62%|██████▏   | 308/500 [21:18<12:55,  4.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1866.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     379.83 ms /    20 tokens (   18.99 ms per token,    52.66 tokens per second)\n",
      "llama_print_timings:        eval time =     494.64 ms /     5 runs   (   98.93 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =     880.86 ms /    25 tokens\n",
      " 62%|██████▏   | 309/500 [21:19<09:50,  3.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.75 ms /    49 runs   (    0.55 ms per token,  1831.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.23 ms /    14 tokens (   19.30 ms per token,    51.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5170.46 ms /    48 runs   (  107.72 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    5496.33 ms /    62 tokens\n",
      " 62%|██████▏   | 310/500 [21:24<12:04,  3.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.64 ms /    35 runs   (    0.50 ms per token,  1983.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     467.44 ms /    25 tokens (   18.70 ms per token,    53.48 tokens per second)\n",
      "llama_print_timings:        eval time =    3538.55 ms /    34 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    4043.21 ms /    59 tokens\n",
      " 62%|██████▏   | 311/500 [21:28<12:14,  3.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    12 runs   (    0.56 ms per token,  1800.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4289.08 ms /   242 tokens (   17.72 ms per token,    56.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.13 ms /    11 runs   (  101.92 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    5423.48 ms /   253 tokens\n",
      " 62%|██████▏   | 312/500 [21:34<13:37,  4.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     569.82 ms /    31 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =     612.92 ms /     6 runs   (  102.15 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    1190.18 ms /    37 tokens\n",
      " 63%|██████▎   | 313/500 [21:35<10:36,  3.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     6 runs   (    0.54 ms per token,  1845.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     467.92 ms /    25 tokens (   18.72 ms per token,    53.43 tokens per second)\n",
      "llama_print_timings:        eval time =     495.22 ms /     5 runs   (   99.04 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     969.98 ms /    30 tokens\n",
      " 63%|██████▎   | 314/500 [21:36<08:17,  2.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.24 ms /    28 runs   (    0.51 ms per token,  1966.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.02 ms /    20 tokens (   18.60 ms per token,    53.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2794.97 ms /    27 runs   (  103.52 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    3196.64 ms /    47 tokens\n",
      " 63%|██████▎   | 315/500 [21:39<08:43,  2.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     9 runs   (    0.51 ms per token,  1968.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3818.42 ms /   215 tokens (   17.76 ms per token,    56.31 tokens per second)\n",
      "llama_print_timings:        eval time =     807.34 ms /     8 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    4635.10 ms /   223 tokens\n",
      " 63%|██████▎   | 316/500 [21:44<10:20,  3.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    21 runs   (    0.55 ms per token,  1833.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     568.78 ms /    31 tokens (   18.35 ms per token,    54.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1985.69 ms /    20 runs   (   99.28 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    2577.93 ms /    51 tokens\n",
      " 63%|██████▎   | 317/500 [21:46<09:33,  3.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      35.69 ms /    77 runs   (    0.46 ms per token,  2157.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     537.25 ms /    29 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =    7971.62 ms /    76 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    8590.89 ms /   105 tokens\n",
      " 64%|██████▎   | 318/500 [21:55<14:28,  4.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /     4 runs   (    0.55 ms per token,  1803.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.84 ms /    16 tokens (   18.93 ms per token,    52.83 tokens per second)\n",
      "llama_print_timings:        eval time =     320.42 ms /     3 runs   (  106.81 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =     627.69 ms /    19 tokens\n",
      " 64%|██████▍   | 319/500 [21:55<10:39,  3.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     5 runs   (    0.55 ms per token,  1826.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     473.89 ms /    26 tokens (   18.23 ms per token,    54.86 tokens per second)\n",
      "llama_print_timings:        eval time =     424.68 ms /     4 runs   (  106.17 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =     904.15 ms /    30 tokens\n",
      " 64%|██████▍   | 320/500 [21:56<08:13,  2.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     5 runs   (    0.54 ms per token,  1857.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5888.93 ms /   329 tokens (   17.90 ms per token,    55.87 tokens per second)\n",
      "llama_print_timings:        eval time =     397.07 ms /     4 runs   (   99.27 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    6291.22 ms /   333 tokens\n",
      " 64%|██████▍   | 321/500 [22:03<11:21,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    21 runs   (    0.55 ms per token,  1811.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     477.39 ms /    26 tokens (   18.36 ms per token,    54.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2011.16 ms /    20 runs   (  100.56 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    2512.92 ms /    46 tokens\n",
      " 64%|██████▍   | 322/500 [22:05<10:08,  3.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /     8 runs   (    0.54 ms per token,  1860.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     468.91 ms /    25 tokens (   18.76 ms per token,    53.31 tokens per second)\n",
      "llama_print_timings:        eval time =     701.73 ms /     7 runs   (  100.25 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =    1179.12 ms /    32 tokens\n",
      " 65%|██████▍   | 323/500 [22:06<08:06,  2.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /     8 runs   (    0.54 ms per token,  1842.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4792.18 ms /   269 tokens (   17.81 ms per token,    56.13 tokens per second)\n",
      "llama_print_timings:        eval time =     734.26 ms /     7 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5534.83 ms /   276 tokens\n",
      " 65%|██████▍   | 324/500 [22:12<10:31,  3.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.10 ms /    35 runs   (    0.49 ms per token,  2046.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     467.28 ms /    25 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =    3541.47 ms /    34 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    4047.10 ms /    59 tokens\n",
      " 65%|██████▌   | 325/500 [22:16<10:51,  3.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.80 ms /    29 runs   (    0.51 ms per token,  1959.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.57 ms /    19 tokens (   19.03 ms per token,    52.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2839.33 ms /    28 runs   (  101.40 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    3231.34 ms /    47 tokens\n",
      " 65%|██████▌   | 326/500 [22:19<10:22,  3.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     6 runs   (    0.56 ms per token,  1774.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     548.08 ms /    30 tokens (   18.27 ms per token,    54.74 tokens per second)\n",
      "llama_print_timings:        eval time =     489.67 ms /     5 runs   (   97.93 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =    1044.59 ms /    35 tokens\n",
      " 65%|██████▌   | 327/500 [22:20<08:07,  2.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    18 runs   (    0.53 ms per token,  1897.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     865.50 ms /    48 tokens (   18.03 ms per token,    55.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1761.90 ms /    17 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2647.03 ms /    65 tokens\n",
      " 66%|██████▌   | 328/500 [22:23<07:56,  2.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      45.73 ms /    90 runs   (    0.51 ms per token,  1968.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     754.80 ms /    42 tokens (   17.97 ms per token,    55.64 tokens per second)\n",
      "llama_print_timings:        eval time =    9240.36 ms /    89 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   10097.13 ms /   131 tokens\n",
      " 66%|██████▌   | 329/500 [22:33<14:09,  4.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    18 runs   (    0.48 ms per token,  2070.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     376.38 ms /    20 tokens (   18.82 ms per token,    53.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1779.59 ms /    17 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2174.35 ms /    37 tokens\n",
      " 66%|██████▌   | 330/500 [22:35<11:42,  4.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     6 runs   (    0.58 ms per token,  1739.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     512.99 ms /    28 tokens (   18.32 ms per token,    54.58 tokens per second)\n",
      "llama_print_timings:        eval time =     494.77 ms /     5 runs   (   98.95 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    1015.08 ms /    33 tokens\n",
      " 66%|██████▌   | 331/500 [22:36<09:00,  3.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    26 runs   (    0.50 ms per token,  1987.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3410.91 ms /   192 tokens (   17.77 ms per token,    56.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2584.61 ms /    25 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    6023.78 ms /   217 tokens\n",
      " 66%|██████▋   | 332/500 [22:42<11:19,  4.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     8 runs   (    0.53 ms per token,  1889.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.61 ms /    23 tokens (   18.68 ms per token,    53.54 tokens per second)\n",
      "llama_print_timings:        eval time =     704.70 ms /     7 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1141.88 ms /    30 tokens\n",
      " 67%|██████▋   | 333/500 [22:43<08:50,  3.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    22 runs   (    0.51 ms per token,  1959.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.40 ms /    20 tokens (   18.57 ms per token,    53.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2134.27 ms /    21 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2528.80 ms /    41 tokens\n",
      " 67%|██████▋   | 334/500 [22:46<08:15,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    18 runs   (    0.51 ms per token,  1944.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.53 ms /    20 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1697.87 ms /    17 runs   (   99.87 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    2087.92 ms /    37 tokens\n",
      " 67%|██████▋   | 335/500 [22:48<07:27,  2.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.73 ms /    27 runs   (    0.51 ms per token,  1966.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4253.17 ms /   240 tokens (   17.72 ms per token,    56.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2592.43 ms /    26 runs   (   99.71 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    6873.28 ms /   266 tokens\n",
      " 67%|██████▋   | 336/500 [22:55<10:50,  3.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.02 ms /    29 runs   (    0.52 ms per token,  1930.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     440.11 ms /    24 tokens (   18.34 ms per token,    54.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2846.42 ms /    28 runs   (  101.66 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3319.11 ms /    52 tokens\n",
      " 67%|██████▋   | 337/500 [22:58<10:14,  3.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     6 runs   (    0.53 ms per token,  1877.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     650.56 ms /    36 tokens (   18.07 ms per token,    55.34 tokens per second)\n",
      "llama_print_timings:        eval time =     477.91 ms /     5 runs   (   95.58 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    1134.41 ms /    41 tokens\n",
      " 68%|██████▊   | 338/500 [22:59<08:02,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.27 ms /    26 runs   (    0.55 ms per token,  1822.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.98 ms /    22 tokens (   18.45 ms per token,    54.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2612.18 ms /    25 runs   (  104.49 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    3045.99 ms /    47 tokens\n",
      " 68%|██████▊   | 339/500 [23:02<08:03,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.00 ms /    53 runs   (    0.49 ms per token,  2038.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4585.52 ms /   258 tokens (   17.77 ms per token,    56.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5286.80 ms /    52 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    9928.95 ms /   310 tokens\n",
      " 68%|██████▊   | 340/500 [23:12<13:32,  5.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.42 ms /    64 runs   (    0.52 ms per token,  1915.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.35 ms /    38 tokens (   17.98 ms per token,    55.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6627.26 ms /    63 runs   (  105.19 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    7381.71 ms /   101 tokens\n",
      " 68%|██████▊   | 341/500 [23:20<15:17,  5.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      32.80 ms /    61 runs   (    0.54 ms per token,  1859.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     502.69 ms /    27 tokens (   18.62 ms per token,    53.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6100.09 ms /    60 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    6672.80 ms /    87 tokens\n",
      " 68%|██████▊   | 342/500 [23:26<15:54,  6.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.35 ms /    50 runs   (    0.49 ms per token,  2053.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.84 ms /    23 tokens (   18.78 ms per token,    53.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5053.41 ms /    49 runs   (  103.13 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    5537.48 ms /    72 tokens\n",
      " 69%|██████▊   | 343/500 [23:32<15:25,  5.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    14 runs   (    0.50 ms per token,  1990.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     683.05 ms /    38 tokens (   17.97 ms per token,    55.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1289.64 ms /    13 runs   (   99.20 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =    1986.57 ms /    51 tokens\n",
      " 69%|██████▉   | 344/500 [23:34<12:16,  4.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.65 ms /    51 runs   (    0.50 ms per token,  1988.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.98 ms /    13 tokens (   19.92 ms per token,    50.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5117.44 ms /    50 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    5431.68 ms /    63 tokens\n",
      " 69%|██████▉   | 345/500 [23:39<12:45,  4.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.32 ms /    50 runs   (    0.49 ms per token,  2055.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     430.46 ms /    23 tokens (   18.72 ms per token,    53.43 tokens per second)\n",
      "llama_print_timings:        eval time =    5151.38 ms /    49 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    5633.71 ms /    72 tokens\n",
      " 69%|██████▉   | 346/500 [23:45<13:12,  5.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.86 ms /    45 runs   (    0.51 ms per token,  1968.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.41 ms /    11 tokens (   20.31 ms per token,    49.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4593.70 ms /    44 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    4865.79 ms /    55 tokens\n",
      " 69%|██████▉   | 347/500 [23:50<12:54,  5.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.34 ms /    39 runs   (    0.52 ms per token,  1917.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5622.78 ms /   316 tokens (   17.79 ms per token,    56.20 tokens per second)\n",
      "llama_print_timings:        eval time =    3877.56 ms /    38 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    9542.94 ms /   354 tokens\n",
      " 70%|██████▉   | 348/500 [23:59<16:14,  6.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    11 runs   (    0.57 ms per token,  1763.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     433.37 ms /    23 tokens (   18.84 ms per token,    53.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.12 ms /    10 runs   (  105.41 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =    1500.40 ms /    33 tokens\n",
      " 70%|██████▉   | 349/500 [24:01<12:25,  4.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      45.01 ms /    90 runs   (    0.50 ms per token,  1999.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     478.35 ms /    26 tokens (   18.40 ms per token,    54.35 tokens per second)\n",
      "llama_print_timings:        eval time =    9176.44 ms /    89 runs   (  103.11 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    9754.00 ms /   115 tokens\n",
      " 70%|███████   | 350/500 [24:11<15:57,  6.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /    36 runs   (    0.52 ms per token,  1909.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     398.78 ms /    21 tokens (   18.99 ms per token,    52.66 tokens per second)\n",
      "llama_print_timings:        eval time =    3706.61 ms /    35 runs   (  105.90 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    4144.71 ms /    56 tokens\n",
      " 70%|███████   | 351/500 [24:15<14:11,  5.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      34.85 ms /    68 runs   (    0.51 ms per token,  1951.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     515.31 ms /    28 tokens (   18.40 ms per token,    54.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6816.63 ms /    67 runs   (  101.74 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    7406.43 ms /    95 tokens\n",
      " 70%|███████   | 352/500 [24:22<15:20,  6.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    25 runs   (    0.52 ms per token,  1941.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2993.10 ms /   168 tokens (   17.82 ms per token,    56.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2490.53 ms /    24 runs   (  103.77 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    5510.24 ms /   192 tokens\n",
      " 71%|███████   | 353/500 [24:28<14:43,  6.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    13 runs   (    0.56 ms per token,  1791.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     463.59 ms /    25 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.49 ms /    12 runs   (  103.87 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1724.28 ms /    37 tokens\n",
      " 71%|███████   | 354/500 [24:29<11:29,  4.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     7 runs   (    0.57 ms per token,  1746.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.34 ms /    22 tokens (   18.47 ms per token,    54.14 tokens per second)\n",
      "llama_print_timings:        eval time =     620.02 ms /     6 runs   (  103.34 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1034.91 ms /    28 tokens\n",
      " 71%|███████   | 355/500 [24:30<08:44,  3.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.70 ms /    34 runs   (    0.52 ms per token,  1920.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     369.55 ms /    20 tokens (   18.48 ms per token,    54.12 tokens per second)\n",
      "llama_print_timings:        eval time =    3427.75 ms /    33 runs   (  103.87 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    3833.69 ms /    53 tokens\n",
      " 71%|███████   | 356/500 [24:34<08:50,  3.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1809.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.68 ms /    20 tokens (   18.68 ms per token,    53.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1466.67 ms /    14 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1856.09 ms /    34 tokens\n",
      " 71%|███████▏  | 357/500 [24:36<07:28,  3.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    15 runs   (    0.55 ms per token,  1825.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.88 ms /    22 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1387.31 ms /    14 runs   (   99.09 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    1808.98 ms /    36 tokens\n",
      " 72%|███████▏  | 358/500 [24:38<06:28,  2.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    23 runs   (    0.53 ms per token,  1881.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.97 ms /    13 tokens (   19.69 ms per token,    50.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2324.75 ms /    22 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    2605.90 ms /    35 tokens\n",
      " 72%|███████▏  | 359/500 [24:41<06:20,  2.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    13 runs   (    0.57 ms per token,  1760.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     532.86 ms /    29 tokens (   18.37 ms per token,    54.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.98 ms /    12 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1758.50 ms /    41 tokens\n",
      " 72%|███████▏  | 360/500 [24:42<05:38,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    10 runs   (    0.54 ms per token,  1840.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4427.66 ms /   249 tokens (   17.78 ms per token,    56.24 tokens per second)\n",
      "llama_print_timings:        eval time =     914.37 ms /     9 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    5352.53 ms /   258 tokens\n",
      " 72%|███████▏  | 361/500 [24:48<07:38,  3.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.39 ms /    40 runs   (    0.51 ms per token,  1961.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     429.49 ms /    23 tokens (   18.67 ms per token,    53.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4158.27 ms /    39 runs   (  106.62 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    4631.38 ms /    62 tokens\n",
      " 72%|███████▏  | 362/500 [24:52<08:30,  3.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.70 ms /    23 runs   (    0.55 ms per token,  1811.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     536.25 ms /    29 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2260.56 ms /    22 runs   (  102.75 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    2822.69 ms /    51 tokens\n",
      " 73%|███████▎  | 363/500 [24:55<07:51,  3.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.46 ms /    38 runs   (    0.54 ms per token,  1857.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     479.68 ms /    26 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
      "llama_print_timings:        eval time =    3826.58 ms /    37 runs   (  103.42 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    4348.35 ms /    63 tokens\n",
      " 73%|███████▎  | 364/500 [25:00<08:24,  3.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.64 ms /    47 runs   (    0.52 ms per token,  1907.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.84 ms /    13 tokens (   19.83 ms per token,    50.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4776.22 ms /    46 runs   (  103.83 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    5084.02 ms /    59 tokens\n",
      " 73%|███████▎  | 365/500 [25:05<09:16,  4.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    11 runs   (    0.54 ms per token,  1843.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.01 ms /    31 tokens (   18.39 ms per token,    54.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.34 ms /    10 runs   (  107.43 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    1656.89 ms /    41 tokens\n",
      " 73%|███████▎  | 366/500 [25:06<07:33,  3.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.54 ms /    40 runs   (    0.54 ms per token,  1856.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     752.84 ms /    42 tokens (   17.92 ms per token,    55.79 tokens per second)\n",
      "llama_print_timings:        eval time =    3991.74 ms /    39 runs   (  102.35 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    4789.83 ms /    81 tokens\n",
      " 73%|███████▎  | 367/500 [25:11<08:26,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.10 ms /    33 runs   (    0.49 ms per token,  2049.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     637.73 ms /    35 tokens (   18.22 ms per token,    54.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3292.94 ms /    32 runs   (  102.90 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3965.89 ms /    67 tokens\n",
      " 74%|███████▎  | 368/500 [25:15<08:28,  3.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    25 runs   (    0.55 ms per token,  1819.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5385.30 ms /   302 tokens (   17.83 ms per token,    56.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2466.92 ms /    24 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    7881.24 ms /   326 tokens\n",
      " 74%|███████▍  | 369/500 [25:23<11:03,  5.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     7 runs   (    0.56 ms per token,  1782.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     605.43 ms /    33 tokens (   18.35 ms per token,    54.51 tokens per second)\n",
      "llama_print_timings:        eval time =     590.23 ms /     6 runs   (   98.37 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =    1203.57 ms /    39 tokens\n",
      " 74%|███████▍  | 370/500 [25:24<08:27,  3.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    11 runs   (    0.53 ms per token,  1897.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     304.53 ms /    16 tokens (   19.03 ms per token,    52.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1002.80 ms /    10 runs   (  100.28 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1320.19 ms /    26 tokens\n",
      " 74%|███████▍  | 371/500 [25:25<06:44,  3.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    13 runs   (    0.55 ms per token,  1813.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     754.70 ms /    42 tokens (   17.97 ms per token,    55.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.48 ms /    12 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    1970.18 ms /    54 tokens\n",
      " 74%|███████▍  | 372/500 [25:27<05:56,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.84 ms /    17 runs   (    0.52 ms per token,  1923.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.20 ms /    20 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1692.39 ms /    16 runs   (  105.77 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    2082.83 ms /    36 tokens\n",
      " 75%|███████▍  | 373/500 [25:30<05:26,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    19 runs   (    0.48 ms per token,  2100.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3548.39 ms /   200 tokens (   17.74 ms per token,    56.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1851.21 ms /    18 runs   (  102.85 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    5419.66 ms /   218 tokens\n",
      " 75%|███████▍  | 374/500 [25:35<07:12,  3.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      23.47 ms /    47 runs   (    0.50 ms per token,  2002.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     441.97 ms /    24 tokens (   18.42 ms per token,    54.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4819.29 ms /    46 runs   (  104.77 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    5311.74 ms /    70 tokens\n",
      " 75%|███████▌  | 375/500 [25:40<08:19,  3.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      41.34 ms /    77 runs   (    0.54 ms per token,  1862.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.92 ms /    21 tokens (   18.76 ms per token,    53.31 tokens per second)\n",
      "llama_print_timings:        eval time =    7861.44 ms /    76 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    8342.25 ms /    97 tokens\n",
      " 75%|███████▌  | 376/500 [25:49<10:57,  5.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.69 ms /    60 runs   (    0.51 ms per token,  1954.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.17 ms /    18 tokens (   18.73 ms per token,    53.38 tokens per second)\n",
      "llama_print_timings:        eval time =    6092.40 ms /    59 runs   (  103.26 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    6494.43 ms /    77 tokens\n",
      " 75%|███████▌  | 377/500 [25:55<11:36,  5.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    27 runs   (    0.52 ms per token,  1913.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3292.76 ms /   186 tokens (   17.70 ms per token,    56.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2685.35 ms /    26 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    6006.96 ms /   212 tokens\n",
      " 76%|███████▌  | 378/500 [26:01<11:43,  5.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1906.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     942.74 ms /    52 tokens (   18.13 ms per token,    55.16 tokens per second)\n",
      "llama_print_timings:        eval time =     630.75 ms /     6 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    1579.85 ms /    58 tokens\n",
      " 76%|███████▌  | 379/500 [26:03<09:05,  4.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.69 ms /    54 runs   (    0.53 ms per token,  1882.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.77 ms /    12 tokens (   19.40 ms per token,    51.55 tokens per second)\n",
      "llama_print_timings:        eval time =    5364.09 ms /    53 runs   (  101.21 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    5656.67 ms /    65 tokens\n",
      " 76%|███████▌  | 380/500 [26:08<09:42,  4.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     7 runs   (    0.55 ms per token,  1810.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     739.44 ms /    41 tokens (   18.04 ms per token,    55.45 tokens per second)\n",
      "llama_print_timings:        eval time =     641.57 ms /     6 runs   (  106.93 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    1388.85 ms /    47 tokens\n",
      " 76%|███████▌  | 381/500 [26:10<07:34,  3.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    20 runs   (    0.52 ms per token,  1921.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.76 ms /    18 tokens (   18.60 ms per token,    53.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1874.80 ms /    19 runs   (   98.67 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    2231.63 ms /    37 tokens\n",
      " 76%|███████▋  | 382/500 [26:12<06:34,  3.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /     9 runs   (    0.53 ms per token,  1904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6643.55 ms /   372 tokens (   17.86 ms per token,    55.99 tokens per second)\n",
      "llama_print_timings:        eval time =     772.21 ms /     8 runs   (   96.53 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =    7425.66 ms /   380 tokens\n",
      " 77%|███████▋  | 383/500 [26:19<08:54,  4.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.90 ms /    55 runs   (    0.49 ms per token,  2044.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     756.40 ms /    41 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5699.23 ms /    54 runs   (  105.54 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    6515.07 ms /    95 tokens\n",
      " 77%|███████▋  | 384/500 [26:26<09:57,  5.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /    40 runs   (    0.49 ms per token,  2040.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     623.13 ms /    34 tokens (   18.33 ms per token,    54.56 tokens per second)\n",
      "llama_print_timings:        eval time =    4040.48 ms /    39 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    4706.20 ms /    73 tokens\n",
      " 77%|███████▋  | 385/500 [26:31<09:37,  5.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /     9 runs   (    0.52 ms per token,  1936.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     339.61 ms /    18 tokens (   18.87 ms per token,    53.00 tokens per second)\n",
      "llama_print_timings:        eval time =     790.73 ms /     8 runs   (   98.84 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    1140.65 ms /    26 tokens\n",
      " 77%|███████▋  | 386/500 [26:32<07:19,  3.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    22 runs   (    0.53 ms per token,  1896.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.93 ms /    21 tokens (   18.85 ms per token,    53.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2154.73 ms /    21 runs   (  102.61 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2574.95 ms /    42 tokens\n",
      " 77%|███████▋  | 387/500 [26:34<06:32,  3.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    26 runs   (    0.46 ms per token,  2172.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3189.95 ms /   180 tokens (   17.72 ms per token,    56.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2522.97 ms /    25 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    5738.50 ms /   205 tokens\n",
      " 78%|███████▊  | 388/500 [26:40<07:45,  4.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.05 ms /    20 runs   (    0.50 ms per token,  1990.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     404.95 ms /    22 tokens (   18.41 ms per token,    54.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1978.58 ms /    19 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2405.13 ms /    41 tokens\n",
      " 78%|███████▊  | 389/500 [26:43<06:42,  3.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      39.88 ms /    75 runs   (    0.53 ms per token,  1880.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.31 ms /    15 tokens (   19.42 ms per token,    51.49 tokens per second)\n",
      "llama_print_timings:        eval time =    7578.93 ms /    74 runs   (  102.42 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    7954.70 ms /    89 tokens\n",
      " 78%|███████▊  | 390/500 [26:50<09:02,  4.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.02 ms /    36 runs   (    0.50 ms per token,  1997.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     335.52 ms /    18 tokens (   18.64 ms per token,    53.65 tokens per second)\n",
      "llama_print_timings:        eval time =    3438.14 ms /    35 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =    3810.90 ms /    53 tokens\n",
      " 78%|███████▊  | 391/500 [26:54<08:20,  4.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    11 runs   (    0.51 ms per token,  1974.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     437.53 ms /    24 tokens (   18.23 ms per token,    54.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1043.37 ms /    10 runs   (  104.34 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1491.93 ms /    34 tokens\n",
      " 78%|███████▊  | 392/500 [26:56<06:35,  3.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    27 runs   (    0.52 ms per token,  1923.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4970.10 ms /   279 tokens (   17.81 ms per token,    56.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2666.24 ms /    26 runs   (  102.55 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    7663.76 ms /   305 tokens\n",
      " 79%|███████▊  | 393/500 [27:03<08:40,  4.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    10 runs   (    0.54 ms per token,  1846.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     338.51 ms /    17 tokens (   19.91 ms per token,    50.22 tokens per second)\n",
      "llama_print_timings:        eval time =     876.18 ms /     9 runs   (   97.35 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =    1225.50 ms /    26 tokens\n",
      " 79%|███████▉  | 394/500 [27:05<06:40,  3.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /     8 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     414.14 ms /    22 tokens (   18.82 ms per token,    53.12 tokens per second)\n",
      "llama_print_timings:        eval time =     707.04 ms /     7 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    1128.83 ms /    29 tokens\n",
      " 79%|███████▉  | 395/500 [27:06<05:13,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    27 runs   (    0.52 ms per token,  1908.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.67 ms /    20 tokens (   18.63 ms per token,    53.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2716.00 ms /    26 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    3118.46 ms /    46 tokens\n",
      " 79%|███████▉  | 396/500 [27:09<05:14,  3.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.85 ms /    50 runs   (    0.54 ms per token,  1861.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.54 ms /    15 tokens (   19.44 ms per token,    51.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5175.35 ms /    49 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    5524.20 ms /    64 tokens\n",
      " 79%|███████▉  | 397/500 [27:14<06:28,  3.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.11 ms /    32 runs   (    0.53 ms per token,  1870.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.23 ms /    19 tokens (   19.12 ms per token,    52.31 tokens per second)\n",
      "llama_print_timings:        eval time =    3138.86 ms /    31 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3537.84 ms /    50 tokens\n",
      " 80%|███████▉  | 398/500 [27:18<06:17,  3.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /     8 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.72 ms /    15 tokens (   19.51 ms per token,    51.24 tokens per second)\n",
      "llama_print_timings:        eval time =     743.84 ms /     7 runs   (  106.26 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1045.76 ms /    22 tokens\n",
      " 80%|███████▉  | 399/500 [27:19<04:53,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.81 ms /    35 runs   (    0.51 ms per token,  1965.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     360.75 ms /    19 tokens (   18.99 ms per token,    52.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3561.54 ms /    34 runs   (  104.75 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    3961.12 ms /    53 tokens\n",
      " 80%|████████  | 400/500 [27:23<05:22,  3.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.90 ms /    27 runs   (    0.51 ms per token,  1942.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3435.85 ms /   193 tokens (   17.80 ms per token,    56.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2791.08 ms /    26 runs   (  107.35 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    6254.77 ms /   219 tokens\n",
      " 80%|████████  | 401/500 [27:29<06:49,  4.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     6 runs   (    0.56 ms per token,  1788.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     396.45 ms /    21 tokens (   18.88 ms per token,    52.97 tokens per second)\n",
      "llama_print_timings:        eval time =     518.42 ms /     5 runs   (  103.68 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     921.73 ms /    26 tokens\n",
      " 80%|████████  | 402/500 [27:30<05:10,  3.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     3 runs   (    0.54 ms per token,  1840.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.13 ms /    20 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =     209.94 ms /     2 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =     584.25 ms /    22 tokens\n",
      " 81%|████████  | 403/500 [27:31<03:52,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.30 ms /    47 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.97 ms /    12 tokens (   19.50 ms per token,    51.29 tokens per second)\n",
      "llama_print_timings:        eval time =    4670.33 ms /    46 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    4954.59 ms /    58 tokens\n",
      " 81%|████████  | 404/500 [27:36<05:03,  3.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      36.15 ms /    69 runs   (    0.52 ms per token,  1908.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     237.45 ms /    12 tokens (   19.79 ms per token,    50.54 tokens per second)\n",
      "llama_print_timings:        eval time =    7072.22 ms /    68 runs   (  104.00 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    7385.09 ms /    80 tokens\n",
      " 81%|████████  | 405/500 [27:43<07:00,  4.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    41 runs   (    0.51 ms per token,  1969.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7260.11 ms /   403 tokens (   18.02 ms per token,    55.51 tokens per second)\n",
      "llama_print_timings:        eval time =    4259.71 ms /    40 runs   (  106.49 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   11566.24 ms /   443 tokens\n",
      " 81%|████████  | 406/500 [27:55<10:17,  6.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.11 ms /    32 runs   (    0.50 ms per token,  1986.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     584.68 ms /    32 tokens (   18.27 ms per token,    54.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3141.80 ms /    31 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    3760.83 ms /    63 tokens\n",
      " 81%|████████▏ | 407/500 [27:58<08:52,  5.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      23.06 ms /    45 runs   (    0.51 ms per token,  1951.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     646.25 ms /    35 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4472.59 ms /    44 runs   (  101.65 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    5166.62 ms /    79 tokens\n",
      " 82%|████████▏ | 408/500 [28:04<08:31,  5.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    21 runs   (    0.55 ms per token,  1820.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     469.28 ms /    25 tokens (   18.77 ms per token,    53.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2012.02 ms /    20 runs   (  100.60 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    2504.53 ms /    45 tokens\n",
      " 82%|████████▏ | 409/500 [28:06<07:02,  4.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    26 runs   (    0.51 ms per token,  1946.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     481.10 ms /    26 tokens (   18.50 ms per token,    54.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2721.04 ms /    25 runs   (  108.84 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =    3230.50 ms /    51 tokens\n",
      " 82%|████████▏ | 410/500 [28:09<06:20,  4.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.65 ms /    48 runs   (    0.51 ms per token,  1947.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4077.84 ms /   229 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =    4907.59 ms /    47 runs   (  104.42 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    9038.25 ms /   276 tokens\n",
      " 82%|████████▏ | 411/500 [28:18<08:24,  5.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.22 ms /    38 runs   (    0.53 ms per token,  1879.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     672.38 ms /    37 tokens (   18.17 ms per token,    55.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3819.50 ms /    37 runs   (  103.23 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    4534.04 ms /    74 tokens\n",
      " 82%|████████▏ | 412/500 [28:23<07:48,  5.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.34 ms /    37 runs   (    0.55 ms per token,  1819.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.93 ms /    16 tokens (   19.00 ms per token,    52.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3627.68 ms /    36 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    3972.89 ms /    52 tokens\n",
      " 83%|████████▎ | 413/500 [28:27<07:08,  4.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      27.27 ms /    53 runs   (    0.51 ms per token,  1943.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.17 ms /    16 tokens (   18.95 ms per token,    52.78 tokens per second)\n",
      "llama_print_timings:        eval time =    5369.93 ms /    52 runs   (  103.27 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    5730.86 ms /    68 tokens\n",
      " 83%|████████▎ | 414/500 [28:33<07:24,  5.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    20 runs   (    0.53 ms per token,  1871.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3614.79 ms /   203 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1982.75 ms /    19 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    5620.71 ms /   222 tokens\n",
      " 83%|████████▎ | 415/500 [28:38<07:30,  5.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    26 runs   (    0.52 ms per token,  1919.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     374.44 ms /    20 tokens (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2434.16 ms /    25 runs   (   97.37 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =    2835.67 ms /    45 tokens\n",
      " 83%|████████▎ | 416/500 [28:41<06:23,  4.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    32 runs   (    0.53 ms per token,  1896.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.09 ms /    23 tokens (   18.61 ms per token,    53.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3140.34 ms /    31 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    3603.84 ms /    54 tokens\n",
      " 83%|████████▎ | 417/500 [28:45<05:54,  4.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    32 runs   (    0.53 ms per token,  1899.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     499.47 ms /    27 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3196.97 ms /    31 runs   (  103.13 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    3731.49 ms /    58 tokens\n",
      " 84%|████████▎ | 418/500 [28:48<05:37,  4.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    14 runs   (    0.52 ms per token,  1935.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.81 ms /    12 tokens (   19.57 ms per token,    51.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1322.38 ms /    13 runs   (  101.72 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1571.69 ms /    25 tokens\n",
      " 84%|████████▍ | 419/500 [28:50<04:31,  3.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    18 runs   (    0.53 ms per token,  1886.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.64 ms /    19 tokens (   19.03 ms per token,    52.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1670.86 ms /    17 runs   (   98.29 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =    2052.22 ms /    36 tokens\n",
      " 84%|████████▍ | 420/500 [28:52<03:57,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.48 ms /    20 runs   (    0.52 ms per token,  1908.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.18 ms /    20 tokens (   18.66 ms per token,    53.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.38 ms /    19 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2356.09 ms /    39 tokens\n",
      " 84%|████████▍ | 421/500 [28:54<03:39,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    16 runs   (    0.52 ms per token,  1928.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.39 ms /    13 tokens (   19.88 ms per token,    50.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1526.17 ms /    15 runs   (  101.74 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1801.51 ms /    28 tokens\n",
      " 84%|████████▍ | 422/500 [28:56<03:14,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.44 ms /    24 runs   (    0.48 ms per token,  2098.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.96 ms /    23 tokens (   18.65 ms per token,    53.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2291.51 ms /    23 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    2745.43 ms /    46 tokens\n",
      " 85%|████████▍ | 423/500 [28:59<03:17,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.41 ms /    90 runs   (    0.53 ms per token,  1898.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.04 ms /    22 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    9194.47 ms /    89 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    9702.57 ms /   111 tokens\n",
      " 85%|████████▍ | 424/500 [29:09<05:57,  4.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     7 runs   (    0.54 ms per token,  1848.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4255.68 ms /   239 tokens (   17.81 ms per token,    56.16 tokens per second)\n",
      "llama_print_timings:        eval time =     622.01 ms /     6 runs   (  103.67 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    4885.19 ms /   245 tokens\n",
      " 85%|████████▌ | 425/500 [29:14<05:57,  4.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    27 runs   (    0.49 ms per token,  2028.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.93 ms /    17 tokens (   19.17 ms per token,    52.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2758.76 ms /    26 runs   (  106.11 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    3112.93 ms /    43 tokens\n",
      " 85%|████████▌ | 426/500 [29:17<05:15,  4.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    11 runs   (    0.52 ms per token,  1918.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.33 ms /    14 tokens (   19.17 ms per token,    52.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1011.16 ms /    10 runs   (  101.12 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1290.90 ms /    24 tokens\n",
      " 85%|████████▌ | 427/500 [29:18<04:06,  3.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /     7 runs   (    0.52 ms per token,  1913.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.24 ms /    16 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =     621.70 ms /     6 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     932.25 ms /    22 tokens\n",
      " 86%|████████▌ | 428/500 [29:19<03:10,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    22 runs   (    0.55 ms per token,  1830.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.16 ms /    14 tokens (   19.37 ms per token,    51.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2158.04 ms /    21 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    2454.50 ms /    35 tokens\n",
      " 86%|████████▌ | 429/500 [29:21<03:03,  2.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.79 ms /    40 runs   (    0.52 ms per token,  1923.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5872.44 ms /   327 tokens (   17.96 ms per token,    55.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4005.66 ms /    39 runs   (  102.71 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    9922.41 ms /   366 tokens\n",
      " 86%|████████▌ | 430/500 [29:31<05:35,  4.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.18 ms /    90 runs   (    0.52 ms per token,  1907.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.23 ms /    18 tokens (   18.90 ms per token,    52.91 tokens per second)\n",
      "llama_print_timings:        eval time =    9206.57 ms /    89 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    9648.36 ms /   107 tokens\n",
      " 86%|████████▌ | 431/500 [29:41<07:11,  6.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.37 ms /    36 runs   (    0.54 ms per token,  1858.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.15 ms /    21 tokens (   18.91 ms per token,    52.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3558.91 ms /    35 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    3995.88 ms /    56 tokens\n",
      " 86%|████████▋ | 432/500 [29:45<06:18,  5.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     8 runs   (    0.55 ms per token,  1824.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     513.25 ms /    28 tokens (   18.33 ms per token,    54.55 tokens per second)\n",
      "llama_print_timings:        eval time =     722.68 ms /     7 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    1244.70 ms /    35 tokens\n",
      " 87%|████████▋ | 433/500 [29:46<04:46,  4.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /     8 runs   (    0.55 ms per token,  1812.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     619.13 ms /    34 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =     739.33 ms /     7 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1367.75 ms /    41 tokens\n",
      " 87%|████████▋ | 434/500 [29:48<03:44,  3.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     442.34 ms /    24 tokens (   18.43 ms per token,    54.26 tokens per second)\n",
      "llama_print_timings:        eval time =     489.16 ms /     5 runs   (   97.83 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =     938.21 ms /    29 tokens\n",
      " 87%|████████▋ | 435/500 [29:49<02:53,  2.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.39 ms /    33 runs   (    0.53 ms per token,  1897.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.13 ms /    19 tokens (   19.11 ms per token,    52.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3336.24 ms /    32 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3736.30 ms /    51 tokens\n",
      " 87%|████████▋ | 436/500 [29:52<03:11,  2.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    13 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     894.67 ms /    49 tokens (   18.26 ms per token,    54.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.45 ms /    12 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    2133.84 ms /    61 tokens\n",
      " 87%|████████▋ | 437/500 [29:54<02:52,  2.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    10 runs   (    0.54 ms per token,  1853.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     470.87 ms /    25 tokens (   18.83 ms per token,    53.09 tokens per second)\n",
      "llama_print_timings:        eval time =     939.40 ms /     9 runs   (  104.38 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    1421.25 ms /    34 tokens\n",
      " 88%|████████▊ | 438/500 [29:56<02:25,  2.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      44.79 ms /    90 runs   (    0.50 ms per token,  2009.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4081.51 ms /   229 tokens (   17.82 ms per token,    56.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9324.25 ms /    89 runs   (  104.77 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =   13505.13 ms /   318 tokens\n",
      " 88%|████████▊ | 439/500 [30:09<05:47,  5.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.83 ms /    32 runs   (    0.53 ms per token,  1901.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     336.99 ms /    18 tokens (   18.72 ms per token,    53.41 tokens per second)\n",
      "llama_print_timings:        eval time =    3287.20 ms /    31 runs   (  106.04 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    3657.69 ms /    49 tokens\n",
      " 88%|████████▊ | 440/500 [30:13<05:04,  5.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      48.37 ms /    90 runs   (    0.54 ms per token,  1860.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     396.66 ms /    20 tokens (   19.83 ms per token,    50.42 tokens per second)\n",
      "llama_print_timings:        eval time =    9035.32 ms /    89 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    9533.17 ms /   109 tokens\n",
      " 88%|████████▊ | 441/500 [30:23<06:18,  6.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.10 ms /    33 runs   (    0.52 ms per token,  1929.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     406.92 ms /    22 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3432.31 ms /    32 runs   (  107.26 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    3875.71 ms /    54 tokens\n",
      " 88%|████████▊ | 442/500 [30:26<05:28,  5.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    25 runs   (    0.53 ms per token,  1903.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.71 ms /    20 tokens (   18.59 ms per token,    53.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2534.78 ms /    24 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2933.13 ms /    44 tokens\n",
      " 89%|████████▊ | 443/500 [30:29<04:35,  4.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    18 runs   (    0.53 ms per token,  1870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4818.85 ms /   267 tokens (   18.05 ms per token,    55.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1678.30 ms /    17 runs   (   98.72 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    6516.44 ms /   284 tokens\n",
      " 89%|████████▉ | 444/500 [30:36<04:59,  5.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    20 runs   (    0.54 ms per token,  1860.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     337.63 ms /    18 tokens (   18.76 ms per token,    53.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1919.75 ms /    19 runs   (  101.04 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =    2280.03 ms /    37 tokens\n",
      " 89%|████████▉ | 445/500 [30:38<04:03,  4.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    23 runs   (    0.54 ms per token,  1856.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.46 ms /    16 tokens (   18.97 ms per token,    52.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2224.38 ms /    22 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    2553.47 ms /    38 tokens\n",
      " 89%|████████▉ | 446/500 [30:41<03:28,  3.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    10 runs   (    0.55 ms per token,  1827.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.54 ms /    25 tokens (   18.62 ms per token,    53.70 tokens per second)\n",
      "llama_print_timings:        eval time =     903.04 ms /     9 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1379.20 ms /    34 tokens\n",
      " 89%|████████▉ | 447/500 [30:42<02:45,  3.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.50 ms /    37 runs   (    0.55 ms per token,  1804.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3558.76 ms /   197 tokens (   18.06 ms per token,    55.36 tokens per second)\n",
      "llama_print_timings:        eval time =    3709.24 ms /    36 runs   (  103.03 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    7310.33 ms /   233 tokens\n",
      " 90%|████████▉ | 448/500 [30:49<03:47,  4.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    11 runs   (    0.54 ms per token,  1844.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.58 ms /    21 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_print_timings:        eval time =     982.32 ms /    10 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =    1391.68 ms /    31 tokens\n",
      " 90%|████████▉ | 449/500 [30:51<02:57,  3.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.31 ms /    28 runs   (    0.55 ms per token,  1829.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.34 ms /    15 tokens (   19.42 ms per token,    51.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2794.54 ms /    27 runs   (  103.50 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    3117.39 ms /    42 tokens\n",
      " 90%|█████████ | 450/500 [30:54<02:48,  3.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      37.77 ms /    71 runs   (    0.53 ms per token,  1879.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     578.64 ms /    32 tokens (   18.08 ms per token,    55.30 tokens per second)\n",
      "llama_print_timings:        eval time =    7109.70 ms /    70 runs   (  101.57 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    7767.56 ms /   102 tokens\n",
      " 90%|█████████ | 451/500 [31:02<03:49,  4.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.70 ms /    28 runs   (    0.53 ms per token,  1904.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.09 ms /    21 tokens (   18.91 ms per token,    52.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2745.50 ms /    27 runs   (  101.69 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    3172.69 ms /    48 tokens\n",
      " 90%|█████████ | 452/500 [31:05<03:23,  4.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    15 runs   (    0.54 ms per token,  1859.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     301.39 ms /    16 tokens (   18.84 ms per token,    53.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1384.66 ms /    14 runs   (   98.90 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    1701.91 ms /    30 tokens\n",
      " 91%|█████████ | 453/500 [31:07<02:43,  3.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    12 runs   (    0.49 ms per token,  2024.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     636.68 ms /    35 tokens (   18.19 ms per token,    54.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.00 ms /    11 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1764.25 ms /    46 tokens\n",
      " 91%|█████████ | 454/500 [31:08<02:16,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    15 runs   (    0.56 ms per token,  1770.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     510.27 ms /    28 tokens (   18.22 ms per token,    54.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1385.76 ms /    14 runs   (   98.98 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    1912.18 ms /    42 tokens\n",
      " 91%|█████████ | 455/500 [31:10<01:59,  2.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    18 runs   (    0.55 ms per token,  1812.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     859.48 ms /    48 tokens (   17.91 ms per token,    55.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1838.11 ms /    17 runs   (  108.12 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =    2716.82 ms /    65 tokens\n",
      " 91%|█████████ | 456/500 [31:13<01:57,  2.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.88 ms /    27 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     535.58 ms /    29 tokens (   18.47 ms per token,    54.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2664.41 ms /    26 runs   (  102.48 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    3228.38 ms /    55 tokens\n",
      " 91%|█████████▏| 457/500 [31:16<02:02,  2.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    27 runs   (    0.53 ms per token,  1888.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6215.62 ms /   348 tokens (   17.86 ms per token,    55.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2515.64 ms /    26 runs   (   96.76 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    8760.54 ms /   374 tokens\n",
      " 92%|█████████▏| 458/500 [31:25<03:13,  4.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    14 runs   (    0.54 ms per token,  1852.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     437.67 ms /    24 tokens (   18.24 ms per token,    54.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.55 ms /    13 runs   (   98.43 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    1731.74 ms /    37 tokens\n",
      " 92%|█████████▏| 459/500 [31:27<02:33,  3.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    22 runs   (    0.53 ms per token,  1889.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     404.71 ms /    22 tokens (   18.40 ms per token,    54.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2158.25 ms /    21 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    2585.67 ms /    43 tokens\n",
      " 92%|█████████▏| 460/500 [31:29<02:16,  3.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    10 runs   (    0.54 ms per token,  1848.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     475.30 ms /    26 tokens (   18.28 ms per token,    54.70 tokens per second)\n",
      "llama_print_timings:        eval time =     893.26 ms /     9 runs   (   99.25 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =    1379.79 ms /    35 tokens\n",
      " 92%|█████████▏| 461/500 [31:31<01:49,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    17 runs   (    0.46 ms per token,  2180.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     404.63 ms /    22 tokens (   18.39 ms per token,    54.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1599.40 ms /    16 runs   (   99.96 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    2021.18 ms /    38 tokens\n",
      " 92%|█████████▏| 462/500 [31:33<01:37,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    12 runs   (    0.53 ms per token,  1885.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4320.01 ms /   243 tokens (   17.78 ms per token,    56.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.69 ms /    11 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5487.00 ms /   254 tokens\n",
      " 93%|█████████▎| 463/500 [31:38<02:07,  3.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.75 ms /    30 runs   (    0.52 ms per token,  1904.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     441.19 ms /    24 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2971.04 ms /    29 runs   (  102.45 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    3444.94 ms /    53 tokens\n",
      " 93%|█████████▎| 464/500 [31:42<02:03,  3.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.26 ms /    39 runs   (    0.49 ms per token,  2024.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     410.00 ms /    22 tokens (   18.64 ms per token,    53.66 tokens per second)\n",
      "llama_print_timings:        eval time =    3909.53 ms /    38 runs   (  102.88 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    4361.44 ms /    60 tokens\n",
      " 93%|█████████▎| 465/500 [31:46<02:10,  3.72s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.78 ms /    36 runs   (    0.55 ms per token,  1819.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     604.74 ms /    33 tokens (   18.33 ms per token,    54.57 tokens per second)\n",
      "llama_print_timings:        eval time =    3562.00 ms /    35 runs   (  101.77 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    4208.63 ms /    68 tokens\n",
      " 93%|█████████▎| 466/500 [31:50<02:11,  3.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    15 runs   (    0.54 ms per token,  1836.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     474.82 ms /    26 tokens (   18.26 ms per token,    54.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1419.05 ms /    14 runs   (  101.36 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    1911.56 ms /    40 tokens\n",
      " 93%|█████████▎| 467/500 [31:52<01:48,  3.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    24 runs   (    0.52 ms per token,  1932.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4831.98 ms /   271 tokens (   17.83 ms per token,    56.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2408.59 ms /    23 runs   (  104.72 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    7267.70 ms /   294 tokens\n",
      " 94%|█████████▎| 468/500 [31:59<02:23,  4.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    31 runs   (    0.50 ms per token,  1990.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     480.63 ms /    26 tokens (   18.49 ms per token,    54.10 tokens per second)\n",
      "llama_print_timings:        eval time =    3175.03 ms /    30 runs   (  105.83 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    3688.86 ms /    56 tokens\n",
      " 94%|█████████▍| 469/500 [32:03<02:11,  4.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    17 runs   (    0.49 ms per token,  2045.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.98 ms /    14 tokens (   19.21 ms per token,    52.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1581.47 ms /    16 runs   (   98.84 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    1867.49 ms /    30 tokens\n",
      " 94%|█████████▍| 470/500 [32:05<01:45,  3.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    26 runs   (    0.54 ms per token,  1862.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     306.55 ms /    16 tokens (   19.16 ms per token,    52.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2528.51 ms /    25 runs   (  101.14 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    2861.78 ms /    41 tokens\n",
      " 94%|█████████▍| 471/500 [32:08<01:36,  3.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.73 ms /    39 runs   (    0.51 ms per token,  1976.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     510.60 ms /    28 tokens (   18.24 ms per token,    54.84 tokens per second)\n",
      "llama_print_timings:        eval time =    3894.66 ms /    38 runs   (  102.49 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    4446.65 ms /    66 tokens\n",
      " 94%|█████████▍| 472/500 [32:12<01:42,  3.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    24 runs   (    0.53 ms per token,  1894.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5769.28 ms /   322 tokens (   17.92 ms per token,    55.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2406.70 ms /    23 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    8202.31 ms /   345 tokens\n",
      " 95%|█████████▍| 473/500 [32:20<02:15,  5.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.96 ms /    29 runs   (    0.52 ms per token,  1937.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.38 ms /    21 tokens (   18.92 ms per token,    52.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2888.11 ms /    28 runs   (  103.15 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    3316.20 ms /    49 tokens\n",
      " 95%|█████████▍| 474/500 [32:24<01:57,  4.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    37 runs   (    0.54 ms per token,  1864.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.37 ms /    12 tokens (   19.61 ms per token,    50.98 tokens per second)\n",
      "llama_print_timings:        eval time =    3705.88 ms /    36 runs   (  102.94 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    3982.33 ms /    48 tokens\n",
      " 95%|█████████▌| 475/500 [32:28<01:48,  4.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.61 ms /    38 runs   (    0.52 ms per token,  1938.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     640.25 ms /    35 tokens (   18.29 ms per token,    54.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3788.12 ms /    37 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    4470.27 ms /    72 tokens\n",
      " 95%|█████████▌| 476/500 [32:32<01:45,  4.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    32 runs   (    0.52 ms per token,  1931.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3611.44 ms /   203 tokens (   17.79 ms per token,    56.21 tokens per second)\n",
      "llama_print_timings:        eval time =    3120.44 ms /    31 runs   (  100.66 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    6767.20 ms /   234 tokens\n",
      " 95%|█████████▌| 477/500 [32:39<01:57,  5.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    21 runs   (    0.50 ms per token,  1984.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     439.36 ms /    24 tokens (   18.31 ms per token,    54.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2042.34 ms /    20 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    2503.52 ms /    44 tokens\n",
      " 96%|█████████▌| 478/500 [32:42<01:35,  4.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     7 runs   (    0.53 ms per token,  1873.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.54 ms /    16 tokens (   18.97 ms per token,    52.71 tokens per second)\n",
      "llama_print_timings:        eval time =     640.69 ms /     6 runs   (  106.78 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =     951.24 ms /    22 tokens\n",
      " 96%|█████████▌| 479/500 [32:42<01:09,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     5 runs   (    0.55 ms per token,  1820.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     533.09 ms /    29 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =     405.18 ms /     4 runs   (  101.29 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =     942.75 ms /    33 tokens\n",
      " 96%|█████████▌| 480/500 [32:43<00:52,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    14 runs   (    0.53 ms per token,  1880.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     498.55 ms /    27 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1320.56 ms /    13 runs   (  101.58 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1833.79 ms /    40 tokens\n",
      " 96%|█████████▌| 481/500 [32:45<00:45,  2.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    17 runs   (    0.50 ms per token,  2013.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5764.39 ms /   322 tokens (   17.90 ms per token,    55.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1712.75 ms /    16 runs   (  107.05 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    7495.08 ms /   338 tokens\n",
      " 96%|█████████▋| 482/500 [32:53<01:10,  3.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    20 runs   (    0.51 ms per token,  1958.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     309.91 ms /    16 tokens (   19.37 ms per token,    51.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2016.43 ms /    19 runs   (  106.13 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    2347.88 ms /    35 tokens\n",
      " 97%|█████████▋| 483/500 [32:55<00:58,  3.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    17 runs   (    0.49 ms per token,  2044.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.35 ms /     9 tokens (   21.15 ms per token,    47.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1680.83 ms /    16 runs   (  105.05 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1889.64 ms /    25 tokens\n",
      " 97%|█████████▋| 484/500 [32:57<00:47,  2.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    21 runs   (    0.49 ms per token,  2023.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     330.07 ms /    17 tokens (   19.42 ms per token,    51.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1934.37 ms /    20 runs   (   96.72 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    2286.89 ms /    37 tokens\n",
      " 97%|█████████▋| 485/500 [32:59<00:41,  2.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    18 runs   (    0.51 ms per token,  1947.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     294.15 ms /    15 tokens (   19.61 ms per token,    50.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1751.73 ms /    17 runs   (  103.04 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    2065.59 ms /    32 tokens\n",
      " 97%|█████████▋| 486/500 [33:01<00:35,  2.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.52 ms /    19 runs   (    0.55 ms per token,  1806.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3590.67 ms /   201 tokens (   17.86 ms per token,    55.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1848.32 ms /    18 runs   (  102.68 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    5460.28 ms /   219 tokens\n",
      " 97%|█████████▋| 487/500 [33:07<00:44,  3.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.91 ms /    55 runs   (    0.53 ms per token,  1902.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     671.71 ms /    37 tokens (   18.15 ms per token,    55.08 tokens per second)\n",
      "llama_print_timings:        eval time =    5548.18 ms /    54 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    6279.53 ms /    91 tokens\n",
      " 98%|█████████▊| 488/500 [33:13<00:51,  4.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    32 runs   (    0.54 ms per token,  1850.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     468.35 ms /    23 tokens (   20.36 ms per token,    49.11 tokens per second)\n",
      "llama_print_timings:        eval time =    3597.38 ms /    31 runs   (  116.04 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =    4101.33 ms /    54 tokens\n",
      " 98%|█████████▊| 489/500 [33:17<00:46,  4.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    26 runs   (    0.52 ms per token,  1924.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     491.40 ms /    26 tokens (   18.90 ms per token,    52.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2670.12 ms /    25 runs   (  106.80 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    3191.46 ms /    51 tokens\n",
      " 98%|█████████▊| 490/500 [33:20<00:39,  3.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    17 runs   (    0.56 ms per token,  1789.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     380.21 ms /    20 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1679.17 ms /    16 runs   (  104.95 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2078.11 ms /    36 tokens\n",
      " 98%|█████████▊| 491/500 [33:22<00:30,  3.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     5 runs   (    0.51 ms per token,  1973.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3743.69 ms /   190 tokens (   19.70 ms per token,    50.75 tokens per second)\n",
      "llama_print_timings:        eval time =     393.32 ms /     4 runs   (   98.33 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =    4141.98 ms /   194 tokens\n",
      " 98%|█████████▊| 492/500 [33:27<00:28,  3.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     5 runs   (    0.51 ms per token,  1969.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.15 ms /     9 tokens (   22.02 ms per token,    45.42 tokens per second)\n",
      "llama_print_timings:        eval time =     401.93 ms /     4 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =     605.40 ms /    13 tokens\n",
      " 99%|█████████▊| 493/500 [33:27<00:18,  2.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     8 runs   (    0.51 ms per token,  1973.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     358.48 ms /    18 tokens (   19.92 ms per token,    50.21 tokens per second)\n",
      "llama_print_timings:        eval time =     691.36 ms /     7 runs   (   98.77 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    1057.87 ms /    25 tokens\n",
      " 99%|█████████▉| 494/500 [33:28<00:13,  2.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     5 runs   (    0.49 ms per token,  2021.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.81 ms /    20 tokens (   19.59 ms per token,    51.05 tokens per second)\n",
      "llama_print_timings:        eval time =     409.33 ms /     4 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =     806.36 ms /    24 tokens\n",
      " 99%|█████████▉| 495/500 [33:29<00:08,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.75 ms /    24 runs   (    0.53 ms per token,  1882.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4993.86 ms /   254 tokens (   19.66 ms per token,    50.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2416.58 ms /    23 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    7437.09 ms /   277 tokens\n",
      " 99%|█████████▉| 496/500 [33:37<00:13,  3.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      47.58 ms /    88 runs   (    0.54 ms per token,  1849.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     370.24 ms /    19 tokens (   19.49 ms per token,    51.32 tokens per second)\n",
      "llama_print_timings:        eval time =    9480.75 ms /    87 runs   (  108.97 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =    9951.36 ms /   106 tokens\n",
      " 99%|█████████▉| 497/500 [33:47<00:16,  5.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.30 ms /    29 runs   (    0.53 ms per token,  1895.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.03 ms /    14 tokens (   20.14 ms per token,    49.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2921.09 ms /    28 runs   (  104.32 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3234.91 ms /    42 tokens\n",
      "100%|█████████▉| 498/500 [33:50<00:09,  4.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.91 ms /    30 runs   (    0.53 ms per token,  1885.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     477.91 ms /    25 tokens (   19.12 ms per token,    52.31 tokens per second)\n",
      "llama_print_timings:        eval time =    3007.51 ms /    29 runs   (  103.71 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    3517.84 ms /    54 tokens\n",
      "100%|█████████▉| 499/500 [33:53<00:04,  4.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.62 ms /    35 runs   (    0.53 ms per token,  1879.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     449.24 ms /    23 tokens (   19.53 ms per token,    51.20 tokens per second)\n",
      "llama_print_timings:        eval time =    3686.85 ms /    34 runs   (  108.44 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    4173.68 ms /    57 tokens\n",
      "100%|██████████| 500/500 [33:57<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time_sberquad = time.time()\n",
    "\n",
    "cnt = BENCHES_SIZE\n",
    "questions_sberquad, predicted_sberquad, context_sberquad = get_relevant_ans(benchmarks_df['sberquad'], reader, cnt, True)\n",
    "targets_sberquad = benchmarks_df['sberquad']['answer'].to_list()[:cnt]\n",
    "\n",
    "time_execute_sberquad = time.time() - start_time_sberquad\n",
    "\n",
    "q_and_a_sberquad = {\n",
    "    'question': questions_sberquad,\n",
    "    'predicted_answer': predicted_sberquad,\n",
    "    'target': targets_sberquad,\n",
    "    'context': context_sberquad\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>чем представлены органические остатки?</td>\n",
       "      <td>Органические остатки в протерозойских отложени...</td>\n",
       "      <td>известковыми выделениями сине-зелёных водорослей</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>что найдено в кремнистых сланцах железорудной ...</td>\n",
       "      <td>Нитевидные водоросли, грибные нити и формы, бл...</td>\n",
       "      <td>нитевидные водоросли, грибные нити</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>что встречается в протерозойских отложениях?</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "      <td>органические остатки</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что относится к числу древнейших растительных ...</td>\n",
       "      <td>Скопления графито-углистого вещества, образова...</td>\n",
       "      <td>скопления графито-углистого вещества</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>как образовалось графито-углистое вещество?</td>\n",
       "      <td>Образование графито-углистого вещества в Проте...</td>\n",
       "      <td>в результате разложения Corycium enigmaticum</td>\n",
       "      <td>В протерозойских отложениях органические остат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Куда поступают остатки непереваренной пищи?</td>\n",
       "      <td>Остатки непереваренной пищи поступают в толсты...</td>\n",
       "      <td>в толстый кишечник</td>\n",
       "      <td>Кишечник млекопитающего подразделяется на тонк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Каким процессам подвергается непереваренная пи...</td>\n",
       "      <td>Бродильным процессам с участием эндосимбионтов...</td>\n",
       "      <td>бродильным процессам с участием эндосимбионтов</td>\n",
       "      <td>Кишечник млекопитающего подразделяется на тонк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>В каком кишечнике переваривается основная част...</td>\n",
       "      <td>Основная часть пищи переваривается в тонком ки...</td>\n",
       "      <td>в тонком кишечнике</td>\n",
       "      <td>Кишечник млекопитающего подразделяется на тонк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Какие виды анатомических сегментов выделяют в ...</td>\n",
       "      <td>У млекопитающих выделяют 4 анатомических сегме...</td>\n",
       "      <td>тонкий и толстый</td>\n",
       "      <td>Кишечник млекопитающего подразделяется на тонк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Для каких видов млекопитающих особо важна слеп...</td>\n",
       "      <td>Слепая кишка играет особенно важную роль у вид...</td>\n",
       "      <td>Для видов, кормящихся грубой растительной пищей</td>\n",
       "      <td>Кишечник млекопитающего подразделяется на тонк...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0             чем представлены органические остатки?   \n",
       "1  что найдено в кремнистых сланцах железорудной ...   \n",
       "2       что встречается в протерозойских отложениях?   \n",
       "3  что относится к числу древнейших растительных ...   \n",
       "4        как образовалось графито-углистое вещество?   \n",
       "5        Куда поступают остатки непереваренной пищи?   \n",
       "6  Каким процессам подвергается непереваренная пи...   \n",
       "7  В каком кишечнике переваривается основная част...   \n",
       "8  Какие виды анатомических сегментов выделяют в ...   \n",
       "9  Для каких видов млекопитающих особо важна слеп...   \n",
       "\n",
       "                                    predicted_answer  \\\n",
       "0  Органические остатки в протерозойских отложени...   \n",
       "1  Нитевидные водоросли, грибные нити и формы, бл...   \n",
       "2  В протерозойских отложениях органические остат...   \n",
       "3  Скопления графито-углистого вещества, образова...   \n",
       "4  Образование графито-углистого вещества в Проте...   \n",
       "5  Остатки непереваренной пищи поступают в толсты...   \n",
       "6  Бродильным процессам с участием эндосимбионтов...   \n",
       "7  Основная часть пищи переваривается в тонком ки...   \n",
       "8  У млекопитающих выделяют 4 анатомических сегме...   \n",
       "9  Слепая кишка играет особенно важную роль у вид...   \n",
       "\n",
       "                                             target  \\\n",
       "0  известковыми выделениями сине-зелёных водорослей   \n",
       "1                нитевидные водоросли, грибные нити   \n",
       "2                              органические остатки   \n",
       "3              скопления графито-углистого вещества   \n",
       "4      в результате разложения Corycium enigmaticum   \n",
       "5                                в толстый кишечник   \n",
       "6    бродильным процессам с участием эндосимбионтов   \n",
       "7                                в тонком кишечнике   \n",
       "8                                  тонкий и толстый   \n",
       "9   Для видов, кормящихся грубой растительной пищей   \n",
       "\n",
       "                                             context  \n",
       "0  В протерозойских отложениях органические остат...  \n",
       "1  В протерозойских отложениях органические остат...  \n",
       "2  В протерозойских отложениях органические остат...  \n",
       "3  В протерозойских отложениях органические остат...  \n",
       "4  В протерозойских отложениях органические остат...  \n",
       "5  Кишечник млекопитающего подразделяется на тонк...  \n",
       "6  Кишечник млекопитающего подразделяется на тонк...  \n",
       "7  Кишечник млекопитающего подразделяется на тонк...  \n",
       "8  Кишечник млекопитающего подразделяется на тонк...  \n",
       "9  Кишечник млекопитающего подразделяется на тонк...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sberquad = pd.DataFrame(q_and_a_sberquad)\n",
    "df_sberquad.to_csv(SAVE_CSVFILE_1)\n",
    "df_sberquad.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### squadv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      36.62 ms /    69 runs   (    0.53 ms per token,  1883.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     349.94 ms /    18 tokens (   19.44 ms per token,    51.44 tokens per second)\n",
      "llama_print_timings:        eval time =    7237.98 ms /    68 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    7669.36 ms /    86 tokens\n",
      "  0%|          | 1/500 [00:07<1:03:47,  7.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    21 runs   (    0.52 ms per token,  1917.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     350.23 ms /    18 tokens (   19.46 ms per token,    51.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2193.24 ms /    20 runs   (  109.66 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =    2565.89 ms /    38 tokens\n",
      "  0%|          | 2/500 [00:10<38:45,  4.67s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.85 ms /    34 runs   (    0.52 ms per token,  1904.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     358.54 ms /    19 tokens (   18.87 ms per token,    52.99 tokens per second)\n",
      "llama_print_timings:        eval time =    3603.47 ms /    33 runs   (  109.20 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    3998.71 ms /    52 tokens\n",
      "  1%|          | 3/500 [00:14<36:09,  4.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    11 runs   (    0.52 ms per token,  1914.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.09 ms /    18 tokens (   19.62 ms per token,    50.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.90 ms /    10 runs   (  112.19 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    1486.40 ms /    28 tokens\n",
      "  1%|          | 4/500 [00:15<26:41,  3.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     7 runs   (    0.52 ms per token,  1935.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.99 ms /    13 tokens (   20.23 ms per token,    49.43 tokens per second)\n",
      "llama_print_timings:        eval time =     602.37 ms /     6 runs   (  100.39 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =     871.92 ms /    19 tokens\n",
      "  1%|          | 5/500 [00:16<19:38,  2.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1928.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     301.78 ms /    15 tokens (   20.12 ms per token,    49.70 tokens per second)\n",
      "llama_print_timings:        eval time =     367.16 ms /     3 runs   (  122.39 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =     673.29 ms /    18 tokens\n",
      "  1%|          | 6/500 [00:17<14:49,  1.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    16 runs   (    0.51 ms per token,  1960.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.73 ms /    14 tokens (   19.84 ms per token,    50.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1603.42 ms /    15 runs   (  106.89 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =    1898.26 ms /    29 tokens\n",
      "  1%|▏         | 7/500 [00:19<15:03,  1.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     6 runs   (    0.51 ms per token,  1965.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.81 ms /    13 tokens (   20.22 ms per token,    49.47 tokens per second)\n",
      "llama_print_timings:        eval time =     507.79 ms /     5 runs   (  101.56 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =     776.58 ms /    18 tokens\n",
      "  2%|▏         | 8/500 [00:19<12:16,  1.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.44 ms /    58 runs   (    0.52 ms per token,  1905.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.68 ms /    13 tokens (   20.51 ms per token,    48.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6063.44 ms /    57 runs   (  106.38 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    6394.17 ms /    70 tokens\n",
      "  2%|▏         | 9/500 [00:26<24:47,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    19 runs   (    0.52 ms per token,  1940.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     328.36 ms /    16 tokens (   20.52 ms per token,    48.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1986.65 ms /    18 runs   (  110.37 ms per token,     9.06 tokens per second)\n",
      "llama_print_timings:       total time =    2334.80 ms /    34 tokens\n",
      "  2%|▏         | 10/500 [00:28<22:59,  2.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    23 runs   (    0.51 ms per token,  1979.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     343.54 ms /    17 tokens (   20.21 ms per token,    49.48 tokens per second)\n",
      "llama_print_timings:        eval time =    2415.35 ms /    22 runs   (  109.79 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =    2783.31 ms /    39 tokens\n",
      "  2%|▏         | 11/500 [00:31<22:52,  2.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    20 runs   (    0.51 ms per token,  1948.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     308.84 ms /    15 tokens (   20.59 ms per token,    48.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2044.95 ms /    19 runs   (  107.63 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    2374.99 ms /    34 tokens\n",
      "  2%|▏         | 12/500 [00:33<21:45,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    19 runs   (    0.52 ms per token,  1925.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.65 ms /    19 tokens (   19.03 ms per token,    52.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1894.98 ms /    18 runs   (  105.28 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2277.29 ms /    37 tokens\n",
      "  3%|▎         | 13/500 [00:36<20:44,  2.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    13 runs   (    0.51 ms per token,  1954.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.08 ms /    16 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.24 ms /    12 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    1555.59 ms /    28 tokens\n",
      "  3%|▎         | 14/500 [00:37<18:15,  2.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    17 runs   (    0.51 ms per token,  1956.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.72 ms /    15 tokens (   19.25 ms per token,    51.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1664.06 ms /    16 runs   (  104.00 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1970.86 ms /    31 tokens\n",
      "  3%|▎         | 15/500 [00:39<17:32,  2.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.45 ms /    30 runs   (    0.52 ms per token,  1941.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     369.25 ms /    20 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2994.48 ms /    29 runs   (  103.26 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    3395.10 ms /    49 tokens\n",
      "  3%|▎         | 16/500 [00:43<20:29,  2.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1928.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.58 ms /    12 tokens (   19.21 ms per token,    52.04 tokens per second)\n",
      "llama_print_timings:        eval time =     285.02 ms /     3 runs   (   95.01 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =     519.30 ms /    15 tokens\n",
      "  3%|▎         | 17/500 [00:43<15:33,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    10 runs   (    0.52 ms per token,  1909.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.67 ms /    20 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =     922.88 ms /     9 runs   (  102.54 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1300.51 ms /    29 tokens\n",
      "  4%|▎         | 18/500 [00:44<14:00,  1.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.80 ms /    19 runs   (    0.52 ms per token,  1938.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.28 ms /    19 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1833.32 ms /    18 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    2209.82 ms /    37 tokens\n",
      "  4%|▍         | 19/500 [00:47<15:06,  1.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      32.11 ms /    61 runs   (    0.53 ms per token,  1899.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     403.48 ms /    22 tokens (   18.34 ms per token,    54.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6307.80 ms /    60 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    6779.22 ms /    82 tokens\n",
      "  4%|▍         | 20/500 [00:53<26:50,  3.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    24 runs   (    0.52 ms per token,  1928.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     301.66 ms /    16 tokens (   18.85 ms per token,    53.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2381.50 ms /    23 runs   (  103.54 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2708.53 ms /    39 tokens\n",
      "  4%|▍         | 21/500 [00:56<25:14,  3.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    30 runs   (    0.52 ms per token,  1933.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.66 ms /    21 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2909.37 ms /    29 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    3329.77 ms /    50 tokens\n",
      "  4%|▍         | 22/500 [00:59<25:35,  3.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    12 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.76 ms /    15 tokens (   19.18 ms per token,    52.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.79 ms /    11 runs   (  102.34 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1425.62 ms /    26 tokens\n",
      "  5%|▍         | 23/500 [01:01<21:17,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    16 runs   (    0.50 ms per token,  1982.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.46 ms /    17 tokens (   18.97 ms per token,    52.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1492.49 ms /    15 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    1832.07 ms /    32 tokens\n",
      "  5%|▍         | 24/500 [01:03<19:13,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.35 ms /    30 runs   (    0.51 ms per token,  1954.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.70 ms /    17 tokens (   18.92 ms per token,    52.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2924.48 ms /    29 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    3278.77 ms /    46 tokens\n",
      "  5%|▌         | 25/500 [01:06<21:13,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1942.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.97 ms /    12 tokens (   19.33 ms per token,    51.73 tokens per second)\n",
      "llama_print_timings:        eval time =     286.37 ms /     3 runs   (   95.46 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =     522.26 ms /    15 tokens\n",
      "  5%|▌         | 26/500 [01:06<16:04,  2.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1934.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     324.78 ms /    17 tokens (   19.10 ms per token,    52.34 tokens per second)\n",
      "llama_print_timings:        eval time =     491.08 ms /     5 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =     821.85 ms /    22 tokens\n",
      "  5%|▌         | 27/500 [01:07<13:10,  1.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      29.59 ms /    57 runs   (    0.52 ms per token,  1926.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.92 ms /    17 tokens (   19.00 ms per token,    52.64 tokens per second)\n",
      "llama_print_timings:        eval time =    5826.27 ms /    56 runs   (  104.04 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    6210.98 ms /    73 tokens\n",
      "  6%|▌         | 28/500 [01:14<23:51,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1942.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.99 ms /    21 tokens (   18.67 ms per token,    53.57 tokens per second)\n",
      "llama_print_timings:        eval time =     278.19 ms /     3 runs   (   92.73 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =     673.62 ms /    24 tokens\n",
      "  6%|▌         | 29/500 [01:14<18:15,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     5 runs   (    0.51 ms per token,  1954.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.00 ms /    15 tokens (   19.27 ms per token,    51.90 tokens per second)\n",
      "llama_print_timings:        eval time =     381.05 ms /     4 runs   (   95.26 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =     674.51 ms /    19 tokens\n",
      "  6%|▌         | 30/500 [01:15<14:20,  1.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    23 runs   (    0.52 ms per token,  1941.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     460.59 ms /    25 tokens (   18.42 ms per token,    54.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2265.11 ms /    22 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    2750.51 ms /    47 tokens\n",
      "  6%|▌         | 31/500 [01:18<16:28,  2.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     4 runs   (    0.53 ms per token,  1885.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.54 ms /    21 tokens (   18.60 ms per token,    53.77 tokens per second)\n",
      "llama_print_timings:        eval time =     307.13 ms /     3 runs   (  102.38 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =     701.26 ms /    24 tokens\n",
      "  6%|▋         | 32/500 [01:18<13:09,  1.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.88 ms /    58 runs   (    0.53 ms per token,  1878.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.59 ms /    15 tokens (   19.17 ms per token,    52.16 tokens per second)\n",
      "llama_print_timings:        eval time =    5852.39 ms /    57 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    6203.57 ms /    72 tokens\n",
      "  7%|▋         | 33/500 [01:25<23:40,  3.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.72 ms /    27 runs   (    0.51 ms per token,  1967.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.84 ms /    24 tokens (   18.12 ms per token,    55.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2576.39 ms /    26 runs   (   99.09 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    3039.63 ms /    50 tokens\n",
      "  7%|▋         | 34/500 [01:28<23:37,  3.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    23 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.43 ms /    19 tokens (   18.71 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2259.44 ms /    22 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    2638.86 ms /    41 tokens\n",
      "  7%|▋         | 35/500 [01:30<22:38,  2.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    13 runs   (    0.52 ms per token,  1913.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.25 ms /    16 tokens (   18.64 ms per token,    53.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1240.59 ms /    12 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1552.71 ms /    28 tokens\n",
      "  7%|▋         | 36/500 [01:32<19:25,  2.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    21 runs   (    0.53 ms per token,  1896.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.73 ms /    23 tokens (   18.42 ms per token,    54.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2040.65 ms /    20 runs   (  102.03 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    2486.57 ms /    43 tokens\n",
      "  7%|▋         | 37/500 [01:34<19:19,  2.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    11 runs   (    0.51 ms per token,  1964.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.31 ms /    14 tokens (   18.88 ms per token,    52.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1075.89 ms /    10 runs   (  107.59 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    1351.60 ms /    24 tokens\n",
      "  8%|▊         | 38/500 [01:36<16:37,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1903.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.22 ms /    21 tokens (   18.53 ms per token,    53.95 tokens per second)\n",
      "llama_print_timings:        eval time =     401.72 ms /     4 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =     795.83 ms /    25 tokens\n",
      "  8%|▊         | 39/500 [01:36<13:27,  1.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    24 runs   (    0.53 ms per token,  1900.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.10 ms /    19 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2278.87 ms /    23 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    2659.50 ms /    42 tokens\n",
      "  8%|▊         | 40/500 [01:39<15:31,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      31.99 ms /    63 runs   (    0.51 ms per token,  1969.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.15 ms /    14 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =    6258.79 ms /    62 runs   (  100.95 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    6592.12 ms /    76 tokens\n",
      "  8%|▊         | 41/500 [01:46<25:58,  3.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    16 runs   (    0.50 ms per token,  1983.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    13 tokens (   19.54 ms per token,    51.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1516.82 ms /    15 runs   (  101.12 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1787.35 ms /    28 tokens\n",
      "  8%|▊         | 42/500 [01:47<22:14,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.52 ms per token,  1906.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.30 ms /    16 tokens (   18.71 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =     292.56 ms /     3 runs   (   97.52 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     595.75 ms /    19 tokens\n",
      "  9%|▊         | 43/500 [01:48<16:54,  2.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1916.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.20 ms /    15 tokens (   19.15 ms per token,    52.23 tokens per second)\n",
      "llama_print_timings:        eval time =     415.07 ms /     4 runs   (  103.77 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     707.63 ms /    19 tokens\n",
      "  9%|▉         | 44/500 [01:49<13:25,  1.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    21 runs   (    0.51 ms per token,  1945.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.10 ms /    11 tokens (   20.10 ms per token,    49.75 tokens per second)\n",
      "llama_print_timings:        eval time =    2093.17 ms /    20 runs   (  104.66 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2336.28 ms /    31 tokens\n",
      "  9%|▉         | 45/500 [01:51<14:41,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     6 runs   (    0.53 ms per token,  1902.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.47 ms /    18 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =     485.79 ms /     5 runs   (   97.16 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =     825.07 ms /    23 tokens\n",
      "  9%|▉         | 46/500 [01:52<12:08,  1.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     5 runs   (    0.53 ms per token,  1891.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.23 ms /    18 tokens (   18.51 ms per token,    54.02 tokens per second)\n",
      "llama_print_timings:        eval time =     371.60 ms /     4 runs   (   92.90 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     710.47 ms /    22 tokens\n",
      "  9%|▉         | 47/500 [01:53<10:05,  1.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.74 ms /    17 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.17 ms /    20 tokens (   18.31 ms per token,    54.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1622.29 ms /    16 runs   (  101.39 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    2005.28 ms /    36 tokens\n",
      " 10%|▉         | 48/500 [01:55<11:35,  1.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    21 runs   (    0.50 ms per token,  1985.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.48 ms /    18 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2013.37 ms /    20 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    2368.41 ms /    38 tokens\n",
      " 10%|▉         | 49/500 [01:57<13:26,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.66 ms /    15 tokens (   19.24 ms per token,    51.96 tokens per second)\n",
      "llama_print_timings:        eval time =     485.76 ms /     5 runs   (   97.15 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =     779.96 ms /    20 tokens\n",
      " 10%|█         | 50/500 [01:58<11:08,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /     8 runs   (    0.53 ms per token,  1903.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.84 ms /    17 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_print_timings:        eval time =     705.75 ms /     7 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1036.51 ms /    24 tokens\n",
      " 10%|█         | 51/500 [01:59<10:06,  1.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     3 runs   (    0.52 ms per token,  1937.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.61 ms /    11 tokens (   19.96 ms per token,    50.09 tokens per second)\n",
      "llama_print_timings:        eval time =     190.64 ms /     2 runs   (   95.32 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     413.34 ms /    13 tokens\n",
      " 10%|█         | 52/500 [01:59<07:59,  1.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    12 runs   (    0.51 ms per token,  1950.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.94 ms /    15 tokens (   19.26 ms per token,    51.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.29 ms /    11 runs   (  109.84 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    1508.85 ms /    26 tokens\n",
      " 11%|█         | 53/500 [02:01<08:57,  1.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.58 ms /    49 runs   (    0.52 ms per token,  1915.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.54 ms /    18 tokens (   18.53 ms per token,    53.97 tokens per second)\n",
      "llama_print_timings:        eval time =    4855.82 ms /    48 runs   (  101.16 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    5243.71 ms /    66 tokens\n",
      " 11%|█         | 54/500 [02:06<17:57,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    19 runs   (    0.52 ms per token,  1927.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     365.97 ms /    20 tokens (   18.30 ms per token,    54.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1763.73 ms /    18 runs   (   97.99 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =    2149.52 ms /    38 tokens\n",
      " 11%|█         | 55/500 [02:08<17:19,  2.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    23 runs   (    0.52 ms per token,  1941.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.80 ms /    16 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2283.30 ms /    22 runs   (  103.79 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2608.26 ms /    38 tokens\n",
      " 11%|█         | 56/500 [02:11<17:54,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.38 ms /    22 runs   (    0.52 ms per token,  1933.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.24 ms /    22 tokens (   18.24 ms per token,    54.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2209.99 ms /    21 runs   (  105.24 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2633.74 ms /    43 tokens\n",
      " 11%|█▏        | 57/500 [02:13<18:20,  2.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    11 runs   (    0.51 ms per token,  1968.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     276.28 ms /    14 tokens (   19.73 ms per token,    50.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1044.56 ms /    10 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    1331.60 ms /    24 tokens\n",
      " 12%|█▏        | 58/500 [02:15<15:45,  2.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    11 runs   (    0.53 ms per token,  1878.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     373.77 ms /    20 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.55 ms /    10 runs   (  110.95 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =    1494.82 ms /    30 tokens\n",
      " 12%|█▏        | 59/500 [02:16<14:18,  1.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     3 runs   (    0.51 ms per token,  1956.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.09 ms /    16 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =     207.39 ms /     2 runs   (  103.69 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     509.33 ms /    18 tokens\n",
      " 12%|█▏        | 60/500 [02:17<11:07,  1.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.86 ms /    16 tokens (   18.68 ms per token,    53.54 tokens per second)\n",
      "llama_print_timings:        eval time =     371.81 ms /     4 runs   (   92.95 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     675.61 ms /    20 tokens\n",
      " 12%|█▏        | 61/500 [02:17<09:15,  1.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.37 ms /    22 runs   (    0.52 ms per token,  1935.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.48 ms /    18 tokens (   18.47 ms per token,    54.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2199.89 ms /    21 runs   (  104.76 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2556.94 ms /    39 tokens\n",
      " 12%|█▏        | 62/500 [02:20<12:03,  1.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    16 runs   (    0.52 ms per token,  1926.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.33 ms /    16 tokens (   18.77 ms per token,    53.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1536.97 ms /    15 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    1853.86 ms /    31 tokens\n",
      " 13%|█▎        | 63/500 [02:22<12:29,  1.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.49 ms /    30 runs   (    0.52 ms per token,  1937.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     368.02 ms /    20 tokens (   18.40 ms per token,    54.34 tokens per second)\n",
      "llama_print_timings:        eval time =    2903.40 ms /    29 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    3303.12 ms /    49 tokens\n",
      " 13%|█▎        | 64/500 [02:25<15:55,  2.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    18 runs   (    0.51 ms per token,  1971.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.26 ms /    19 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1743.03 ms /    17 runs   (  102.53 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2118.30 ms /    36 tokens\n",
      " 13%|█▎        | 65/500 [02:27<15:43,  2.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    17 runs   (    0.50 ms per token,  1992.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.64 ms /    19 tokens (   18.77 ms per token,    53.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1588.25 ms /    16 runs   (   99.27 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    1963.23 ms /    35 tokens\n",
      " 13%|█▎        | 66/500 [02:29<15:15,  2.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.58 ms /    30 runs   (    0.52 ms per token,  1925.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.95 ms /    18 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2846.32 ms /    29 runs   (   98.15 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    3212.62 ms /    47 tokens\n",
      " 13%|█▎        | 67/500 [02:32<17:36,  2.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    29 runs   (    0.52 ms per token,  1918.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.52 ms /    21 tokens (   18.60 ms per token,    53.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2917.26 ms /    28 runs   (  104.19 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    3338.07 ms /    49 tokens\n",
      " 14%|█▎        | 68/500 [02:36<19:30,  2.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     5 runs   (    0.51 ms per token,  1944.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.99 ms /    18 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =     384.48 ms /     4 runs   (   96.12 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =     722.03 ms /    22 tokens\n",
      " 14%|█▍        | 69/500 [02:37<15:11,  2.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1913.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.33 ms /    18 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =     404.23 ms /     4 runs   (  101.06 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =     741.57 ms /    22 tokens\n",
      " 14%|█▍        | 70/500 [02:37<12:12,  1.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.11 ms /    39 runs   (    0.52 ms per token,  1939.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.64 ms /    17 tokens (   18.92 ms per token,    52.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3861.79 ms /    38 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    4225.15 ms /    55 tokens\n",
      " 14%|█▍        | 71/500 [02:42<17:35,  2.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.70 ms /    41 runs   (    0.50 ms per token,  1980.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.78 ms /    19 tokens (   18.73 ms per token,    53.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4113.30 ms /    40 runs   (  102.83 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    4511.33 ms /    59 tokens\n",
      " 14%|█▍        | 72/500 [02:46<21:56,  3.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    19 runs   (    0.48 ms per token,  2079.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.22 ms /    20 tokens (   18.36 ms per token,    54.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1851.43 ms /    18 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    2237.06 ms /    38 tokens\n",
      " 15%|█▍        | 73/500 [02:48<20:06,  2.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    17 runs   (    0.52 ms per token,  1940.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.05 ms /    15 tokens (   19.27 ms per token,    51.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1710.19 ms /    16 runs   (  106.89 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    2017.20 ms /    31 tokens\n",
      " 15%|█▍        | 74/500 [02:50<18:20,  2.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.35 ms /    39 runs   (    0.52 ms per token,  1916.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.92 ms /    16 tokens (   18.75 ms per token,    53.35 tokens per second)\n",
      "llama_print_timings:        eval time =    3964.63 ms /    38 runs   (  104.33 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    4307.56 ms /    54 tokens\n",
      " 15%|█▌        | 75/500 [02:55<21:58,  3.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    17 runs   (    0.49 ms per token,  2034.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.06 ms /    19 tokens (   18.74 ms per token,    53.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1716.28 ms /    16 runs   (  107.27 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    2090.13 ms /    35 tokens\n",
      " 15%|█▌        | 76/500 [02:57<19:46,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.92 ms /    36 runs   (    0.50 ms per token,  2008.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.00 ms /    16 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3524.90 ms /    35 runs   (  100.71 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    3861.33 ms /    51 tokens\n",
      " 15%|█▌        | 77/500 [03:01<21:58,  3.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.26 ms /    33 runs   (    0.52 ms per token,  1912.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     459.89 ms /    25 tokens (   18.40 ms per token,    54.36 tokens per second)\n",
      "llama_print_timings:        eval time =    3251.45 ms /    32 runs   (  101.61 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    3746.54 ms /    57 tokens\n",
      " 16%|█▌        | 78/500 [03:04<23:15,  3.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    26 runs   (    0.53 ms per token,  1888.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.00 ms /    19 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2549.72 ms /    25 runs   (  101.99 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    2933.30 ms /    44 tokens\n",
      " 16%|█▌        | 79/500 [03:07<22:25,  3.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     3 runs   (    0.52 ms per token,  1926.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.37 ms /    21 tokens (   18.59 ms per token,    53.79 tokens per second)\n",
      "llama_print_timings:        eval time =     214.61 ms /     2 runs   (  107.31 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =     607.90 ms /    23 tokens\n",
      " 16%|█▌        | 80/500 [03:08<16:56,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.39 ms /    37 runs   (    0.50 ms per token,  2012.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     398.35 ms /    22 tokens (   18.11 ms per token,    55.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3821.51 ms /    36 runs   (  106.15 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    4258.53 ms /    58 tokens\n",
      " 16%|█▌        | 81/500 [03:12<20:45,  2.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.09 ms /    27 runs   (    0.52 ms per token,  1916.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.51 ms /    23 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2579.82 ms /    26 runs   (   99.22 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =    3032.76 ms /    49 tokens\n",
      " 16%|█▋        | 82/500 [03:15<20:50,  2.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    27 runs   (    0.52 ms per token,  1914.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.20 ms /    20 tokens (   18.31 ms per token,    54.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2716.91 ms /    26 runs   (  104.50 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    3111.40 ms /    46 tokens\n",
      " 17%|█▋        | 83/500 [03:18<21:02,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.45 ms /    28 runs   (    0.52 ms per token,  1937.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     415.15 ms /    22 tokens (   18.87 ms per token,    52.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2849.53 ms /    27 runs   (  105.54 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    3294.10 ms /    49 tokens\n",
      " 17%|█▋        | 84/500 [03:22<21:33,  3.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.22 ms /    41 runs   (    0.52 ms per token,  1931.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.51 ms /    15 tokens (   19.43 ms per token,    51.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4057.68 ms /    40 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    4392.92 ms /    55 tokens\n",
      " 17%|█▋        | 85/500 [03:26<24:10,  3.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.97 ms /    28 runs   (    0.50 ms per token,  2004.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     403.73 ms /    22 tokens (   18.35 ms per token,    54.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2766.46 ms /    27 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    3198.61 ms /    49 tokens\n",
      " 17%|█▋        | 86/500 [03:29<23:30,  3.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.94 ms /    22 runs   (    0.50 ms per token,  2010.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.19 ms /    16 tokens (   18.70 ms per token,    53.48 tokens per second)\n",
      "llama_print_timings:        eval time =    2061.48 ms /    21 runs   (   98.17 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    2382.72 ms /    37 tokens\n",
      " 17%|█▋        | 87/500 [03:32<21:20,  3.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    19 runs   (    0.51 ms per token,  1967.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.71 ms /    15 tokens (   19.18 ms per token,    52.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1864.02 ms /    18 runs   (  103.56 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2171.46 ms /    33 tokens\n",
      " 18%|█▊        | 88/500 [03:34<19:22,  2.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    25 runs   (    0.52 ms per token,  1926.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.41 ms /    22 tokens (   18.25 ms per token,    54.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2453.72 ms /    24 runs   (  102.24 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    2881.96 ms /    46 tokens\n",
      " 18%|█▊        | 89/500 [03:37<19:27,  2.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    24 runs   (    0.53 ms per token,  1899.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.26 ms /    15 tokens (   19.28 ms per token,    51.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2316.89 ms /    23 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    2630.73 ms /    38 tokens\n",
      " 18%|█▊        | 90/500 [03:39<18:59,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1925.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.28 ms /    13 tokens (   19.56 ms per token,    51.12 tokens per second)\n",
      "llama_print_timings:        eval time =     303.30 ms /     3 runs   (  101.10 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =     561.66 ms /    16 tokens\n",
      " 18%|█▊        | 91/500 [03:40<14:24,  2.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.83 ms /    23 runs   (    0.51 ms per token,  1944.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    13 tokens (   19.57 ms per token,    51.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2207.34 ms /    22 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2486.08 ms /    35 tokens\n",
      " 18%|█▊        | 92/500 [03:42<15:08,  2.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      40.54 ms /    77 runs   (    0.53 ms per token,  1899.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.19 ms /    13 tokens (   19.55 ms per token,    51.14 tokens per second)\n",
      "llama_print_timings:        eval time =    7955.20 ms /    76 runs   (  104.67 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    8294.46 ms /    89 tokens\n",
      " 19%|█▊        | 93/500 [03:51<27:27,  4.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      31.92 ms /    60 runs   (    0.53 ms per token,  1879.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.34 ms /    12 tokens (   19.19 ms per token,    52.10 tokens per second)\n",
      "llama_print_timings:        eval time =    6137.99 ms /    59 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    6434.20 ms /    71 tokens\n",
      " 19%|█▉        | 94/500 [03:57<32:14,  4.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.20 ms /    15 tokens (   19.28 ms per token,    51.87 tokens per second)\n",
      "llama_print_timings:        eval time =     309.73 ms /     3 runs   (  103.24 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =     602.48 ms /    18 tokens\n",
      " 19%|█▉        | 95/500 [03:58<23:44,  3.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.34 ms /    24 runs   (    0.51 ms per token,  1944.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.31 ms /    16 tokens (   18.71 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2342.55 ms /    23 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    2666.47 ms /    39 tokens\n",
      " 19%|█▉        | 96/500 [04:00<21:57,  3.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    16 runs   (    0.53 ms per token,  1892.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.28 ms /    18 tokens (   18.46 ms per token,    54.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1510.96 ms /    15 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1860.31 ms /    33 tokens\n",
      " 19%|█▉        | 97/500 [04:02<19:05,  2.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    19 runs   (    0.51 ms per token,  1957.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.94 ms /    21 tokens (   18.57 ms per token,    53.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1748.18 ms /    18 runs   (   97.12 ms per token,    10.30 tokens per second)\n",
      "llama_print_timings:       total time =    2158.40 ms /    39 tokens\n",
      " 20%|█▉        | 98/500 [04:04<17:40,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1924.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.62 ms /    15 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =     289.72 ms /     3 runs   (   96.57 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     581.96 ms /    18 tokens\n",
      " 20%|█▉        | 99/500 [04:05<13:30,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1951.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.63 ms /    18 tokens (   18.48 ms per token,    54.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1413.01 ms /    14 runs   (  100.93 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1760.46 ms /    32 tokens\n",
      " 20%|██        | 100/500 [04:07<12:57,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.27 ms /    35 runs   (    0.52 ms per token,  1916.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.34 ms /    21 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3496.50 ms /    34 runs   (  102.84 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3924.64 ms /    55 tokens\n",
      " 20%|██        | 101/500 [04:11<16:53,  2.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.04 ms /    27 runs   (    0.52 ms per token,  1922.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.82 ms /    19 tokens (   18.67 ms per token,    53.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2798.05 ms /    26 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    3182.25 ms /    45 tokens\n",
      " 20%|██        | 102/500 [04:14<18:07,  2.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    21 runs   (    0.51 ms per token,  1946.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.78 ms /    19 tokens (   19.15 ms per token,    52.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2166.63 ms /    20 runs   (  108.33 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =    2552.56 ms /    39 tokens\n",
      " 21%|██        | 103/500 [04:16<17:43,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    21 runs   (    0.51 ms per token,  1944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.30 ms /    24 tokens (   18.14 ms per token,    55.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2111.26 ms /    20 runs   (  105.56 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2568.96 ms /    44 tokens\n",
      " 21%|██        | 104/500 [04:19<17:28,  2.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    25 runs   (    0.52 ms per token,  1923.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.13 ms /    17 tokens (   20.01 ms per token,    49.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2605.82 ms /    24 runs   (  108.58 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    2972.31 ms /    41 tokens\n",
      " 21%|██        | 105/500 [04:22<18:04,  2.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /     8 runs   (    0.51 ms per token,  1946.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.88 ms /    19 tokens (   18.68 ms per token,    53.54 tokens per second)\n",
      "llama_print_timings:        eval time =     744.14 ms /     7 runs   (  106.31 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    1106.40 ms /    26 tokens\n",
      " 21%|██        | 106/500 [04:23<14:48,  2.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    23 runs   (    0.52 ms per token,  1919.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.17 ms /    21 tokens (   18.63 ms per token,    53.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2312.43 ms /    22 runs   (  105.11 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2727.35 ms /    43 tokens\n",
      " 21%|██▏       | 107/500 [04:26<15:42,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    13 runs   (    0.51 ms per token,  1954.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.37 ms /    16 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.32 ms /    12 runs   (   95.53 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =    1459.50 ms /    28 tokens\n",
      " 22%|██▏       | 108/500 [04:27<13:49,  2.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /     9 runs   (    0.51 ms per token,  1974.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.77 ms /    12 tokens (   19.23 ms per token,    52.00 tokens per second)\n",
      "llama_print_timings:        eval time =     826.65 ms /     8 runs   (  103.33 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1066.22 ms /    20 tokens\n",
      " 22%|██▏       | 109/500 [04:28<11:44,  1.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    13 runs   (    0.51 ms per token,  1970.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.35 ms /    14 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.67 ms /    12 runs   (  100.06 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    1479.28 ms /    26 tokens\n",
      " 22%|██▏       | 110/500 [04:30<11:05,  1.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     4 runs   (    0.54 ms per token,  1845.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.94 ms /    22 tokens (   18.27 ms per token,    54.74 tokens per second)\n",
      "llama_print_timings:        eval time =     293.34 ms /     3 runs   (   97.78 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =     699.74 ms /    25 tokens\n",
      " 22%|██▏       | 111/500 [04:30<09:06,  1.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    29 runs   (    0.52 ms per token,  1939.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.52 ms /    23 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2971.45 ms /    28 runs   (  106.12 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    3426.83 ms /    51 tokens\n",
      " 22%|██▏       | 112/500 [04:34<13:00,  2.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    15 runs   (    0.52 ms per token,  1921.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.55 ms /    19 tokens (   18.77 ms per token,    53.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1399.90 ms /    14 runs   (   99.99 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    1772.51 ms /    33 tokens\n",
      " 23%|██▎       | 113/500 [04:36<12:31,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.47 ms /    38 runs   (    0.51 ms per token,  1951.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     437.22 ms /    24 tokens (   18.22 ms per token,    54.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3821.73 ms /    37 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    4299.00 ms /    61 tokens\n",
      " 23%|██▎       | 114/500 [04:40<17:02,  2.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.95 ms /    66 runs   (    0.51 ms per token,  1943.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     338.11 ms /    17 tokens (   19.89 ms per token,    50.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6843.78 ms /    65 runs   (  105.29 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    7253.84 ms /    82 tokens\n",
      " 23%|██▎       | 115/500 [04:47<25:53,  4.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    20 runs   (    0.53 ms per token,  1902.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.64 ms /    16 tokens (   18.79 ms per token,    53.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1976.29 ms /    19 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2298.23 ms /    35 tokens\n",
      " 23%|██▎       | 116/500 [04:49<22:29,  3.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.98 ms /    27 runs   (    0.52 ms per token,  1931.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     301.22 ms /    16 tokens (   18.83 ms per token,    53.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2564.97 ms /    26 runs   (   98.65 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =    2893.81 ms /    42 tokens\n",
      " 23%|██▎       | 117/500 [04:52<21:14,  3.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    25 runs   (    0.53 ms per token,  1903.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.62 ms /    20 tokens (   18.33 ms per token,    54.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2434.86 ms /    24 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    2827.49 ms /    44 tokens\n",
      " 24%|██▎       | 118/500 [04:55<20:14,  3.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    24 runs   (    0.52 ms per token,  1928.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.21 ms /    17 tokens (   18.89 ms per token,    52.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2318.76 ms /    23 runs   (  100.82 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    2666.03 ms /    40 tokens\n",
      " 24%|██▍       | 119/500 [04:58<19:12,  3.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      38.14 ms /    73 runs   (    0.52 ms per token,  1914.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.64 ms /    21 tokens (   18.74 ms per token,    53.35 tokens per second)\n",
      "llama_print_timings:        eval time =    7714.51 ms /    72 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    8189.07 ms /    93 tokens\n",
      " 24%|██▍       | 120/500 [05:06<28:58,  4.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.37 ms /    22 runs   (    0.52 ms per token,  1934.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.49 ms /    20 tokens (   18.37 ms per token,    54.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2288.89 ms /    21 runs   (  108.99 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =    2679.97 ms /    41 tokens\n",
      " 24%|██▍       | 121/500 [05:09<25:18,  4.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1893.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.84 ms /    18 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =     592.44 ms /     6 runs   (   98.74 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =     932.91 ms /    24 tokens\n",
      " 24%|██▍       | 122/500 [05:10<19:26,  3.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.53 ms per token,  1870.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     436.54 ms /    24 tokens (   18.19 ms per token,    54.98 tokens per second)\n",
      "llama_print_timings:        eval time =     549.03 ms /     5 runs   (  109.81 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =     991.18 ms /    29 tokens\n",
      " 25%|██▍       | 123/500 [05:11<15:26,  2.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.30 ms /    26 runs   (    0.51 ms per token,  1954.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     471.88 ms /    26 tokens (   18.15 ms per token,    55.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2574.65 ms /    25 runs   (  102.99 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    3073.33 ms /    51 tokens\n",
      " 25%|██▍       | 124/500 [05:14<16:33,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.94 ms /    34 runs   (    0.53 ms per token,  1894.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.00 ms /    20 tokens (   18.30 ms per token,    54.65 tokens per second)\n",
      "llama_print_timings:        eval time =    3397.84 ms /    33 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    3801.21 ms /    53 tokens\n",
      " 25%|██▌       | 125/500 [05:18<18:41,  2.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.99 ms /    39 runs   (    0.51 ms per token,  1951.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.09 ms /    22 tokens (   18.23 ms per token,    54.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3853.79 ms /    38 runs   (  101.42 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    4295.55 ms /    60 tokens\n",
      " 25%|██▌       | 126/500 [05:22<21:05,  3.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1902.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.20 ms /    17 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =     562.69 ms /     6 runs   (   93.78 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =     892.48 ms /    23 tokens\n",
      " 25%|██▌       | 127/500 [05:23<16:23,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /    31 runs   (    0.52 ms per token,  1912.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.73 ms /    21 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3062.20 ms /    30 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    3484.46 ms /    51 tokens\n",
      " 26%|██▌       | 128/500 [05:26<17:55,  2.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.08 ms /    17 tokens (   18.95 ms per token,    52.78 tokens per second)\n",
      "llama_print_timings:        eval time =     477.77 ms /     5 runs   (   95.55 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     805.66 ms /    22 tokens\n",
      " 26%|██▌       | 129/500 [05:27<14:00,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     3 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.08 ms /    16 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =     181.75 ms /     2 runs   (   90.87 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =     483.79 ms /    18 tokens\n",
      " 26%|██▌       | 130/500 [05:28<10:40,  1.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    13 runs   (    0.52 ms per token,  1925.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     462.92 ms /    25 tokens (   18.52 ms per token,    54.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.03 ms /    12 runs   (   98.75 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    1662.23 ms /    37 tokens\n",
      " 26%|██▌       | 131/500 [05:29<10:31,  1.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1888.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.01 ms /    17 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time =     590.69 ms /     6 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =     920.36 ms /    23 tokens\n",
      " 26%|██▋       | 132/500 [05:30<09:02,  1.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    21 runs   (    0.50 ms per token,  2001.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.87 ms /    24 tokens (   18.12 ms per token,    55.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1990.31 ms /    20 runs   (   99.52 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    2446.47 ms /    44 tokens\n",
      " 27%|██▋       | 133/500 [05:33<10:48,  1.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     6 runs   (    0.53 ms per token,  1888.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.03 ms /    19 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =     490.38 ms /     5 runs   (   98.08 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =     852.73 ms /    24 tokens\n",
      " 27%|██▋       | 134/500 [05:33<09:06,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.55 ms /    42 runs   (    0.54 ms per token,  1862.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.19 ms /    17 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =    4190.43 ms /    41 runs   (  102.21 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    4558.72 ms /    58 tokens\n",
      " 27%|██▋       | 135/500 [05:38<14:41,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    24 runs   (    0.51 ms per token,  1950.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.23 ms /    15 tokens (   19.15 ms per token,    52.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2312.51 ms /    23 runs   (  100.54 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    2624.49 ms /    38 tokens\n",
      " 27%|██▋       | 136/500 [05:41<15:01,  2.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.52 ms /    23 runs   (    0.50 ms per token,  1996.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.88 ms /    17 tokens (   18.99 ms per token,    52.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2363.75 ms /    22 runs   (  107.44 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =    2710.22 ms /    39 tokens\n",
      " 27%|██▋       | 137/500 [05:43<15:25,  2.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.96 ms /    30 runs   (    0.50 ms per token,  2006.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     572.49 ms /    32 tokens (   17.89 ms per token,    55.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2995.19 ms /    29 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    3599.82 ms /    61 tokens\n",
      " 28%|██▊       | 138/500 [05:47<17:17,  2.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    17 runs   (    0.51 ms per token,  1961.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.18 ms /    21 tokens (   18.58 ms per token,    53.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.06 ms /    16 runs   (   98.88 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    1989.89 ms /    37 tokens\n",
      " 28%|██▊       | 139/500 [05:49<15:39,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1946.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.03 ms /    16 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =     589.56 ms /     6 runs   (   98.26 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =     895.52 ms /    22 tokens\n",
      " 28%|██▊       | 140/500 [05:50<12:32,  2.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     3 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.73 ms /    18 tokens (   18.43 ms per token,    54.26 tokens per second)\n",
      "llama_print_timings:        eval time =     173.41 ms /     2 runs   (   86.70 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     507.66 ms /    20 tokens\n",
      " 28%|██▊       | 141/500 [05:50<09:40,  1.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    19 runs   (    0.52 ms per token,  1924.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.37 ms /    22 tokens (   18.20 ms per token,    54.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1878.68 ms /    18 runs   (  104.37 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    2299.57 ms /    40 tokens\n",
      " 28%|██▊       | 142/500 [05:53<10:52,  1.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    22 runs   (    0.50 ms per token,  1981.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.28 ms /    18 tokens (   18.46 ms per token,    54.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2102.32 ms /    21 runs   (  100.11 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    2457.46 ms /    39 tokens\n",
      " 29%|██▊       | 143/500 [05:55<11:58,  2.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     3 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     388.84 ms /    21 tokens (   18.52 ms per token,    54.01 tokens per second)\n",
      "llama_print_timings:        eval time =     203.11 ms /     2 runs   (  101.55 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =     594.65 ms /    23 tokens\n",
      " 29%|██▉       | 144/500 [05:56<09:25,  1.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.67 ms /    23 runs   (    0.51 ms per token,  1970.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.95 ms /    20 tokens (   18.35 ms per token,    54.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2228.62 ms /    22 runs   (  101.30 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    2619.54 ms /    42 tokens\n",
      " 29%|██▉       | 145/500 [05:58<11:14,  1.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    23 runs   (    0.50 ms per token,  2005.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     444.50 ms /    23 tokens (   19.33 ms per token,    51.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2174.04 ms /    22 runs   (   98.82 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    2642.31 ms /    45 tokens\n",
      " 29%|██▉       | 146/500 [06:01<12:31,  2.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1923.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.92 ms /    19 tokens (   18.68 ms per token,    53.53 tokens per second)\n",
      "llama_print_timings:        eval time =     496.95 ms /     5 runs   (   99.39 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =     857.76 ms /    24 tokens\n",
      " 29%|██▉       | 147/500 [06:02<10:15,  1.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    23 runs   (    0.52 ms per token,  1912.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.67 ms /    22 tokens (   18.21 ms per token,    54.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2269.59 ms /    22 runs   (  103.16 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2695.81 ms /    44 tokens\n",
      " 30%|██▉       | 148/500 [06:05<11:54,  2.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    22 runs   (    0.50 ms per token,  1988.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.04 ms /    18 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2119.36 ms /    21 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    2475.82 ms /    39 tokens\n",
      " 30%|██▉       | 149/500 [06:07<12:39,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.81 ms /    28 runs   (    0.53 ms per token,  1891.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.67 ms /    23 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2771.28 ms /    27 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    3226.69 ms /    50 tokens\n",
      " 30%|███       | 150/500 [06:10<14:29,  2.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    10 runs   (    0.52 ms per token,  1928.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     311.09 ms /    15 tokens (   20.74 ms per token,    48.22 tokens per second)\n",
      "llama_print_timings:        eval time =     906.06 ms /     9 runs   (  100.67 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    1227.28 ms /    24 tokens\n",
      " 30%|███       | 151/500 [06:11<12:15,  2.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.09 ms /    49 runs   (    0.51 ms per token,  1952.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     404.53 ms /    22 tokens (   18.39 ms per token,    54.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4925.44 ms /    48 runs   (  102.61 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    5382.26 ms /    70 tokens\n",
      " 30%|███       | 152/500 [06:17<17:55,  3.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.35 ms /    43 runs   (    0.52 ms per token,  1924.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.59 ms /    12 tokens (   19.55 ms per token,    51.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4452.90 ms /    42 runs   (  106.02 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    4733.13 ms /    54 tokens\n",
      " 31%|███       | 153/500 [06:22<20:43,  3.58s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    18 runs   (    0.51 ms per token,  1962.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     338.80 ms /    17 tokens (   19.93 ms per token,    50.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1681.83 ms /    17 runs   (   98.93 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    2039.82 ms /    34 tokens\n",
      " 31%|███       | 154/500 [06:24<17:59,  3.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     4 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     405.44 ms /    22 tokens (   18.43 ms per token,    54.26 tokens per second)\n",
      "llama_print_timings:        eval time =     310.82 ms /     3 runs   (  103.61 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     720.26 ms /    25 tokens\n",
      " 31%|███       | 155/500 [06:24<13:48,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    25 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     359.95 ms /    19 tokens (   18.94 ms per token,    52.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2555.60 ms /    24 runs   (  106.48 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =    2943.02 ms /    43 tokens\n",
      " 31%|███       | 156/500 [06:27<14:42,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     5 runs   (    0.51 ms per token,  1944.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.99 ms /    16 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =     430.70 ms /     4 runs   (  107.68 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =     739.56 ms /    20 tokens\n",
      " 31%|███▏      | 157/500 [06:28<11:32,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.82 ms /    32 runs   (    0.53 ms per token,  1902.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.63 ms /    21 tokens (   18.65 ms per token,    53.62 tokens per second)\n",
      "llama_print_timings:        eval time =    3218.05 ms /    31 runs   (  103.81 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    3643.52 ms /    52 tokens\n",
      " 32%|███▏      | 158/500 [06:32<14:17,  2.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1924.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.85 ms /    18 tokens (   18.49 ms per token,    54.08 tokens per second)\n",
      "llama_print_timings:        eval time =     290.44 ms /     3 runs   (   96.81 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     627.11 ms /    21 tokens\n",
      " 32%|███▏      | 159/500 [06:32<11:02,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /     8 runs   (    0.52 ms per token,  1907.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.26 ms /    19 tokens (   18.70 ms per token,    53.48 tokens per second)\n",
      "llama_print_timings:        eval time =     713.34 ms /     7 runs   (  101.91 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    1076.81 ms /    26 tokens\n",
      " 32%|███▏      | 160/500 [06:33<09:32,  1.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1946.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.01 ms /    16 tokens (   18.69 ms per token,    53.51 tokens per second)\n",
      "llama_print_timings:        eval time =     612.29 ms /     6 runs   (  102.05 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =     918.07 ms /    22 tokens\n",
      " 32%|███▏      | 161/500 [06:34<08:13,  1.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1934.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.38 ms /    15 tokens (   19.49 ms per token,    51.30 tokens per second)\n",
      "llama_print_timings:        eval time =     498.15 ms /     5 runs   (   99.63 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =     796.68 ms /    20 tokens\n",
      " 32%|███▏      | 162/500 [06:35<07:05,  1.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    20 runs   (    0.50 ms per token,  2020.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.35 ms /    17 tokens (   19.02 ms per token,    52.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.24 ms /    19 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    2352.11 ms /    36 tokens\n",
      " 33%|███▎      | 163/500 [06:37<08:54,  1.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    11 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.16 ms /    15 tokens (   19.21 ms per token,    52.05 tokens per second)\n",
      "llama_print_timings:        eval time =     986.49 ms /    10 runs   (   98.65 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =    1286.72 ms /    25 tokens\n",
      " 33%|███▎      | 164/500 [06:39<08:23,  1.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.90 ms /    23 runs   (    0.52 ms per token,  1933.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.02 ms /    19 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2309.07 ms /    22 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2689.35 ms /    41 tokens\n",
      " 33%|███▎      | 165/500 [06:41<10:21,  1.86s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    28 runs   (    0.53 ms per token,  1876.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     361.61 ms /    19 tokens (   19.03 ms per token,    52.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2736.45 ms /    27 runs   (  101.35 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =    3128.51 ms /    46 tokens\n",
      " 33%|███▎      | 166/500 [06:45<12:27,  2.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    17 runs   (    0.51 ms per token,  1950.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.24 ms /    15 tokens (   19.15 ms per token,    52.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1663.38 ms /    16 runs   (  103.96 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    1967.80 ms /    31 tokens\n",
      " 33%|███▎      | 167/500 [06:47<11:58,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1914.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.66 ms /    20 tokens (   18.88 ms per token,    52.96 tokens per second)\n",
      "llama_print_timings:        eval time =     413.16 ms /     4 runs   (  103.29 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =     795.84 ms /    24 tokens\n",
      " 34%|███▎      | 168/500 [06:47<09:40,  1.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     8 runs   (    0.52 ms per token,  1930.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.32 ms /    16 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =     726.27 ms /     7 runs   (  103.75 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    1033.69 ms /    23 tokens\n",
      " 34%|███▍      | 169/500 [06:48<08:28,  1.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     5 runs   (    0.53 ms per token,  1889.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     365.90 ms /    20 tokens (   18.30 ms per token,    54.66 tokens per second)\n",
      "llama_print_timings:        eval time =     420.95 ms /     4 runs   (  105.24 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =     792.44 ms /    24 tokens\n",
      " 34%|███▍      | 170/500 [06:49<07:13,  1.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    16 runs   (    0.50 ms per token,  1999.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.48 ms /    16 tokens (   18.66 ms per token,    53.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1589.35 ms /    15 runs   (  105.96 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1903.89 ms /    31 tokens\n",
      " 34%|███▍      | 171/500 [06:51<08:10,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.65 ms /    23 runs   (    0.51 ms per token,  1974.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.33 ms /    14 tokens (   19.02 ms per token,    52.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2194.11 ms /    22 runs   (   99.73 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    2484.28 ms /    36 tokens\n",
      " 34%|███▍      | 172/500 [06:54<09:47,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     5 runs   (    0.53 ms per token,  1877.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.17 ms /    19 tokens (   18.69 ms per token,    53.50 tokens per second)\n",
      "llama_print_timings:        eval time =     431.53 ms /     4 runs   (  107.88 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =     791.71 ms /    23 tokens\n",
      " 35%|███▍      | 173/500 [06:54<08:07,  1.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1920.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.05 ms /    17 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time =     279.21 ms /     3 runs   (   93.07 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =     604.67 ms /    20 tokens\n",
      " 35%|███▍      | 174/500 [06:55<06:39,  1.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.97 ms /    27 runs   (    0.52 ms per token,  1932.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.46 ms /    22 tokens (   18.20 ms per token,    54.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2632.32 ms /    26 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3061.34 ms /    48 tokens\n",
      " 35%|███▌      | 175/500 [06:58<09:37,  1.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.23 ms /    22 tokens (   18.24 ms per token,    54.83 tokens per second)\n",
      "llama_print_timings:        eval time =     594.12 ms /     6 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    1002.98 ms /    28 tokens\n",
      " 35%|███▌      | 176/500 [06:59<08:20,  1.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    32 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     311.71 ms /    16 tokens (   19.48 ms per token,    51.33 tokens per second)\n",
      "llama_print_timings:        eval time =    3261.24 ms /    31 runs   (  105.20 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    3607.96 ms /    47 tokens\n",
      " 35%|███▌      | 177/500 [07:03<11:39,  2.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.82 ms /    28 runs   (    0.53 ms per token,  1888.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.97 ms /    24 tokens (   18.17 ms per token,    55.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2765.10 ms /    27 runs   (  102.41 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    3230.90 ms /    51 tokens\n",
      " 36%|███▌      | 178/500 [07:06<13:20,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    24 runs   (    0.52 ms per token,  1935.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     240.47 ms /    12 tokens (   20.04 ms per token,    49.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2373.29 ms /    23 runs   (  103.19 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2638.66 ms /    35 tokens\n",
      " 36%|███▌      | 179/500 [07:09<13:32,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    25 runs   (    0.52 ms per token,  1938.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.09 ms /    15 tokens (   19.27 ms per token,    51.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2460.75 ms /    24 runs   (  102.53 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2776.53 ms /    39 tokens\n",
      " 36%|███▌      | 180/500 [07:11<13:54,  2.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.14 ms /    29 runs   (    0.52 ms per token,  1915.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.68 ms /    15 tokens (   19.25 ms per token,    51.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2943.76 ms /    28 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    3263.35 ms /    43 tokens\n",
      " 36%|███▌      | 181/500 [07:15<14:54,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    18 runs   (    0.51 ms per token,  1957.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.21 ms /    16 tokens (   18.70 ms per token,    53.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1782.49 ms /    17 runs   (  104.85 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    2100.29 ms /    33 tokens\n",
      " 36%|███▋      | 182/500 [07:17<13:44,  2.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    18 runs   (    0.51 ms per token,  1949.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.97 ms /    12 tokens (   19.91 ms per token,    50.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1729.42 ms /    17 runs   (  101.73 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    1987.31 ms /    29 tokens\n",
      " 37%|███▋      | 183/500 [07:19<12:44,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     4 runs   (    0.51 ms per token,  1976.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.44 ms /    11 tokens (   20.68 ms per token,    48.36 tokens per second)\n",
      "llama_print_timings:        eval time =     300.72 ms /     3 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =     531.89 ms /    14 tokens\n",
      " 37%|███▋      | 184/500 [07:19<09:44,  1.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     6 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.72 ms /    12 tokens (   20.23 ms per token,    49.44 tokens per second)\n",
      "llama_print_timings:        eval time =     509.53 ms /     5 runs   (  101.91 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =     758.52 ms /    17 tokens\n",
      " 37%|███▋      | 185/500 [07:20<07:59,  1.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    10 runs   (    0.53 ms per token,  1883.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.76 ms /    24 tokens (   18.11 ms per token,    55.20 tokens per second)\n",
      "llama_print_timings:        eval time =     903.87 ms /     9 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1349.15 ms /    33 tokens\n",
      " 37%|███▋      | 186/500 [07:21<07:41,  1.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     4 runs   (    0.52 ms per token,  1912.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     544.54 ms /    30 tokens (   18.15 ms per token,    55.09 tokens per second)\n",
      "llama_print_timings:        eval time =     325.62 ms /     3 runs   (  108.54 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =     873.97 ms /    33 tokens\n",
      " 37%|███▋      | 187/500 [07:22<06:44,  1.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1899.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     347.59 ms /    18 tokens (   19.31 ms per token,    51.79 tokens per second)\n",
      "llama_print_timings:        eval time =     482.95 ms /     4 runs   (  120.74 ms per token,     8.28 tokens per second)\n",
      "llama_print_timings:       total time =     835.94 ms /    22 tokens\n",
      " 38%|███▊      | 188/500 [07:23<06:00,  1.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.74 ms /    23 runs   (    0.51 ms per token,  1958.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     318.11 ms /    16 tokens (   19.88 ms per token,    50.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2502.97 ms /    22 runs   (  113.77 ms per token,     8.79 tokens per second)\n",
      "llama_print_timings:       total time =    2845.11 ms /    38 tokens\n",
      " 38%|███▊      | 189/500 [07:26<08:37,  1.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.20 ms /    21 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     376.01 ms /    20 tokens (   18.80 ms per token,    53.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2307.91 ms /    20 runs   (  115.40 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =    2706.73 ms /    40 tokens\n",
      " 38%|███▊      | 190/500 [07:29<10:12,  1.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    12 runs   (    0.52 ms per token,  1919.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     433.72 ms /    23 tokens (   18.86 ms per token,    53.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1348.84 ms /    11 runs   (  122.62 ms per token,     8.16 tokens per second)\n",
      "llama_print_timings:       total time =    1795.70 ms /    34 tokens\n",
      " 38%|███▊      | 191/500 [07:30<09:54,  1.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /     9 runs   (    0.52 ms per token,  1910.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     414.87 ms /    22 tokens (   18.86 ms per token,    53.03 tokens per second)\n",
      "llama_print_timings:        eval time =     897.54 ms /     8 runs   (  112.19 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    1322.32 ms /    30 tokens\n",
      " 38%|███▊      | 192/500 [07:32<08:57,  1.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    25 runs   (    0.52 ms per token,  1923.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.91 ms /    18 tokens (   19.72 ms per token,    50.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2827.04 ms /    24 runs   (  117.79 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =    3209.19 ms /    42 tokens\n",
      " 39%|███▊      | 193/500 [07:35<11:10,  2.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    12 runs   (    0.52 ms per token,  1908.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.87 ms /    14 tokens (   19.99 ms per token,    50.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.47 ms /    11 runs   (  109.22 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    1493.97 ms /    25 tokens\n",
      " 39%|███▉      | 194/500 [07:36<10:05,  1.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.80 ms /    19 runs   (    0.52 ms per token,  1938.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     340.14 ms /    17 tokens (   20.01 ms per token,    49.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2023.98 ms /    18 runs   (  112.44 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =    2384.55 ms /    35 tokens\n",
      " 39%|███▉      | 195/500 [07:39<10:40,  2.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.09 ms /    50 runs   (    0.52 ms per token,  1916.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     347.73 ms /    17 tokens (   20.45 ms per token,    48.89 tokens per second)\n",
      "llama_print_timings:        eval time =    5763.09 ms /    49 runs   (  117.61 ms per token,     8.50 tokens per second)\n",
      "llama_print_timings:       total time =    6166.59 ms /    66 tokens\n",
      " 39%|███▉      | 196/500 [07:45<16:49,  3.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     5 runs   (    0.51 ms per token,  1952.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     310.85 ms /    15 tokens (   20.72 ms per token,    48.25 tokens per second)\n",
      "llama_print_timings:        eval time =     450.44 ms /     4 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =     765.85 ms /    19 tokens\n",
      " 39%|███▉      | 197/500 [07:46<12:54,  2.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.96 ms /    27 runs   (    0.52 ms per token,  1933.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.19 ms /    15 tokens (   20.15 ms per token,    49.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2971.10 ms /    26 runs   (  114.27 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =    3301.67 ms /    41 tokens\n",
      " 40%|███▉      | 198/500 [07:49<13:59,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.52 ms /    30 runs   (    0.52 ms per token,  1933.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     371.97 ms /    19 tokens (   19.58 ms per token,    51.08 tokens per second)\n",
      "llama_print_timings:        eval time =    3319.36 ms /    29 runs   (  114.46 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =    3724.02 ms /    48 tokens\n",
      " 40%|███▉      | 199/500 [07:53<15:22,  3.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    16 runs   (    0.51 ms per token,  1957.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     351.92 ms /    18 tokens (   19.55 ms per token,    51.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1680.03 ms /    15 runs   (  112.00 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =    2049.27 ms /    33 tokens\n",
      " 40%|████      | 200/500 [07:55<13:48,  2.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    18 runs   (    0.51 ms per token,  1945.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     399.06 ms /    21 tokens (   19.00 ms per token,    52.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1951.48 ms /    17 runs   (  114.79 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =    2369.86 ms /    38 tokens\n",
      " 40%|████      | 201/500 [07:57<13:10,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    21 runs   (    0.50 ms per token,  1998.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     377.80 ms /    20 tokens (   18.89 ms per token,    52.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2232.53 ms /    20 runs   (  111.63 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =    2631.69 ms /    40 tokens\n",
      " 40%|████      | 202/500 [08:00<13:06,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     362.73 ms /    19 tokens (   19.09 ms per token,    52.38 tokens per second)\n",
      "llama_print_timings:        eval time =     317.10 ms /     3 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =     683.69 ms /    22 tokens\n",
      " 41%|████      | 203/500 [08:00<10:10,  2.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.48 ms /    26 runs   (    0.52 ms per token,  1928.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.33 ms /    21 tokens (   19.06 ms per token,    52.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2693.25 ms /    25 runs   (  107.73 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    3120.73 ms /    46 tokens\n",
      " 41%|████      | 204/500 [08:04<11:42,  2.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    22 runs   (    0.51 ms per token,  1970.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     369.13 ms /    19 tokens (   19.43 ms per token,    51.47 tokens per second)\n",
      "llama_print_timings:        eval time =    2357.04 ms /    21 runs   (  112.24 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =    2750.22 ms /    40 tokens\n",
      " 41%|████      | 205/500 [08:06<12:13,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     353.15 ms /    18 tokens (   19.62 ms per token,    50.97 tokens per second)\n",
      "llama_print_timings:        eval time =     108.43 ms /     1 runs   (  108.43 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =     463.93 ms /    19 tokens\n",
      " 41%|████      | 206/500 [08:07<09:13,  1.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    22 runs   (    0.51 ms per token,  1960.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     339.99 ms /    17 tokens (   20.00 ms per token,    50.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2189.90 ms /    21 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2553.26 ms /    38 tokens\n",
      " 41%|████▏     | 207/500 [08:09<10:10,  2.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     4 runs   (    0.54 ms per token,  1857.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.25 ms /    14 tokens (   19.95 ms per token,    50.13 tokens per second)\n",
      "llama_print_timings:        eval time =     475.93 ms /     3 runs   (  158.64 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:       total time =     759.89 ms /    17 tokens\n",
      " 42%|████▏     | 208/500 [08:10<08:12,  1.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    11 runs   (    0.53 ms per token,  1887.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     642.08 ms /    14 tokens (   45.86 ms per token,    21.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1491.42 ms /    10 runs   (  149.14 ms per token,     6.71 tokens per second)\n",
      "llama_print_timings:       total time =    2147.03 ms /    24 tokens\n",
      " 42%|████▏     | 209/500 [08:12<08:51,  1.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    28 runs   (    0.53 ms per token,  1873.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     705.88 ms /    17 tokens (   41.52 ms per token,    24.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4494.78 ms /    27 runs   (  166.47 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:       total time =    5235.52 ms /    44 tokens\n",
      " 42%|████▏     | 210/500 [08:18<13:46,  2.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.54 ms per token,  1863.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     916.56 ms /    21 tokens (   43.65 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:        eval time =     184.39 ms /     1 runs   (  184.39 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:       total time =    1102.31 ms /    22 tokens\n",
      " 42%|████▏     | 211/500 [08:19<11:12,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    19 runs   (    0.53 ms per token,  1881.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     775.94 ms /    20 tokens (   38.80 ms per token,    25.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2790.71 ms /    18 runs   (  155.04 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:       total time =    3589.27 ms /    38 tokens\n",
      " 42%|████▏     | 212/500 [08:22<12:59,  2.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1942.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     570.43 ms /    20 tokens (   28.52 ms per token,    35.06 tokens per second)\n",
      "llama_print_timings:        eval time =     308.53 ms /     3 runs   (  102.84 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =     883.09 ms /    23 tokens\n",
      " 43%|████▎     | 213/500 [08:23<10:19,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    21 runs   (    0.51 ms per token,  1954.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     460.22 ms /    25 tokens (   18.41 ms per token,    54.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1982.45 ms /    20 runs   (   99.12 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =    2464.20 ms /    45 tokens\n",
      " 43%|████▎     | 214/500 [08:26<10:44,  2.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     3 runs   (    0.51 ms per token,  1967.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.03 ms /    18 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =     197.60 ms /     2 runs   (   98.80 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =     534.60 ms /    20 tokens\n",
      " 43%|████▎     | 215/500 [08:26<08:15,  1.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     3 runs   (    0.51 ms per token,  1962.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.93 ms /    17 tokens (   18.94 ms per token,    52.81 tokens per second)\n",
      "llama_print_timings:        eval time =     187.05 ms /     2 runs   (   93.53 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =     511.23 ms /    19 tokens\n",
      " 43%|████▎     | 216/500 [08:27<06:29,  1.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     7 runs   (    0.51 ms per token,  1947.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.12 ms /    14 tokens (   18.79 ms per token,    53.21 tokens per second)\n",
      "llama_print_timings:        eval time =     606.45 ms /     6 runs   (  101.08 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =     876.56 ms /    20 tokens\n",
      " 43%|████▎     | 217/500 [08:28<05:46,  1.22s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /    31 runs   (    0.52 ms per token,  1912.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.85 ms /    15 tokens (   19.19 ms per token,    52.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2970.46 ms /    30 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    3290.95 ms /    45 tokens\n",
      " 44%|████▎     | 218/500 [08:31<08:39,  1.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    25 runs   (    0.51 ms per token,  1980.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.43 ms /    10 tokens (   19.74 ms per token,    50.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2459.16 ms /    24 runs   (  102.46 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    2681.80 ms /    34 tokens\n",
      " 44%|████▍     | 219/500 [08:33<09:48,  2.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    14 runs   (    0.51 ms per token,  1951.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.15 ms /    16 tokens (   18.76 ms per token,    53.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1314.43 ms /    13 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1629.49 ms /    29 tokens\n",
      " 44%|████▍     | 220/500 [08:35<09:07,  1.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /     8 runs   (    0.52 ms per token,  1936.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.34 ms /    12 tokens (   19.20 ms per token,    52.10 tokens per second)\n",
      "llama_print_timings:        eval time =     723.90 ms /     7 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     962.78 ms /    19 tokens\n",
      " 44%|████▍     | 221/500 [08:36<07:42,  1.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    24 runs   (    0.52 ms per token,  1906.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.88 ms /    16 tokens (   18.68 ms per token,    53.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2359.99 ms /    23 runs   (  102.61 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    2685.00 ms /    39 tokens\n",
      " 44%|████▍     | 222/500 [08:39<09:06,  1.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.19 ms /    24 runs   (    0.51 ms per token,  1968.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.56 ms /    13 tokens (   19.50 ms per token,    51.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2340.43 ms /    23 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    2618.50 ms /    36 tokens\n",
      " 45%|████▍     | 223/500 [08:41<09:59,  2.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    19 runs   (    0.50 ms per token,  1984.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.98 ms /    15 tokens (   19.27 ms per token,    51.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1751.00 ms /    18 runs   (   97.28 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =    2059.12 ms /    33 tokens\n",
      " 45%|████▍     | 224/500 [08:43<09:48,  2.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    10 runs   (    0.51 ms per token,  1978.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.64 ms /    12 tokens (   19.22 ms per token,    52.03 tokens per second)\n",
      "llama_print_timings:        eval time =     903.88 ms /     9 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1143.70 ms /    21 tokens\n",
      " 45%|████▌     | 225/500 [08:45<08:25,  1.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    18 runs   (    0.51 ms per token,  1974.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.55 ms /    22 tokens (   18.25 ms per token,    54.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1724.81 ms /    17 runs   (  101.46 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    2144.35 ms /    39 tokens\n",
      " 45%|████▌     | 226/500 [08:47<08:48,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.80 ms /    30 runs   (    0.53 ms per token,  1898.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.57 ms /    18 tokens (   18.48 ms per token,    54.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2908.28 ms /    29 runs   (  100.29 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    3272.96 ms /    47 tokens\n",
      " 45%|████▌     | 227/500 [08:50<10:37,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.53 ms per token,  1902.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.37 ms /    24 tokens (   18.14 ms per token,    55.13 tokens per second)\n",
      "llama_print_timings:        eval time =     293.86 ms /     3 runs   (   97.95 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =     733.11 ms /    27 tokens\n",
      " 46%|████▌     | 228/500 [08:51<08:24,  1.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    20 runs   (    0.51 ms per token,  1974.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.22 ms /    18 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1832.45 ms /    19 runs   (   96.44 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =    2185.06 ms /    37 tokens\n",
      " 46%|████▌     | 229/500 [08:53<08:49,  1.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     2 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     403.64 ms /    22 tokens (   18.35 ms per token,    54.50 tokens per second)\n",
      "llama_print_timings:        eval time =     104.96 ms /     1 runs   (  104.96 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =     510.16 ms /    23 tokens\n",
      " 46%|████▌     | 230/500 [08:53<06:50,  1.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      34.37 ms /    64 runs   (    0.54 ms per token,  1861.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.12 ms /    18 tokens (   18.45 ms per token,    54.20 tokens per second)\n",
      "llama_print_timings:        eval time =    6680.81 ms /    63 runs   (  106.04 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    7083.85 ms /    81 tokens\n",
      " 46%|████▌     | 231/500 [09:01<14:18,  3.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    30 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.73 ms /    11 tokens (   19.98 ms per token,    50.06 tokens per second)\n",
      "llama_print_timings:        eval time =    3070.33 ms /    29 runs   (  105.87 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =    3321.81 ms /    40 tokens\n",
      " 46%|████▋     | 232/500 [09:04<14:25,  3.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    10 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.49 ms /    13 tokens (   19.58 ms per token,    51.08 tokens per second)\n",
      "llama_print_timings:        eval time =     950.69 ms /     9 runs   (  105.63 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    1216.42 ms /    22 tokens\n",
      " 47%|████▋     | 233/500 [09:05<11:41,  2.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.94 ms /    42 runs   (    0.52 ms per token,  1914.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.58 ms /    15 tokens (   19.31 ms per token,    51.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4158.86 ms /    41 runs   (  101.44 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    4492.29 ms /    56 tokens\n",
      " 47%|████▋     | 234/500 [09:10<14:07,  3.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1962.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.58 ms /    17 tokens (   18.98 ms per token,    52.70 tokens per second)\n",
      "llama_print_timings:        eval time =     387.58 ms /     4 runs   (   96.89 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =     715.03 ms /    21 tokens\n",
      " 47%|████▋     | 235/500 [09:10<10:48,  2.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    16 runs   (    0.50 ms per token,  2003.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.03 ms /    18 tokens (   18.50 ms per token,    54.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1517.22 ms /    15 runs   (  101.15 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1867.15 ms /    33 tokens\n",
      " 47%|████▋     | 236/500 [09:12<10:00,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    24 runs   (    0.52 ms per token,  1936.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.60 ms /    19 tokens (   18.72 ms per token,    53.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2396.71 ms /    23 runs   (  104.20 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    2778.09 ms /    42 tokens\n",
      " 47%|████▋     | 237/500 [09:15<10:37,  2.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     3 runs   (    0.52 ms per token,  1914.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     495.11 ms /    27 tokens (   18.34 ms per token,    54.53 tokens per second)\n",
      "llama_print_timings:        eval time =     203.71 ms /     2 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =     701.32 ms /    29 tokens\n",
      " 48%|████▊     | 238/500 [09:16<08:20,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     4 runs   (    0.51 ms per token,  1961.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.23 ms /    14 tokens (   18.95 ms per token,    52.78 tokens per second)\n",
      "llama_print_timings:        eval time =     299.23 ms /     3 runs   (   99.74 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =     568.50 ms /    17 tokens\n",
      " 48%|████▊     | 239/500 [09:16<06:33,  1.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    20 runs   (    0.50 ms per token,  1982.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.99 ms /    15 tokens (   19.20 ms per token,    52.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1971.32 ms /    19 runs   (  103.75 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    2279.40 ms /    34 tokens\n",
      " 48%|████▊     | 240/500 [09:19<07:32,  1.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.01 ms /    31 runs   (    0.52 ms per token,  1936.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.39 ms /    19 tokens (   18.70 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =    3123.08 ms /    30 runs   (  104.10 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    3510.26 ms /    49 tokens\n",
      " 48%|████▊     | 241/500 [09:22<09:48,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    19 runs   (    0.51 ms per token,  1969.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.62 ms /    18 tokens (   18.48 ms per token,    54.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1927.22 ms /    18 runs   (  107.07 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    2278.65 ms /    36 tokens\n",
      " 48%|████▊     | 242/500 [09:24<09:46,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    27 runs   (    0.52 ms per token,  1921.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.79 ms /    14 tokens (   18.91 ms per token,    52.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2646.83 ms /    26 runs   (  101.80 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    2940.67 ms /    40 tokens\n",
      " 49%|████▊     | 243/500 [09:27<10:36,  2.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    19 runs   (    0.52 ms per token,  1927.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.22 ms /    17 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1876.94 ms /    18 runs   (  104.27 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    2220.03 ms /    35 tokens\n",
      " 49%|████▉     | 244/500 [09:29<10:14,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.94 ms /    29 runs   (    0.52 ms per token,  1941.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.03 ms /    14 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2913.54 ms /    28 runs   (  104.05 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    3209.30 ms /    42 tokens\n",
      " 49%|████▉     | 245/500 [09:33<11:13,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.58 ms /    28 runs   (    0.52 ms per token,  1921.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.33 ms /    16 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2847.91 ms /    27 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    3177.16 ms /    43 tokens\n",
      " 49%|████▉     | 246/500 [09:36<11:52,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1930.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.12 ms /    17 tokens (   19.01 ms per token,    52.61 tokens per second)\n",
      "llama_print_timings:        eval time =     306.55 ms /     3 runs   (  102.18 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =     633.52 ms /    20 tokens\n",
      " 49%|████▉     | 247/500 [09:36<09:04,  2.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.89 ms /    27 runs   (    0.51 ms per token,  1943.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.81 ms /    11 tokens (   20.07 ms per token,    49.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2730.68 ms /    26 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2980.81 ms /    37 tokens\n",
      " 50%|████▉     | 248/500 [09:39<10:05,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    22 runs   (    0.51 ms per token,  1974.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     328.06 ms /    17 tokens (   19.30 ms per token,    51.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2093.31 ms /    21 runs   (   99.68 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    2443.76 ms /    38 tokens\n",
      " 50%|████▉     | 249/500 [09:42<10:06,  2.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.59 ms /    35 runs   (    0.53 ms per token,  1883.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.00 ms /    19 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    3600.70 ms /    34 runs   (  105.90 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    3993.94 ms /    53 tokens\n",
      " 50%|█████     | 250/500 [09:46<12:02,  2.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.50 ms /    28 runs   (    0.52 ms per token,  1931.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     425.39 ms /    23 tokens (   18.50 ms per token,    54.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2663.15 ms /    27 runs   (   98.64 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =    3117.78 ms /    50 tokens\n",
      " 50%|█████     | 251/500 [09:49<12:16,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.20 ms /    22 runs   (    0.51 ms per token,  1965.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.01 ms /    14 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2112.96 ms /    21 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    2401.75 ms /    35 tokens\n",
      " 50%|█████     | 252/500 [09:51<11:32,  2.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1937.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.52 ms /    16 tokens (   18.78 ms per token,    53.24 tokens per second)\n",
      "llama_print_timings:        eval time =     428.58 ms /     4 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =     733.85 ms /    20 tokens\n",
      " 51%|█████     | 253/500 [09:52<08:57,  2.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1914.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.86 ms /    15 tokens (   19.32 ms per token,    51.75 tokens per second)\n",
      "llama_print_timings:        eval time =     406.78 ms /     4 runs   (  101.69 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =     701.47 ms /    19 tokens\n",
      " 51%|█████     | 254/500 [09:53<07:06,  1.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     5 runs   (    0.51 ms per token,  1965.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.69 ms /    15 tokens (   19.18 ms per token,    52.14 tokens per second)\n",
      "llama_print_timings:        eval time =     405.36 ms /     4 runs   (  101.34 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =     697.48 ms /    19 tokens\n",
      " 51%|█████     | 255/500 [09:54<05:48,  1.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.61 ms /    32 runs   (    0.52 ms per token,  1926.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.45 ms /    12 tokens (   19.29 ms per token,    51.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3303.46 ms /    31 runs   (  106.56 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    3569.69 ms /    43 tokens\n",
      " 51%|█████     | 256/500 [09:57<08:24,  2.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.07 ms /    29 runs   (    0.52 ms per token,  1924.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.66 ms /    20 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2872.41 ms /    28 runs   (  102.59 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    3271.16 ms /    48 tokens\n",
      " 51%|█████▏    | 257/500 [10:00<09:50,  2.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.67 ms /    26 runs   (    0.53 ms per token,  1902.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.01 ms /    14 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2461.56 ms /    25 runs   (   98.46 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    2755.18 ms /    39 tokens\n",
      " 52%|█████▏    | 258/500 [10:03<10:11,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    24 runs   (    0.51 ms per token,  1953.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.20 ms /    15 tokens (   19.21 ms per token,    52.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2437.30 ms /    23 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    2750.43 ms /    38 tokens\n",
      " 52%|█████▏    | 259/500 [10:06<10:25,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     5 runs   (    0.50 ms per token,  1986.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    13 tokens (   19.54 ms per token,    51.18 tokens per second)\n",
      "llama_print_timings:        eval time =     408.73 ms /     4 runs   (  102.18 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =     667.53 ms /    17 tokens\n",
      " 52%|█████▏    | 260/500 [10:07<08:04,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    16 runs   (    0.51 ms per token,  1965.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.45 ms /    11 tokens (   20.04 ms per token,    49.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1561.82 ms /    15 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    1799.08 ms /    26 tokens\n",
      " 52%|█████▏    | 261/500 [10:08<07:46,  1.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.20 ms /    38 runs   (    0.51 ms per token,  1978.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.80 ms /    15 tokens (   19.25 ms per token,    51.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3782.00 ms /    37 runs   (  102.22 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    4110.90 ms /    52 tokens\n",
      " 52%|█████▏    | 262/500 [10:13<10:18,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    20 runs   (    0.51 ms per token,  1963.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.98 ms /    16 tokens (   18.75 ms per token,    53.34 tokens per second)\n",
      "llama_print_timings:        eval time =    2034.55 ms /    19 runs   (  107.08 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =    2355.17 ms /    35 tokens\n",
      " 53%|█████▎    | 263/500 [10:15<09:59,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    19 runs   (    0.50 ms per token,  2007.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.73 ms /    17 tokens (   19.04 ms per token,    52.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1782.28 ms /    18 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    2125.90 ms /    35 tokens\n",
      " 53%|█████▎    | 264/500 [10:17<09:28,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     3 runs   (    0.52 ms per token,  1930.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.54 ms /    15 tokens (   19.24 ms per token,    51.99 tokens per second)\n",
      "llama_print_timings:        eval time =     198.23 ms /     2 runs   (   99.12 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =     489.50 ms /    17 tokens\n",
      " 53%|█████▎    | 265/500 [10:18<07:10,  1.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    14 runs   (    0.52 ms per token,  1920.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.60 ms /    15 tokens (   19.24 ms per token,    51.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.40 ms /    13 runs   (   99.72 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    1598.64 ms /    28 tokens\n",
      " 53%|█████▎    | 266/500 [10:19<06:52,  1.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.91 ms /    62 runs   (    0.50 ms per token,  2005.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.71 ms /    17 tokens (   18.92 ms per token,    52.84 tokens per second)\n",
      "llama_print_timings:        eval time =    5961.69 ms /    61 runs   (   97.73 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    6351.35 ms /    78 tokens\n",
      " 53%|█████▎    | 267/500 [10:25<12:11,  3.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    14 runs   (    0.51 ms per token,  1969.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.06 ms /    17 tokens (   19.00 ms per token,    52.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1364.88 ms /    13 runs   (  104.99 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    1701.74 ms /    30 tokens\n",
      " 54%|█████▎    | 268/500 [10:27<10:28,  2.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    16 runs   (    0.52 ms per token,  1914.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.99 ms /    15 tokens (   19.40 ms per token,    51.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.07 ms /    15 runs   (  102.74 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1848.86 ms /    30 tokens\n",
      " 54%|█████▍    | 269/500 [10:29<09:26,  2.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.19 ms /    25 runs   (    0.53 ms per token,  1895.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.99 ms /    17 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2396.07 ms /    24 runs   (   99.84 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    2746.01 ms /    41 tokens\n",
      " 54%|█████▍    | 270/500 [10:32<09:44,  2.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.93 ms /    67 runs   (    0.51 ms per token,  1974.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.88 ms /    14 tokens (   18.92 ms per token,    52.85 tokens per second)\n",
      "llama_print_timings:        eval time =    6876.34 ms /    66 runs   (  104.19 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    7214.37 ms /    80 tokens\n",
      " 54%|█████▍    | 271/500 [10:39<15:03,  3.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    13 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.10 ms /    14 tokens (   18.94 ms per token,    52.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1192.08 ms /    12 runs   (   99.34 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    1470.06 ms /    26 tokens\n",
      " 54%|█████▍    | 272/500 [10:40<12:10,  3.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    24 runs   (    0.53 ms per token,  1901.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.73 ms /    16 tokens (   18.67 ms per token,    53.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2337.71 ms /    23 runs   (  101.64 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2662.34 ms /    39 tokens\n",
      " 55%|█████▍    | 273/500 [10:43<11:30,  3.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.63 ms /    54 runs   (    0.53 ms per token,  1886.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     354.88 ms /    19 tokens (   18.68 ms per token,    53.54 tokens per second)\n",
      "llama_print_timings:        eval time =    5483.29 ms /    53 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    5897.29 ms /    72 tokens\n",
      " 55%|█████▍    | 274/500 [10:49<14:41,  3.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    11 runs   (    0.53 ms per token,  1900.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.73 ms /    15 tokens (   19.18 ms per token,    52.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1027.30 ms /    10 runs   (  102.73 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    1326.77 ms /    25 tokens\n",
      " 55%|█████▌    | 275/500 [10:50<11:43,  3.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      26.19 ms /    51 runs   (    0.51 ms per token,  1947.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.40 ms /    21 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5420.08 ms /    50 runs   (  108.40 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =    5865.49 ms /    71 tokens\n",
      " 55%|█████▌    | 276/500 [10:56<14:44,  3.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    20 runs   (    0.53 ms per token,  1902.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.20 ms /    18 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1956.21 ms /    19 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    2309.91 ms /    37 tokens\n",
      " 55%|█████▌    | 277/500 [10:59<12:51,  3.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     6 runs   (    0.52 ms per token,  1922.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.25 ms /    18 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =     513.87 ms /     5 runs   (  102.77 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =     852.28 ms /    23 tokens\n",
      " 56%|█████▌    | 278/500 [10:59<09:54,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    21 runs   (    0.51 ms per token,  1976.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.17 ms /    13 tokens (   19.63 ms per token,    50.95 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.16 ms /    20 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    2311.78 ms /    33 tokens\n",
      " 56%|█████▌    | 279/500 [11:02<09:27,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     6 runs   (    0.51 ms per token,  1974.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.28 ms /    11 tokens (   20.03 ms per token,    49.94 tokens per second)\n",
      "llama_print_timings:        eval time =     514.31 ms /     5 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =     740.16 ms /    16 tokens\n",
      " 56%|█████▌    | 280/500 [11:02<07:24,  2.02s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /     9 runs   (    0.52 ms per token,  1940.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.67 ms /    14 tokens (   18.90 ms per token,    52.90 tokens per second)\n",
      "llama_print_timings:        eval time =     827.58 ms /     8 runs   (  103.45 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1101.54 ms /    22 tokens\n",
      " 56%|█████▌    | 281/500 [11:04<06:22,  1.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.87 ms /    21 runs   (    0.52 ms per token,  1931.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.10 ms /    15 tokens (   19.21 ms per token,    52.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1973.71 ms /    20 runs   (   98.69 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    2283.08 ms /    35 tokens\n",
      " 56%|█████▋    | 282/500 [11:06<06:55,  1.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    21 runs   (    0.53 ms per token,  1903.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.06 ms /    15 tokens (   19.20 ms per token,    52.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.52 ms /    20 runs   (   99.58 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    2302.84 ms /    35 tokens\n",
      " 57%|█████▋    | 283/500 [11:08<07:19,  2.03s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    20 runs   (    0.51 ms per token,  1955.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     388.84 ms /    21 tokens (   18.52 ms per token,    54.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2006.25 ms /    19 runs   (  105.59 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =    2415.74 ms /    40 tokens\n",
      " 57%|█████▋    | 284/500 [11:11<07:43,  2.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    13 runs   (    0.51 ms per token,  1949.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.47 ms /    18 tokens (   18.53 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.89 ms /    12 runs   (  101.57 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1566.22 ms /    30 tokens\n",
      " 57%|█████▋    | 285/500 [11:12<07:03,  1.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.23 ms /    47 runs   (    0.52 ms per token,  1940.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     403.43 ms /    22 tokens (   18.34 ms per token,    54.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4822.97 ms /    46 runs   (  104.85 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    5277.18 ms /    68 tokens\n",
      " 57%|█████▋    | 286/500 [11:17<10:34,  2.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    20 runs   (    0.50 ms per token,  2016.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     357.32 ms /    19 tokens (   18.81 ms per token,    53.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1958.23 ms /    19 runs   (  103.06 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    2335.92 ms /    38 tokens\n",
      " 57%|█████▋    | 287/500 [11:20<09:51,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1946.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     357.23 ms /    19 tokens (   18.80 ms per token,    53.19 tokens per second)\n",
      "llama_print_timings:        eval time =     288.64 ms /     3 runs   (   96.21 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =     650.06 ms /    22 tokens\n",
      " 58%|█████▊    | 288/500 [11:20<07:33,  2.14s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.15 ms /    43 runs   (    0.52 ms per token,  1941.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.28 ms /    20 tokens (   18.36 ms per token,    54.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4302.16 ms /    42 runs   (  102.43 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =    4715.20 ms /    62 tokens\n",
      " 58%|█████▊    | 289/500 [11:25<10:14,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    23 runs   (    0.51 ms per token,  1954.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.72 ms /    18 tokens (   18.48 ms per token,    54.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2260.80 ms /    22 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    2617.74 ms /    40 tokens\n",
      " 58%|█████▊    | 290/500 [11:28<09:53,  2.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     9 runs   (    0.51 ms per token,  1979.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.99 ms /    12 tokens (   19.25 ms per token,    51.95 tokens per second)\n",
      "llama_print_timings:        eval time =     820.31 ms /     8 runs   (  102.54 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =    1059.87 ms /    20 tokens\n",
      " 58%|█████▊    | 291/500 [11:29<07:59,  2.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1936.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.18 ms /    16 tokens (   18.64 ms per token,    53.66 tokens per second)\n",
      "llama_print_timings:        eval time =     289.65 ms /     3 runs   (   96.55 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     591.77 ms /    19 tokens\n",
      " 58%|█████▊    | 292/500 [11:29<06:11,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1953.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.38 ms /    17 tokens (   18.90 ms per token,    52.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1399.07 ms /    14 runs   (   99.93 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    1735.70 ms /    31 tokens\n",
      " 59%|█████▊    | 293/500 [11:31<06:06,  1.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    12 runs   (    0.52 ms per token,  1923.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.50 ms /    16 tokens (   18.66 ms per token,    53.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.75 ms /    11 runs   (  105.70 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =    1472.84 ms /    27 tokens\n",
      " 59%|█████▉    | 294/500 [11:33<05:46,  1.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    22 runs   (    0.51 ms per token,  1951.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.33 ms /    15 tokens (   19.29 ms per token,    51.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2208.60 ms /    21 runs   (  105.17 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =    2520.67 ms /    36 tokens\n",
      " 59%|█████▉    | 295/500 [11:35<06:36,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    28 runs   (    0.52 ms per token,  1940.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.79 ms /    21 tokens (   18.56 ms per token,    53.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2733.57 ms /    27 runs   (  101.24 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3152.41 ms /    48 tokens\n",
      " 59%|█████▉    | 296/500 [11:38<07:49,  2.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    11 runs   (    0.52 ms per token,  1909.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.17 ms /    18 tokens (   18.51 ms per token,    54.03 tokens per second)\n",
      "llama_print_timings:        eval time =     989.77 ms /    10 runs   (   98.98 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    1334.01 ms /    28 tokens\n",
      " 59%|█████▉    | 297/500 [11:40<06:48,  2.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.04 ms /    21 runs   (    0.53 ms per token,  1901.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.66 ms /    19 tokens (   18.77 ms per token,    53.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2029.03 ms /    20 runs   (  101.45 ms per token,     9.86 tokens per second)\n",
      "llama_print_timings:       total time =    2408.19 ms /    39 tokens\n",
      " 60%|█████▉    | 298/500 [11:42<07:10,  2.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    16 runs   (    0.52 ms per token,  1910.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.62 ms /    23 tokens (   18.42 ms per token,    54.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.07 ms /    15 runs   (   97.34 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =    1900.43 ms /    38 tokens\n",
      " 60%|█████▉    | 299/500 [11:44<06:54,  2.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     5 runs   (    0.51 ms per token,  1951.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.00 ms /    17 tokens (   19.12 ms per token,    52.31 tokens per second)\n",
      "llama_print_timings:        eval time =     409.92 ms /     4 runs   (  102.48 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =     740.01 ms /    21 tokens\n",
      " 60%|██████    | 300/500 [11:45<05:33,  1.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    18 runs   (    0.51 ms per token,  1952.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.66 ms /    21 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1727.59 ms /    17 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2135.46 ms /    38 tokens\n",
      " 60%|██████    | 301/500 [11:47<05:59,  1.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     4 runs   (    0.51 ms per token,  1958.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.34 ms /    19 tokens (   18.70 ms per token,    53.47 tokens per second)\n",
      "llama_print_timings:        eval time =     300.17 ms /     3 runs   (  100.06 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =     658.80 ms /    22 tokens\n",
      " 60%|██████    | 302/500 [11:47<04:49,  1.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1917.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.97 ms /    18 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =      99.38 ms /     1 runs   (   99.38 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =     433.60 ms /    19 tokens\n",
      " 61%|██████    | 303/500 [11:48<03:47,  1.16s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1960.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.13 ms /    15 tokens (   19.21 ms per token,    52.06 tokens per second)\n",
      "llama_print_timings:        eval time =     385.34 ms /     4 runs   (   96.33 ms per token,    10.38 tokens per second)\n",
      "llama_print_timings:       total time =     678.41 ms /    19 tokens\n",
      " 61%|██████    | 304/500 [11:49<03:18,  1.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     4 runs   (    0.51 ms per token,  1957.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.00 ms /    19 tokens (   18.68 ms per token,    53.52 tokens per second)\n",
      "llama_print_timings:        eval time =     303.03 ms /     3 runs   (  101.01 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =     662.06 ms /    22 tokens\n",
      " 61%|██████    | 305/500 [11:49<02:57,  1.10it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.87 ms /    25 runs   (    0.51 ms per token,  1943.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     460.65 ms /    25 tokens (   18.43 ms per token,    54.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2510.01 ms /    24 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2996.26 ms /    49 tokens\n",
      " 61%|██████    | 306/500 [11:52<04:57,  1.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    10 runs   (    0.50 ms per token,  1981.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.56 ms /    14 tokens (   18.97 ms per token,    52.72 tokens per second)\n",
      "llama_print_timings:        eval time =     911.24 ms /     9 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    1187.41 ms /    23 tokens\n",
      " 61%|██████▏   | 307/500 [11:53<04:36,  1.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     4 runs   (    0.53 ms per token,  1899.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.37 ms /    17 tokens (   18.96 ms per token,    52.73 tokens per second)\n",
      "llama_print_timings:        eval time =     298.52 ms /     3 runs   (   99.51 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     625.11 ms /    20 tokens\n",
      " 62%|██████▏   | 308/500 [11:54<03:48,  1.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    24 runs   (    0.52 ms per token,  1908.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.52 ms /    17 tokens (   18.97 ms per token,    52.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2307.59 ms /    23 runs   (  100.33 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2654.94 ms /    40 tokens\n",
      " 62%|██████▏   | 309/500 [11:57<05:11,  1.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    19 runs   (    0.51 ms per token,  1960.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     402.62 ms /    22 tokens (   18.30 ms per token,    54.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1881.16 ms /    18 runs   (  104.51 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =    2303.69 ms /    40 tokens\n",
      " 62%|██████▏   | 310/500 [11:59<05:48,  1.83s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    16 runs   (    0.51 ms per token,  1953.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.73 ms /    18 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1551.18 ms /    15 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1901.56 ms /    33 tokens\n",
      " 62%|██████▏   | 311/500 [12:01<05:50,  1.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.00 ms /    20 tokens (   18.35 ms per token,    54.50 tokens per second)\n",
      "llama_print_timings:        eval time =     288.81 ms /     3 runs   (   96.27 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =     659.63 ms /    23 tokens\n",
      " 62%|██████▏   | 312/500 [12:02<04:41,  1.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    17 runs   (    0.53 ms per token,  1904.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     471.38 ms /    26 tokens (   18.13 ms per token,    55.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2268.67 ms /    16 runs   (  141.79 ms per token,     7.05 tokens per second)\n",
      "llama_print_timings:       total time =    2758.85 ms /    42 tokens\n",
      " 63%|██████▎   | 313/500 [12:04<05:50,  1.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    17 runs   (    0.52 ms per token,  1917.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.23 ms /    17 tokens (   19.13 ms per token,    52.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.96 ms /    16 runs   (  100.12 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =    1944.71 ms /    33 tokens\n",
      " 63%|██████▎   | 314/500 [12:06<05:52,  1.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    14 runs   (    0.50 ms per token,  1986.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.92 ms /    20 tokens (   18.35 ms per token,    54.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.74 ms /    13 runs   (   97.29 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =    1646.29 ms /    33 tokens\n",
      " 63%|██████▎   | 315/500 [12:08<05:37,  1.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.53 ms per token,  1870.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.02 ms /    17 tokens (   19.00 ms per token,    52.63 tokens per second)\n",
      "llama_print_timings:        eval time =     298.39 ms /     3 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     625.95 ms /    20 tokens\n",
      " 63%|██████▎   | 316/500 [12:09<04:29,  1.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.96 ms /    19 runs   (    0.52 ms per token,  1906.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.00 ms /    16 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1841.74 ms /    18 runs   (  102.32 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    2163.15 ms /    34 tokens\n",
      " 63%|██████▎   | 317/500 [12:11<05:06,  1.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      32.06 ms /    65 runs   (    0.49 ms per token,  2027.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.49 ms /    11 tokens (   20.04 ms per token,    49.89 tokens per second)\n",
      "llama_print_timings:        eval time =    6438.70 ms /    64 runs   (  100.60 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =    6728.29 ms /    75 tokens\n",
      " 64%|██████▎   | 318/500 [12:17<09:40,  3.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     3 runs   (    0.51 ms per token,  1974.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.43 ms /    14 tokens (   19.32 ms per token,    51.77 tokens per second)\n",
      "llama_print_timings:        eval time =     202.12 ms /     2 runs   (  101.06 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =     475.63 ms /    16 tokens\n",
      " 64%|██████▍   | 319/500 [12:18<07:10,  2.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    11 runs   (    0.52 ms per token,  1908.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.17 ms /    13 tokens (   19.55 ms per token,    51.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1046.95 ms /    10 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    1313.26 ms /    23 tokens\n",
      " 64%|██████▍   | 320/500 [12:19<06:10,  2.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    17 runs   (    0.51 ms per token,  1960.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.94 ms /    12 tokens (   19.25 ms per token,    51.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1607.35 ms /    16 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =    1855.97 ms /    28 tokens\n",
      " 64%|██████▍   | 321/500 [12:21<05:57,  2.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    20 runs   (    0.51 ms per token,  1979.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.18 ms /    16 tokens (   18.70 ms per token,    53.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1928.26 ms /    19 runs   (  101.49 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    2248.32 ms /    35 tokens\n",
      " 64%|██████▍   | 322/500 [12:23<06:09,  2.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.50 ms /    25 runs   (    0.50 ms per token,  1999.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.43 ms /    24 tokens (   18.14 ms per token,    55.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2484.07 ms /    24 runs   (  103.50 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2945.93 ms /    48 tokens\n",
      " 65%|██████▍   | 323/500 [12:26<06:53,  2.34s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.06 ms /    29 runs   (    0.52 ms per token,  1925.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.92 ms /    12 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2937.00 ms /    28 runs   (  104.89 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    3198.11 ms /    40 tokens\n",
      " 65%|██████▍   | 324/500 [12:30<07:36,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1901.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     392.66 ms /    21 tokens (   18.70 ms per token,    53.48 tokens per second)\n",
      "llama_print_timings:        eval time =     390.66 ms /     4 runs   (   97.66 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     788.70 ms /    25 tokens\n",
      " 65%|██████▌   | 325/500 [12:30<05:59,  2.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.52 ms per token,  1906.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.34 ms /    14 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =     312.90 ms /     3 runs   (  104.30 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =     582.34 ms /    17 tokens\n",
      " 65%|██████▌   | 326/500 [12:31<04:40,  1.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    18 runs   (    0.51 ms per token,  1963.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.25 ms /    14 tokens (   19.02 ms per token,    52.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1765.33 ms /    17 runs   (  103.84 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    2050.57 ms /    31 tokens\n",
      " 65%|██████▌   | 327/500 [12:33<05:01,  1.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.56 ms /    30 runs   (    0.52 ms per token,  1927.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.90 ms /    12 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2936.67 ms /    29 runs   (  101.26 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =    3199.75 ms /    41 tokens\n",
      " 66%|██████▌   | 328/500 [12:36<06:15,  2.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      37.70 ms /    70 runs   (    0.54 ms per token,  1856.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     335.97 ms /    18 tokens (   18.67 ms per token,    53.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7178.90 ms /    69 runs   (  104.04 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    7592.52 ms /    87 tokens\n",
      " 66%|██████▌   | 329/500 [12:44<10:50,  3.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    25 runs   (    0.52 ms per token,  1933.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.78 ms /    14 tokens (   18.98 ms per token,    52.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2444.46 ms /    24 runs   (  101.85 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    2737.42 ms /    38 tokens\n",
      " 66%|██████▌   | 330/500 [12:46<09:52,  3.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    18 runs   (    0.52 ms per token,  1910.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     461.87 ms /    25 tokens (   18.47 ms per token,    54.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1727.61 ms /    17 runs   (  101.62 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2208.15 ms /    42 tokens\n",
      " 66%|██████▌   | 331/500 [12:49<08:44,  3.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    18 runs   (    0.51 ms per token,  1972.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.92 ms /    14 tokens (   18.92 ms per token,    52.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1817.04 ms /    17 runs   (  106.88 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =    2100.60 ms /    31 tokens\n",
      " 66%|██████▋   | 332/500 [12:51<07:50,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    21 runs   (    0.51 ms per token,  1978.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.14 ms /    17 tokens (   19.01 ms per token,    52.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2120.94 ms /    20 runs   (  106.05 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =    2464.91 ms /    37 tokens\n",
      " 67%|██████▋   | 333/500 [12:53<07:31,  2.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    18 runs   (    0.51 ms per token,  1957.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.82 ms /    19 tokens (   18.73 ms per token,    53.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1753.19 ms /    17 runs   (  103.13 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    2127.46 ms /    36 tokens\n",
      " 67%|██████▋   | 334/500 [12:55<07:00,  2.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.35 ms /    35 runs   (    0.52 ms per token,  1907.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     240.51 ms /    12 tokens (   20.04 ms per token,    49.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3391.82 ms /    34 runs   (   99.76 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    3671.87 ms /    46 tokens\n",
      " 67%|██████▋   | 335/500 [12:59<07:54,  2.87s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    10 runs   (    0.54 ms per token,  1868.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.12 ms /    21 tokens (   18.77 ms per token,    53.28 tokens per second)\n",
      "llama_print_timings:        eval time =     908.40 ms /     9 runs   (  100.93 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1313.36 ms /    30 tokens\n",
      " 67%|██████▋   | 336/500 [13:00<06:34,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     7 runs   (    0.51 ms per token,  1967.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.41 ms /    17 tokens (   18.97 ms per token,    52.73 tokens per second)\n",
      "llama_print_timings:        eval time =     586.17 ms /     6 runs   (   97.69 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     915.02 ms /    23 tokens\n",
      " 67%|██████▋   | 337/500 [13:01<05:19,  1.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    25 runs   (    0.51 ms per token,  1955.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.00 ms /    17 tokens (   18.94 ms per token,    52.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2518.03 ms /    24 runs   (  104.92 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    2865.82 ms /    41 tokens\n",
      " 68%|██████▊   | 338/500 [13:04<06:01,  2.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     8 runs   (    0.51 ms per token,  1950.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.12 ms /    12 tokens (   19.26 ms per token,    51.92 tokens per second)\n",
      "llama_print_timings:        eval time =     730.61 ms /     7 runs   (  104.37 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =     969.63 ms /    19 tokens\n",
      " 68%|██████▊   | 339/500 [13:05<04:58,  1.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      28.66 ms /    55 runs   (    0.52 ms per token,  1919.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.76 ms /    16 tokens (   18.80 ms per token,    53.20 tokens per second)\n",
      "llama_print_timings:        eval time =    5609.66 ms /    54 runs   (  103.88 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    5969.64 ms /    70 tokens\n",
      " 68%|██████▊   | 340/500 [13:11<08:14,  3.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      33.24 ms /    65 runs   (    0.51 ms per token,  1955.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.23 ms /    15 tokens (   19.42 ms per token,    51.50 tokens per second)\n",
      "llama_print_timings:        eval time =    6576.59 ms /    64 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =    6936.41 ms /    79 tokens\n",
      " 68%|██████▊   | 341/500 [13:18<11:14,  4.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.01 ms /    26 runs   (    0.50 ms per token,  1998.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.39 ms /    21 tokens (   18.64 ms per token,    53.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2506.30 ms /    25 runs   (  100.25 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2924.60 ms /    46 tokens\n",
      " 68%|██████▊   | 342/500 [13:21<10:08,  3.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    19 runs   (    0.52 ms per token,  1921.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.47 ms /    14 tokens (   19.25 ms per token,    51.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1791.89 ms /    18 runs   (   99.55 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    2081.87 ms /    32 tokens\n",
      " 69%|██████▊   | 343/500 [13:23<08:41,  3.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.85 ms /    33 runs   (    0.51 ms per token,  1958.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.58 ms /    13 tokens (   19.51 ms per token,    51.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3275.90 ms /    32 runs   (  102.37 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    3564.38 ms /    45 tokens\n",
      " 69%|██████▉   | 344/500 [13:27<08:49,  3.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.51 ms per token,  1942.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.74 ms /    17 tokens (   19.04 ms per token,    52.51 tokens per second)\n",
      "llama_print_timings:        eval time =     495.12 ms /     5 runs   (   99.02 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     824.62 ms /    22 tokens\n",
      " 69%|██████▉   | 345/500 [13:27<06:46,  2.62s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /    29 runs   (    0.50 ms per token,  1994.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.55 ms /    18 tokens (   18.53 ms per token,    53.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2764.17 ms /    28 runs   (   98.72 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    3127.82 ms /    46 tokens\n",
      " 69%|██████▉   | 346/500 [13:31<07:07,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.22 ms /    23 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     459.53 ms /    25 tokens (   18.38 ms per token,    54.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2237.03 ms /    22 runs   (  101.68 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    2719.72 ms /    47 tokens\n",
      " 69%|██████▉   | 347/500 [13:33<07:02,  2.76s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1934.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.64 ms /    13 tokens (   19.51 ms per token,    51.25 tokens per second)\n",
      "llama_print_timings:        eval time =     406.53 ms /     4 runs   (  101.63 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =     664.58 ms /    17 tokens\n",
      " 70%|██████▉   | 348/500 [13:34<05:24,  2.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    12 runs   (    0.52 ms per token,  1913.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.62 ms /    16 tokens (   18.73 ms per token,    53.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.10 ms /    11 runs   (  103.55 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1451.45 ms /    27 tokens\n",
      " 70%|██████▉   | 349/500 [13:35<04:51,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1936.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.85 ms /    15 tokens (   19.19 ms per token,    52.11 tokens per second)\n",
      "llama_print_timings:        eval time =     383.46 ms /     4 runs   (   95.87 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     675.94 ms /    19 tokens\n",
      " 70%|███████   | 350/500 [13:36<03:53,  1.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    14 runs   (    0.51 ms per token,  1956.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    13 tokens (   19.50 ms per token,    51.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1319.78 ms /    13 runs   (  101.52 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    1587.58 ms /    26 tokens\n",
      " 70%|███████   | 351/500 [13:38<03:53,  1.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      30.46 ms /    58 runs   (    0.53 ms per token,  1904.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.67 ms /    18 tokens (   18.43 ms per token,    54.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5997.71 ms /    57 runs   (  105.22 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    6392.94 ms /    75 tokens\n",
      " 70%|███████   | 352/500 [13:44<07:25,  3.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    12 runs   (    0.50 ms per token,  1984.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.16 ms /    13 tokens (   19.55 ms per token,    51.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.03 ms /    11 runs   (   98.09 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    1345.97 ms /    24 tokens\n",
      " 71%|███████   | 353/500 [13:45<06:09,  2.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    21 runs   (    0.51 ms per token,  1945.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.73 ms /    15 tokens (   19.18 ms per token,    52.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1925.35 ms /    20 runs   (   96.27 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =    2235.24 ms /    35 tokens\n",
      " 71%|███████   | 354/500 [13:48<05:54,  2.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    21 runs   (    0.51 ms per token,  1973.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.51 ms /    15 tokens (   19.57 ms per token,    51.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1986.44 ms /    20 runs   (   99.32 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    2301.93 ms /    35 tokens\n",
      " 71%|███████   | 355/500 [13:50<05:46,  2.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     5 runs   (    0.53 ms per token,  1871.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.75 ms /    16 tokens (   18.73 ms per token,    53.38 tokens per second)\n",
      "llama_print_timings:        eval time =     418.56 ms /     4 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =     724.08 ms /    20 tokens\n",
      " 71%|███████   | 356/500 [13:51<04:32,  1.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1902.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.20 ms /    18 tokens (   18.46 ms per token,    54.18 tokens per second)\n",
      "llama_print_timings:        eval time =     411.79 ms /     4 runs   (  102.95 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =     749.40 ms /    22 tokens\n",
      " 71%|███████▏  | 357/500 [13:51<03:41,  1.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     5 runs   (    0.52 ms per token,  1905.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.84 ms /    13 tokens (   19.53 ms per token,    51.21 tokens per second)\n",
      "llama_print_timings:        eval time =     392.56 ms /     4 runs   (   98.14 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     651.60 ms /    17 tokens\n",
      " 72%|███████▏  | 358/500 [13:52<03:01,  1.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    28 runs   (    0.51 ms per token,  1948.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    13 tokens (   19.54 ms per token,    51.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2751.22 ms /    27 runs   (  101.90 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    3034.95 ms /    40 tokens\n",
      " 72%|███████▏  | 359/500 [13:55<04:14,  1.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /     8 runs   (    0.54 ms per token,  1865.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     403.08 ms /    22 tokens (   18.32 ms per token,    54.58 tokens per second)\n",
      "llama_print_timings:        eval time =     727.12 ms /     7 runs   (  103.87 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =    1138.82 ms /    29 tokens\n",
      " 72%|███████▏  | 360/500 [13:56<03:45,  1.61s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.64 ms /    19 runs   (    0.51 ms per token,  1970.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.60 ms /    16 tokens (   18.66 ms per token,    53.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1840.54 ms /    18 runs   (  102.25 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    2159.12 ms /    34 tokens\n",
      " 72%|███████▏  | 361/500 [13:58<04:06,  1.77s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.68 ms /    32 runs   (    0.52 ms per token,  1918.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.49 ms /    21 tokens (   18.55 ms per token,    53.92 tokens per second)\n",
      "llama_print_timings:        eval time =    3193.53 ms /    31 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    3618.07 ms /    52 tokens\n",
      " 72%|███████▏  | 362/500 [14:02<05:21,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    23 runs   (    0.52 ms per token,  1940.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.95 ms /    18 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2302.56 ms /    22 runs   (  104.66 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2659.27 ms /    40 tokens\n",
      " 73%|███████▎  | 363/500 [14:05<05:32,  2.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     6 runs   (    0.51 ms per token,  1944.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    13 tokens (   19.54 ms per token,    51.18 tokens per second)\n",
      "llama_print_timings:        eval time =     514.77 ms /     5 runs   (  102.95 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =     774.76 ms /    18 tokens\n",
      " 73%|███████▎  | 364/500 [14:06<04:22,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    24 runs   (    0.52 ms per token,  1909.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.02 ms /    17 tokens (   19.12 ms per token,    52.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2297.39 ms /    23 runs   (   99.89 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =    2647.85 ms /    40 tokens\n",
      " 73%|███████▎  | 365/500 [14:08<04:49,  2.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    25 runs   (    0.52 ms per token,  1926.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.62 ms /    19 tokens (   18.72 ms per token,    53.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2484.56 ms /    24 runs   (  103.52 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2865.56 ms /    43 tokens\n",
      " 73%|███████▎  | 366/500 [14:11<05:16,  2.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.16 ms /    29 runs   (    0.52 ms per token,  1912.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.37 ms /    13 tokens (   19.49 ms per token,    51.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2748.13 ms /    28 runs   (   98.15 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    3031.69 ms /    41 tokens\n",
      " 73%|███████▎  | 367/500 [14:14<05:41,  2.57s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1921.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     368.80 ms /    20 tokens (   18.44 ms per token,    54.23 tokens per second)\n",
      "llama_print_timings:        eval time =     105.89 ms /     1 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =     476.38 ms /    21 tokens\n",
      " 74%|███████▎  | 368/500 [14:15<04:15,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    17 runs   (    0.50 ms per token,  2004.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.51 ms /    19 tokens (   18.71 ms per token,    53.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1633.94 ms /    16 runs   (  102.12 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    2005.88 ms /    35 tokens\n",
      " 74%|███████▍  | 369/500 [14:17<04:16,  1.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    16 runs   (    0.50 ms per token,  1984.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     366.32 ms /    20 tokens (   18.32 ms per token,    54.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1539.34 ms /    15 runs   (  102.62 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    1921.98 ms /    35 tokens\n",
      " 74%|███████▍  | 370/500 [14:18<04:13,  1.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1932.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.64 ms /    14 tokens (   18.90 ms per token,    52.90 tokens per second)\n",
      "llama_print_timings:        eval time =     498.56 ms /     5 runs   (   99.71 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =     768.47 ms /    19 tokens\n",
      " 74%|███████▍  | 371/500 [14:19<03:25,  1.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.33 ms /    26 runs   (    0.51 ms per token,  1950.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     368.69 ms /    20 tokens (   18.43 ms per token,    54.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2746.62 ms /    25 runs   (  109.86 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    3143.49 ms /    45 tokens\n",
      " 74%|███████▍  | 372/500 [14:22<04:23,  2.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.24 ms /    41 runs   (    0.52 ms per token,  1930.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.70 ms /    15 tokens (   19.31 ms per token,    51.78 tokens per second)\n",
      "llama_print_timings:        eval time =    4161.17 ms /    40 runs   (  104.03 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    4493.83 ms /    55 tokens\n",
      " 75%|███████▍  | 373/500 [14:27<05:54,  2.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    11 runs   (    0.52 ms per token,  1937.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.90 ms /    12 tokens (   19.24 ms per token,    51.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1066.52 ms /    10 runs   (  106.65 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =    1308.66 ms /    22 tokens\n",
      " 75%|███████▍  | 374/500 [14:28<04:55,  2.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.01 ms /    33 runs   (    0.52 ms per token,  1940.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.87 ms /    19 tokens (   18.73 ms per token,    53.39 tokens per second)\n",
      "llama_print_timings:        eval time =    3291.45 ms /    32 runs   (  102.86 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3683.07 ms /    51 tokens\n",
      " 75%|███████▌  | 375/500 [14:32<05:43,  2.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.33 ms /    22 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.64 ms /    11 tokens (   20.42 ms per token,    48.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2173.05 ms /    21 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2420.72 ms /    32 tokens\n",
      " 75%|███████▌  | 376/500 [14:34<05:28,  2.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    12 runs   (    0.52 ms per token,  1918.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.83 ms /    22 tokens (   18.22 ms per token,    54.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.87 ms /    11 runs   (  100.90 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1523.05 ms /    33 tokens\n",
      " 75%|███████▌  | 377/500 [14:36<04:44,  2.31s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.74 ms /    30 runs   (    0.52 ms per token,  1906.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.44 ms /    18 tokens (   18.52 ms per token,    53.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2996.12 ms /    29 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    3361.85 ms /    47 tokens\n",
      " 76%|███████▌  | 378/500 [14:39<05:20,  2.63s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     3 runs   (    0.52 ms per token,  1916.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.30 ms /    18 tokens (   18.52 ms per token,    54.01 tokens per second)\n",
      "llama_print_timings:        eval time =     211.33 ms /     2 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =     547.60 ms /    20 tokens\n",
      " 76%|███████▌  | 379/500 [14:40<04:02,  2.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    28 runs   (    0.52 ms per token,  1909.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.36 ms /    13 tokens (   19.57 ms per token,    51.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2686.50 ms /    27 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    2970.82 ms /    40 tokens\n",
      " 76%|███████▌  | 380/500 [14:43<04:35,  2.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    21 runs   (    0.50 ms per token,  1982.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.44 ms /    15 tokens (   19.16 ms per token,    52.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2059.29 ms /    20 runs   (  102.96 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    2368.70 ms /    35 tokens\n",
      " 76%|███████▌  | 381/500 [14:45<04:35,  2.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     4 runs   (    0.53 ms per token,  1878.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.85 ms /    14 tokens (   18.99 ms per token,    52.66 tokens per second)\n",
      "llama_print_timings:        eval time =     292.36 ms /     3 runs   (   97.45 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =     562.65 ms /    17 tokens\n",
      " 76%|███████▋  | 382/500 [14:46<03:31,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.49 ms /    20 runs   (    0.52 ms per token,  1906.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.82 ms /    16 tokens (   18.74 ms per token,    53.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1905.33 ms /    19 runs   (  100.28 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2226.88 ms /    35 tokens\n",
      " 77%|███████▋  | 383/500 [14:48<03:45,  1.92s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    13 runs   (    0.51 ms per token,  1948.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.34 ms /    12 tokens (   19.20 ms per token,    52.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.64 ms /    12 runs   (  103.30 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    1483.39 ms /    24 tokens\n",
      " 77%|███████▋  | 384/500 [14:49<03:27,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    14 runs   (    0.50 ms per token,  1981.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.12 ms /    10 tokens (   19.71 ms per token,    50.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1383.51 ms /    13 runs   (  106.42 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    1594.24 ms /    23 tokens\n",
      " 77%|███████▋  | 385/500 [14:51<03:19,  1.73s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     6 runs   (    0.50 ms per token,  1999.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.99 ms /    10 tokens (   20.20 ms per token,    49.51 tokens per second)\n",
      "llama_print_timings:        eval time =     498.35 ms /     5 runs   (   99.67 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =     706.39 ms /    15 tokens\n",
      " 77%|███████▋  | 386/500 [14:52<02:42,  1.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1944.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.28 ms /    18 tokens (   18.46 ms per token,    54.17 tokens per second)\n",
      "llama_print_timings:        eval time =     285.86 ms /     3 runs   (   95.29 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     622.19 ms /    21 tokens\n",
      " 77%|███████▋  | 387/500 [14:52<02:13,  1.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    12 runs   (    0.50 ms per token,  1993.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.01 ms /    11 tokens (   20.00 ms per token,    50.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.77 ms /    11 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    1336.33 ms /    22 tokens\n",
      " 78%|███████▊  | 388/500 [14:54<02:17,  1.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     4 runs   (    0.54 ms per token,  1866.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.70 ms /    17 tokens (   18.92 ms per token,    52.84 tokens per second)\n",
      "llama_print_timings:        eval time =     281.15 ms /     3 runs   (   93.72 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     606.56 ms /    20 tokens\n",
      " 78%|███████▊  | 389/500 [14:54<01:55,  1.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    16 runs   (    0.50 ms per token,  1993.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.10 ms /    16 tokens (   18.76 ms per token,    53.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1527.01 ms /    15 runs   (  101.80 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1843.40 ms /    31 tokens\n",
      " 78%|███████▊  | 390/500 [14:56<02:21,  1.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.52 ms per token,  1940.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.56 ms /    21 tokens (   18.55 ms per token,    53.91 tokens per second)\n",
      "llama_print_timings:        eval time =     287.31 ms /     3 runs   (   95.77 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     680.70 ms /    24 tokens\n",
      " 78%|███████▊  | 391/500 [14:57<02:00,  1.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     5 runs   (    0.53 ms per token,  1881.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     357.05 ms /    19 tokens (   18.79 ms per token,    53.21 tokens per second)\n",
      "llama_print_timings:        eval time =     428.42 ms /     4 runs   (  107.10 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =     790.87 ms /    23 tokens\n",
      " 78%|███████▊  | 392/500 [14:58<01:49,  1.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /     9 runs   (    0.50 ms per token,  1981.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     241.50 ms /    12 tokens (   20.13 ms per token,    49.69 tokens per second)\n",
      "llama_print_timings:        eval time =     876.48 ms /     8 runs   (  109.56 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1127.19 ms /    20 tokens\n",
      " 79%|███████▊  | 393/500 [14:59<01:51,  1.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.27 ms /    29 runs   (    0.53 ms per token,  1899.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.82 ms /    13 tokens (   19.91 ms per token,    50.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2904.20 ms /    28 runs   (  103.72 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =    3193.25 ms /    41 tokens\n",
      " 79%|███████▉  | 394/500 [15:02<02:59,  1.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      22.18 ms /    44 runs   (    0.50 ms per token,  1983.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     495.00 ms /    27 tokens (   18.33 ms per token,    54.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4318.43 ms /    43 runs   (  100.43 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =    4858.44 ms /    70 tokens\n",
      " 79%|███████▉  | 395/500 [15:07<04:37,  2.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.60 ms /    27 runs   (    0.54 ms per token,  1849.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.70 ms /    20 tokens (   18.39 ms per token,    54.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2711.95 ms /    26 runs   (  104.31 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3108.74 ms /    46 tokens\n",
      " 79%|███████▉  | 396/500 [15:10<04:49,  2.78s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     3 runs   (    0.52 ms per token,  1907.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.02 ms /    15 tokens (   19.47 ms per token,    51.37 tokens per second)\n",
      "llama_print_timings:        eval time =     194.30 ms /     2 runs   (   97.15 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =     489.17 ms /    17 tokens\n",
      " 79%|███████▉  | 397/500 [15:10<03:35,  2.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    25 runs   (    0.52 ms per token,  1940.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     399.94 ms /    22 tokens (   18.18 ms per token,    55.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2339.76 ms /    24 runs   (   97.49 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    2765.65 ms /    46 tokens\n",
      " 80%|███████▉  | 398/500 [15:13<03:54,  2.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.79 ms /    33 runs   (    0.51 ms per token,  1965.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     434.99 ms /    24 tokens (   18.12 ms per token,    55.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3169.34 ms /    32 runs   (   99.04 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =    3639.17 ms /    56 tokens\n",
      " 80%|███████▉  | 399/500 [15:17<04:32,  2.70s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.75 ms /    23 runs   (    0.51 ms per token,  1956.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.44 ms /    21 tokens (   18.59 ms per token,    53.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2216.38 ms /    22 runs   (  100.74 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    2630.60 ms /    43 tokens\n",
      " 80%|████████  | 400/500 [15:19<04:28,  2.68s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    33 runs   (    0.52 ms per token,  1930.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     357.73 ms /    19 tokens (   18.83 ms per token,    53.11 tokens per second)\n",
      "llama_print_timings:        eval time =    3362.11 ms /    32 runs   (  105.07 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    3754.77 ms /    51 tokens\n",
      " 80%|████████  | 401/500 [15:23<04:57,  3.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.39 ms /    29 runs   (    0.53 ms per token,  1883.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.25 ms /    15 tokens (   19.22 ms per token,    52.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2849.49 ms /    28 runs   (  101.77 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =    3169.20 ms /    43 tokens\n",
      " 80%|████████  | 402/500 [15:26<04:59,  3.05s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.56 ms /    23 runs   (    0.50 ms per token,  1990.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     323.31 ms /    17 tokens (   19.02 ms per token,    52.58 tokens per second)\n",
      "llama_print_timings:        eval time =    2300.33 ms /    22 runs   (  104.56 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2647.61 ms /    39 tokens\n",
      " 81%|████████  | 403/500 [15:29<04:44,  2.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    18 runs   (    0.51 ms per token,  1972.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.90 ms /    20 tokens (   18.39 ms per token,    54.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1745.22 ms /    17 runs   (  102.66 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    2132.21 ms /    37 tokens\n",
      " 81%|████████  | 404/500 [15:31<04:18,  2.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.69 ms /    21 runs   (    0.51 ms per token,  1964.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.15 ms /    18 tokens (   18.45 ms per token,    54.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2017.25 ms /    20 runs   (  100.86 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    2371.57 ms /    38 tokens\n",
      " 81%|████████  | 405/500 [15:33<04:06,  2.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    25 runs   (    0.51 ms per token,  1955.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     358.77 ms /    19 tokens (   18.88 ms per token,    52.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2511.26 ms /    24 runs   (  104.64 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    2895.05 ms /    43 tokens\n",
      " 81%|████████  | 406/500 [15:36<04:12,  2.69s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      35.58 ms /    68 runs   (    0.52 ms per token,  1911.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     428.91 ms /    23 tokens (   18.65 ms per token,    53.62 tokens per second)\n",
      "llama_print_timings:        eval time =    6913.06 ms /    67 runs   (  103.18 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    7417.33 ms /    90 tokens\n",
      " 81%|████████▏ | 407/500 [15:44<06:21,  4.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1914.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.04 ms /    18 tokens (   18.56 ms per token,    53.89 tokens per second)\n",
      "llama_print_timings:        eval time =     387.35 ms /     4 runs   (   96.84 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     726.45 ms /    22 tokens\n",
      " 82%|████████▏ | 408/500 [15:45<04:44,  3.09s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.93 ms /    38 runs   (    0.52 ms per token,  1906.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.68 ms /    18 tokens (   18.54 ms per token,    53.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3811.19 ms /    37 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    4185.68 ms /    55 tokens\n",
      " 82%|████████▏ | 409/500 [15:49<05:11,  3.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.02 ms /    27 runs   (    0.52 ms per token,  1925.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.02 ms /    16 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2600.42 ms /    26 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    2928.07 ms /    42 tokens\n",
      " 82%|████████▏ | 410/500 [15:52<04:54,  3.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.98 ms /    25 runs   (    0.52 ms per token,  1925.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.04 ms /    21 tokens (   18.57 ms per token,    53.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2526.57 ms /    24 runs   (  105.27 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    2942.33 ms /    45 tokens\n",
      " 82%|████████▏ | 411/500 [15:55<04:42,  3.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    21 runs   (    0.52 ms per token,  1939.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.60 ms /    14 tokens (   18.97 ms per token,    52.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2093.97 ms /    20 runs   (  104.70 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =    2381.01 ms /    34 tokens\n",
      " 82%|████████▏ | 412/500 [15:57<04:18,  2.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    22 runs   (    0.51 ms per token,  1944.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     326.21 ms /    17 tokens (   19.19 ms per token,    52.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2174.23 ms /    21 runs   (  103.53 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    2523.58 ms /    38 tokens\n",
      " 83%|████████▎ | 413/500 [16:00<04:04,  2.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    14 runs   (    0.51 ms per token,  1978.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.33 ms /    14 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1324.16 ms /    13 runs   (  101.86 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1603.25 ms /    27 tokens\n",
      " 83%|████████▎ | 414/500 [16:01<03:30,  2.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.59 ms /    48 runs   (    0.53 ms per token,  1875.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.40 ms /    10 tokens (   20.44 ms per token,    48.92 tokens per second)\n",
      "llama_print_timings:        eval time =    4886.67 ms /    47 runs   (  103.97 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    5145.28 ms /    57 tokens\n",
      " 83%|████████▎ | 415/500 [16:06<04:37,  3.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.44 ms /    32 runs   (    0.51 ms per token,  1946.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     346.12 ms /    16 tokens (   21.63 ms per token,    46.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3234.24 ms /    31 runs   (  104.33 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =    3613.33 ms /    47 tokens\n",
      " 83%|████████▎ | 416/500 [16:10<04:42,  3.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.88 ms /    52 runs   (    0.50 ms per token,  2009.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.76 ms /    18 tokens (   18.54 ms per token,    53.93 tokens per second)\n",
      "llama_print_timings:        eval time =    5089.55 ms /    51 runs   (   99.80 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =    5478.36 ms /    69 tokens\n",
      " 83%|████████▎ | 417/500 [16:15<05:32,  4.00s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     3 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     425.22 ms /    23 tokens (   18.49 ms per token,    54.09 tokens per second)\n",
      "llama_print_timings:        eval time =     200.55 ms /     2 runs   (  100.28 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     628.86 ms /    25 tokens\n",
      " 84%|████████▎ | 418/500 [16:16<04:05,  2.99s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    25 runs   (    0.50 ms per token,  1992.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.37 ms /    18 tokens (   18.46 ms per token,    54.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2469.57 ms /    24 runs   (  102.90 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    2827.22 ms /    42 tokens\n",
      " 84%|████████▍ | 419/500 [16:19<03:58,  2.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1960.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.27 ms /    16 tokens (   18.70 ms per token,    53.46 tokens per second)\n",
      "llama_print_timings:        eval time =     386.09 ms /     4 runs   (   96.52 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     690.01 ms /    20 tokens\n",
      " 84%|████████▍ | 420/500 [16:20<03:01,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.59 ms /    24 runs   (    0.52 ms per token,  1906.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.50 ms /    18 tokens (   18.58 ms per token,    53.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2353.50 ms /    23 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    2713.85 ms /    41 tokens\n",
      " 84%|████████▍ | 421/500 [16:22<03:09,  2.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.81 ms /    34 runs   (    0.52 ms per token,  1909.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     409.52 ms /    22 tokens (   18.61 ms per token,    53.72 tokens per second)\n",
      "llama_print_timings:        eval time =    3309.67 ms /    33 runs   (  100.29 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    3755.04 ms /    55 tokens\n",
      " 84%|████████▍ | 422/500 [16:26<03:39,  2.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      21.31 ms /    40 runs   (    0.53 ms per token,  1877.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.42 ms /    14 tokens (   18.89 ms per token,    52.95 tokens per second)\n",
      "llama_print_timings:        eval time =    3930.13 ms /    39 runs   (  100.77 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    4238.49 ms /    53 tokens\n",
      " 85%|████████▍ | 423/500 [16:30<04:09,  3.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /     5 runs   (    0.54 ms per token,  1863.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     334.46 ms /    18 tokens (   18.58 ms per token,    53.82 tokens per second)\n",
      "llama_print_timings:        eval time =     388.47 ms /     4 runs   (   97.12 ms per token,    10.30 tokens per second)\n",
      "llama_print_timings:       total time =     728.76 ms /    22 tokens\n",
      " 85%|████████▍ | 424/500 [16:31<03:08,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      25.16 ms /    48 runs   (    0.52 ms per token,  1907.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.65 ms /    14 tokens (   19.48 ms per token,    51.35 tokens per second)\n",
      "llama_print_timings:        eval time =    4730.95 ms /    47 runs   (  100.66 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =    5055.91 ms /    61 tokens\n",
      " 85%|████████▌ | 425/500 [16:36<04:04,  3.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     3 runs   (    0.53 ms per token,  1892.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.30 ms /    11 tokens (   20.12 ms per token,    49.71 tokens per second)\n",
      "llama_print_timings:        eval time =     192.48 ms /     2 runs   (   96.24 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =     416.46 ms /    13 tokens\n",
      " 85%|████████▌ | 426/500 [16:36<02:58,  2.41s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    10 runs   (    0.51 ms per token,  1955.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.26 ms /    11 tokens (   20.02 ms per token,    49.94 tokens per second)\n",
      "llama_print_timings:        eval time =     936.92 ms /     9 runs   (  104.10 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    1167.49 ms /    20 tokens\n",
      " 85%|████████▌ | 427/500 [16:38<02:28,  2.04s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.26 ms /    29 runs   (    0.53 ms per token,  1900.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.55 ms /    13 tokens (   19.50 ms per token,    51.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2737.86 ms /    28 runs   (   97.78 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    3023.01 ms /    41 tokens\n",
      " 86%|████████▌ | 428/500 [16:41<02:47,  2.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1962.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.54 ms /    14 tokens (   18.97 ms per token,    52.72 tokens per second)\n",
      "llama_print_timings:        eval time =     402.58 ms /     4 runs   (  100.65 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =     672.38 ms /    18 tokens\n",
      " 86%|████████▌ | 429/500 [16:41<02:10,  1.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     3 runs   (    0.51 ms per token,  1954.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.10 ms /    14 tokens (   19.01 ms per token,    52.61 tokens per second)\n",
      "llama_print_timings:        eval time =     182.23 ms /     2 runs   (   91.11 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =     450.44 ms /    16 tokens\n",
      " 86%|████████▌ | 430/500 [16:42<01:39,  1.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     6 runs   (    0.52 ms per token,  1941.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.34 ms /    14 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_print_timings:        eval time =     498.43 ms /     5 runs   (   99.69 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =     769.37 ms /    19 tokens\n",
      " 86%|████████▌ | 431/500 [16:43<01:24,  1.23s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    17 runs   (    0.51 ms per token,  1954.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.05 ms /    14 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1746.35 ms /    16 runs   (  109.15 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    2030.08 ms /    30 tokens\n",
      " 86%|████████▋ | 432/500 [16:45<01:39,  1.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     3 runs   (    0.51 ms per token,  1964.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.15 ms /    17 tokens (   18.95 ms per token,    52.77 tokens per second)\n",
      "llama_print_timings:        eval time =     202.50 ms /     2 runs   (  101.25 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =     526.91 ms /    19 tokens\n",
      " 87%|████████▋ | 433/500 [16:45<01:19,  1.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    14 runs   (    0.52 ms per token,  1937.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.72 ms /    18 tokens (   18.43 ms per token,    54.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.84 ms /    13 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1714.54 ms /    31 tokens\n",
      " 87%|████████▋ | 434/500 [16:47<01:28,  1.35s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     7 runs   (    0.52 ms per token,  1918.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.93 ms /    14 tokens (   18.85 ms per token,    53.04 tokens per second)\n",
      "llama_print_timings:        eval time =     584.36 ms /     6 runs   (   97.39 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =     855.41 ms /    20 tokens\n",
      " 87%|████████▋ | 435/500 [16:48<01:17,  1.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      34.07 ms /    65 runs   (    0.52 ms per token,  1907.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.94 ms /    14 tokens (   18.92 ms per token,    52.84 tokens per second)\n",
      "llama_print_timings:        eval time =    6669.57 ms /    64 runs   (  104.21 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    7005.83 ms /    78 tokens\n",
      " 87%|████████▋ | 436/500 [16:55<03:08,  2.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      19.72 ms /    38 runs   (    0.52 ms per token,  1927.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.45 ms /    15 tokens (   19.30 ms per token,    51.82 tokens per second)\n",
      "llama_print_timings:        eval time =    3733.96 ms /    37 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    4064.08 ms /    52 tokens\n",
      " 87%|████████▋ | 437/500 [16:59<03:26,  3.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     7 runs   (    0.52 ms per token,  1922.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.78 ms /    12 tokens (   19.32 ms per token,    51.77 tokens per second)\n",
      "llama_print_timings:        eval time =     605.01 ms /     6 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =     844.46 ms /    18 tokens\n",
      " 88%|████████▊ | 438/500 [17:00<02:38,  2.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     6 runs   (    0.50 ms per token,  1988.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.19 ms /    14 tokens (   18.94 ms per token,    52.79 tokens per second)\n",
      "llama_print_timings:        eval time =     470.28 ms /     5 runs   (   94.06 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =     741.29 ms /    19 tokens\n",
      " 88%|████████▊ | 439/500 [17:00<02:02,  2.01s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     5 runs   (    0.52 ms per token,  1926.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.44 ms /    24 tokens (   18.14 ms per token,    55.12 tokens per second)\n",
      "llama_print_timings:        eval time =     391.12 ms /     4 runs   (   97.78 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =     831.08 ms /    28 tokens\n",
      " 88%|████████▊ | 440/500 [17:01<01:39,  1.66s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     6 runs   (    0.52 ms per token,  1914.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     404.92 ms /    22 tokens (   18.41 ms per token,    54.33 tokens per second)\n",
      "llama_print_timings:        eval time =     520.53 ms /     5 runs   (  104.11 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =     931.12 ms /    27 tokens\n",
      " 88%|████████▊ | 441/500 [17:02<01:24,  1.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     5 runs   (    0.52 ms per token,  1939.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     388.90 ms /    21 tokens (   18.52 ms per token,    54.00 tokens per second)\n",
      "llama_print_timings:        eval time =     383.03 ms /     4 runs   (   95.76 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     777.08 ms /    25 tokens\n",
      " 88%|████████▊ | 442/500 [17:03<01:11,  1.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    18 runs   (    0.52 ms per token,  1934.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     389.62 ms /    21 tokens (   18.55 ms per token,    53.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1727.17 ms /    17 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    2135.03 ms /    38 tokens\n",
      " 89%|████████▊ | 443/500 [17:05<01:26,  1.51s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.91 ms /    19 tokens (   18.78 ms per token,    53.24 tokens per second)\n",
      "llama_print_timings:        eval time =     283.06 ms /     3 runs   (   94.35 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =     643.72 ms /    22 tokens\n",
      " 89%|████████▉ | 444/500 [17:06<01:10,  1.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    12 runs   (    0.52 ms per token,  1926.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.01 ms /    21 tokens (   18.57 ms per token,    53.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.24 ms /    11 runs   (  101.11 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1514.16 ms /    32 tokens\n",
      " 89%|████████▉ | 445/500 [17:07<01:13,  1.33s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      31.50 ms /    63 runs   (    0.50 ms per token,  1999.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     424.40 ms /    23 tokens (   18.45 ms per token,    54.19 tokens per second)\n",
      "llama_print_timings:        eval time =    6587.45 ms /    62 runs   (  106.25 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =    7079.75 ms /    85 tokens\n",
      " 89%|████████▉ | 446/500 [17:14<02:45,  3.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    13 runs   (    0.51 ms per token,  1957.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.93 ms /    16 tokens (   18.68 ms per token,    53.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.17 ms /    12 runs   (   98.85 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    1498.56 ms /    28 tokens\n",
      " 89%|████████▉ | 447/500 [17:16<02:17,  2.59s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1912.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     470.89 ms /    26 tokens (   18.11 ms per token,    55.21 tokens per second)\n",
      "llama_print_timings:        eval time =     378.82 ms /     4 runs   (   94.70 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     854.18 ms /    30 tokens\n",
      " 90%|████████▉ | 448/500 [17:17<01:47,  2.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    18 runs   (    0.51 ms per token,  1962.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.30 ms /    19 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1682.30 ms /    17 runs   (   98.96 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =    2056.63 ms /    36 tokens\n",
      " 90%|████████▉ | 449/500 [17:19<01:45,  2.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.19 ms /    29 runs   (    0.52 ms per token,  1909.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     465.31 ms /    25 tokens (   18.61 ms per token,    53.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3014.43 ms /    28 runs   (  107.66 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =    3510.72 ms /    53 tokens\n",
      " 90%|█████████ | 450/500 [17:22<02:05,  2.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      16.49 ms /    32 runs   (    0.52 ms per token,  1940.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.59 ms /    22 tokens (   18.21 ms per token,    54.92 tokens per second)\n",
      "llama_print_timings:        eval time =    3232.10 ms /    31 runs   (  104.26 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3666.89 ms /    53 tokens\n",
      " 90%|█████████ | 451/500 [17:26<02:19,  2.85s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     3 runs   (    0.53 ms per token,  1891.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     598.76 ms /    33 tokens (   18.14 ms per token,    55.11 tokens per second)\n",
      "llama_print_timings:        eval time =     191.97 ms /     2 runs   (   95.99 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =     793.13 ms /    35 tokens\n",
      " 90%|█████████ | 452/500 [17:27<01:47,  2.24s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.12 ms /    29 runs   (    0.52 ms per token,  1918.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     400.74 ms /    22 tokens (   18.22 ms per token,    54.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2897.48 ms /    28 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    3329.93 ms /    50 tokens\n",
      " 91%|█████████ | 453/500 [17:30<02:00,  2.56s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    19 runs   (    0.52 ms per token,  1922.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     355.33 ms /    19 tokens (   18.70 ms per token,    53.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1856.80 ms /    18 runs   (  103.16 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    2231.30 ms /    37 tokens\n",
      " 91%|█████████ | 454/500 [17:32<01:53,  2.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      24.77 ms /    47 runs   (    0.53 ms per token,  1897.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.92 ms /    23 tokens (   18.43 ms per token,    54.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4784.79 ms /    46 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    5260.55 ms /    69 tokens\n",
      " 91%|█████████ | 455/500 [17:37<02:28,  3.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     5 runs   (    0.51 ms per token,  1956.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     356.45 ms /    19 tokens (   18.76 ms per token,    53.30 tokens per second)\n",
      "llama_print_timings:        eval time =     404.06 ms /     4 runs   (  101.02 ms per token,     9.90 tokens per second)\n",
      "llama_print_timings:       total time =     765.28 ms /    23 tokens\n",
      " 91%|█████████ | 456/500 [17:38<01:51,  2.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     4 runs   (    0.51 ms per token,  1942.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.79 ms /    18 tokens (   18.43 ms per token,    54.25 tokens per second)\n",
      "llama_print_timings:        eval time =     291.78 ms /     3 runs   (   97.26 ms per token,    10.28 tokens per second)\n",
      "llama_print_timings:       total time =     627.02 ms /    21 tokens\n",
      " 91%|█████████▏| 457/500 [17:39<01:24,  1.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      46.17 ms /    90 runs   (    0.51 ms per token,  1949.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.51 ms /    10 tokens (   19.75 ms per token,    50.63 tokens per second)\n",
      "llama_print_timings:        eval time =    9034.04 ms /    89 runs   (  101.51 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =    9330.66 ms /    99 tokens\n",
      " 92%|█████████▏| 458/500 [17:48<02:55,  4.18s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    29 runs   (    0.52 ms per token,  1919.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.06 ms /    14 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2881.78 ms /    28 runs   (  102.92 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    3177.64 ms /    42 tokens\n",
      " 92%|█████████▏| 459/500 [17:51<02:39,  3.88s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     5 runs   (    0.51 ms per token,  1958.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.04 ms /    14 tokens (   19.00 ms per token,    52.62 tokens per second)\n",
      "llama_print_timings:        eval time =     390.10 ms /     4 runs   (   97.53 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     660.31 ms /    18 tokens\n",
      " 92%|█████████▏| 460/500 [17:52<01:56,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.55 ms /    36 runs   (    0.52 ms per token,  1940.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.90 ms /    13 tokens (   19.53 ms per token,    51.20 tokens per second)\n",
      "llama_print_timings:        eval time =    3609.44 ms /    35 runs   (  103.13 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =    3901.39 ms /    48 tokens\n",
      " 92%|█████████▏| 461/500 [17:56<02:05,  3.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    20 runs   (    0.53 ms per token,  1903.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.73 ms /    17 tokens (   18.98 ms per token,    52.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1876.67 ms /    19 runs   (   98.77 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =    2220.90 ms /    36 tokens\n",
      " 92%|█████████▏| 462/500 [17:58<01:50,  2.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    19 runs   (    0.53 ms per token,  1881.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.88 ms /    21 tokens (   18.76 ms per token,    53.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1899.51 ms /    18 runs   (  105.53 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    2313.61 ms /    39 tokens\n",
      " 93%|█████████▎| 463/500 [18:01<01:41,  2.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    10 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.58 ms /    17 tokens (   18.92 ms per token,    52.86 tokens per second)\n",
      "llama_print_timings:        eval time =     914.38 ms /     9 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =    1246.53 ms /    26 tokens\n",
      " 93%|█████████▎| 464/500 [18:02<01:22,  2.29s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      18.12 ms /    35 runs   (    0.52 ms per token,  1931.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.02 ms /    16 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    3489.28 ms /    34 runs   (  102.63 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    3826.92 ms /    50 tokens\n",
      " 93%|█████████▎| 465/500 [18:06<01:36,  2.75s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     4 runs   (    0.52 ms per token,  1930.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.35 ms /    21 tokens (   18.59 ms per token,    53.80 tokens per second)\n",
      "llama_print_timings:        eval time =     278.39 ms /     3 runs   (   92.80 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =     672.07 ms /    24 tokens\n",
      " 93%|█████████▎| 466/500 [18:06<01:12,  2.13s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.57 ms /    27 runs   (    0.50 ms per token,  1989.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.49 ms /    16 tokens (   18.72 ms per token,    53.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2668.71 ms /    26 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    2996.51 ms /    42 tokens\n",
      " 93%|█████████▎| 467/500 [18:09<01:18,  2.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.27 ms /    24 runs   (    0.51 ms per token,  1956.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.68 ms /    15 tokens (   19.25 ms per token,    51.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2319.36 ms /    23 runs   (  100.84 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    2632.49 ms /    38 tokens\n",
      " 94%|█████████▎| 468/500 [18:12<01:18,  2.46s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    19 runs   (    0.51 ms per token,  1947.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.11 ms /    13 tokens (   19.85 ms per token,    50.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1852.58 ms /    18 runs   (  102.92 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    2129.59 ms /    31 tokens\n",
      " 94%|█████████▍| 469/500 [18:14<01:13,  2.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    20 runs   (    0.51 ms per token,  1965.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.97 ms /    16 tokens (   18.69 ms per token,    53.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1906.15 ms /    19 runs   (  100.32 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    2226.35 ms /    35 tokens\n",
      " 94%|█████████▍| 470/500 [18:16<01:09,  2.32s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     5 runs   (    0.53 ms per token,  1880.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.84 ms /    16 tokens (   18.74 ms per token,    53.36 tokens per second)\n",
      "llama_print_timings:        eval time =     411.03 ms /     4 runs   (  102.76 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =     715.80 ms /    20 tokens\n",
      " 94%|█████████▍| 471/500 [18:17<00:53,  1.84s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      15.45 ms /    29 runs   (    0.53 ms per token,  1876.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     401.36 ms /    22 tokens (   18.24 ms per token,    54.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2821.21 ms /    28 runs   (  100.76 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    3255.23 ms /    50 tokens\n",
      " 94%|█████████▍| 472/500 [18:20<01:03,  2.27s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.49 ms /    24 tokens (   18.15 ms per token,    55.11 tokens per second)\n",
      "llama_print_timings:        eval time =     287.65 ms /     3 runs   (   95.88 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     727.16 ms /    27 tokens\n",
      " 95%|█████████▍| 473/500 [18:21<00:48,  1.81s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /    32 runs   (    0.54 ms per token,  1863.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     435.78 ms /    24 tokens (   18.16 ms per token,    55.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3284.15 ms /    31 runs   (  105.94 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    3754.87 ms /    55 tokens\n",
      " 95%|█████████▍| 474/500 [18:25<01:02,  2.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1915.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     423.73 ms /    23 tokens (   18.42 ms per token,    54.28 tokens per second)\n",
      "llama_print_timings:        eval time =     435.07 ms /     4 runs   (  108.77 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =     863.57 ms /    27 tokens\n",
      " 95%|█████████▌| 475/500 [18:26<00:48,  1.93s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    23 runs   (    0.53 ms per token,  1900.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.99 ms /    11 tokens (   20.45 ms per token,    48.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2289.85 ms /    22 runs   (  104.08 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    2539.80 ms /    33 tokens\n",
      " 95%|█████████▌| 476/500 [18:28<00:50,  2.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      20.40 ms /    40 runs   (    0.51 ms per token,  1960.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.77 ms /    14 tokens (   18.98 ms per token,    52.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4078.53 ms /    39 runs   (  104.58 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =    4385.26 ms /    53 tokens\n",
      " 95%|█████████▌| 477/500 [18:33<01:04,  2.80s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    28 runs   (    0.52 ms per token,  1924.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.86 ms /    16 tokens (   18.68 ms per token,    53.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2772.10 ms /    27 runs   (  102.67 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =    3100.61 ms /    43 tokens\n",
      " 96%|█████████▌| 478/500 [18:36<01:03,  2.89s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      23.18 ms /    44 runs   (    0.53 ms per token,  1897.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.30 ms /     9 tokens (   20.81 ms per token,    48.05 tokens per second)\n",
      "llama_print_timings:        eval time =    4536.53 ms /    43 runs   (  105.50 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    4772.29 ms /    52 tokens\n",
      " 96%|█████████▌| 479/500 [18:40<01:12,  3.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    17 runs   (    0.52 ms per token,  1939.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.73 ms /    10 tokens (   19.87 ms per token,    50.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1614.05 ms /    16 runs   (  100.88 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1830.20 ms /    26 tokens\n",
      " 96%|█████████▌| 480/500 [18:42<00:59,  2.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     4 runs   (    0.51 ms per token,  1958.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.94 ms /    16 tokens (   18.75 ms per token,    53.34 tokens per second)\n",
      "llama_print_timings:        eval time =     317.96 ms /     3 runs   (  105.99 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =     621.59 ms /    19 tokens\n",
      " 96%|█████████▌| 481/500 [18:43<00:43,  2.26s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     5 runs   (    0.52 ms per token,  1918.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.14 ms /    15 tokens (   19.54 ms per token,    51.17 tokens per second)\n",
      "llama_print_timings:        eval time =     395.69 ms /     4 runs   (   98.92 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =     693.97 ms /    19 tokens\n",
      " 96%|█████████▋| 482/500 [18:44<00:32,  1.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    23 runs   (    0.52 ms per token,  1921.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.85 ms /    10 tokens (   19.68 ms per token,    50.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2190.37 ms /    22 runs   (   99.56 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    2412.06 ms /    32 tokens\n",
      " 97%|█████████▋| 483/500 [18:46<00:33,  1.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.47 ms /    24 runs   (    0.52 ms per token,  1924.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.12 ms /    15 tokens (   19.21 ms per token,    52.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2366.12 ms /    23 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    2678.86 ms /    38 tokens\n",
      " 97%|█████████▋| 484/500 [18:49<00:35,  2.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1882.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.14 ms /    20 tokens (   18.36 ms per token,    54.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1373.35 ms /    14 runs   (   98.10 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    1756.32 ms /    34 tokens\n",
      " 97%|█████████▋| 485/500 [18:50<00:30,  2.06s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    19 runs   (    0.53 ms per token,  1893.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.30 ms /    15 tokens (   19.29 ms per token,    51.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1865.18 ms /    18 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =    2175.54 ms /    33 tokens\n",
      " 97%|█████████▋| 486/500 [18:53<00:29,  2.10s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.45 ms /    26 runs   (    0.52 ms per token,  1933.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.15 ms /    15 tokens (   19.21 ms per token,    52.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2453.61 ms /    25 runs   (   98.14 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =    2770.31 ms /    40 tokens\n",
      " 97%|█████████▋| 487/500 [18:55<00:29,  2.30s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      14.14 ms /    28 runs   (    0.51 ms per token,  1979.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.98 ms /    10 tokens (   19.80 ms per token,    50.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2688.69 ms /    27 runs   (   99.58 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =    2916.14 ms /    37 tokens\n",
      " 98%|█████████▊| 488/500 [18:58<00:29,  2.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1936.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     302.60 ms /    16 tokens (   18.91 ms per token,    52.88 tokens per second)\n",
      "llama_print_timings:        eval time =     503.99 ms /     5 runs   (  100.80 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =     812.94 ms /    21 tokens\n",
      " 98%|█████████▊| 489/500 [18:59<00:21,  1.98s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    10 runs   (    0.52 ms per token,  1922.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     459.36 ms /    25 tokens (   18.37 ms per token,    54.42 tokens per second)\n",
      "llama_print_timings:        eval time =     969.84 ms /     9 runs   (  107.76 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =    1439.43 ms /    34 tokens\n",
      " 98%|█████████▊| 490/500 [19:01<00:18,  1.82s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.91 ms /    25 runs   (    0.52 ms per token,  1936.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.61 ms /    16 tokens (   18.73 ms per token,    53.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2446.49 ms /    24 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =    2772.90 ms /    40 tokens\n",
      " 98%|█████████▊| 491/500 [19:03<00:18,  2.11s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.16 ms /    23 runs   (    0.53 ms per token,  1891.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.15 ms /    14 tokens (   19.01 ms per token,    52.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2400.59 ms /    22 runs   (  109.12 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =    2691.26 ms /    36 tokens\n",
      " 98%|█████████▊| 492/500 [19:06<00:18,  2.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      12.63 ms /    25 runs   (    0.51 ms per token,  1979.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     300.04 ms /    16 tokens (   18.75 ms per token,    53.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2520.65 ms /    24 runs   (  105.03 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =    2846.71 ms /    40 tokens\n",
      " 99%|█████████▊| 493/500 [19:09<00:17,  2.45s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       9.99 ms /    20 runs   (    0.50 ms per token,  2002.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.40 ms /    18 tokens (   18.52 ms per token,    53.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1886.26 ms /    19 runs   (   99.28 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =    2239.21 ms /    37 tokens\n",
      " 99%|█████████▉| 494/500 [19:11<00:14,  2.39s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    13 runs   (    0.51 ms per token,  1942.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.14 ms /    14 tokens (   18.94 ms per token,    52.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.86 ms /    12 runs   (  100.90 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1490.29 ms /    26 tokens\n",
      " 99%|█████████▉| 495/500 [19:13<00:10,  2.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.46 ms /    26 runs   (    0.52 ms per token,  1932.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.80 ms /    14 tokens (   18.99 ms per token,    52.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2681.01 ms /    25 runs   (  107.24 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =    2974.93 ms /    39 tokens\n",
      " 99%|█████████▉| 496/500 [19:16<00:09,  2.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    21 runs   (    0.51 ms per token,  1950.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.62 ms /    14 tokens (   19.90 ms per token,    50.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2447.15 ms /    20 runs   (  122.36 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =    2747.83 ms /    34 tokens\n",
      " 99%|█████████▉| 497/500 [19:18<00:07,  2.49s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     4 runs   (    0.52 ms per token,  1907.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.08 ms /    20 tokens (   18.35 ms per token,    54.48 tokens per second)\n",
      "llama_print_timings:        eval time =     295.11 ms /     3 runs   (   98.37 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =     666.05 ms /    23 tokens\n",
      "100%|█████████▉| 498/500 [19:19<00:03,  1.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =      13.72 ms /    26 runs   (    0.53 ms per token,  1894.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    13 tokens (   19.54 ms per token,    51.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2555.63 ms /    25 runs   (  102.23 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    2838.28 ms /    38 tokens\n",
      "100%|█████████▉| 499/500 [19:22<00:02,  2.21s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    4946.73 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     5 runs   (    0.53 ms per token,  1898.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     390.19 ms /    21 tokens (   18.58 ms per token,    53.82 tokens per second)\n",
      "llama_print_timings:        eval time =     386.81 ms /     4 runs   (   96.70 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =     781.98 ms /    25 tokens\n",
      "100%|██████████| 500/500 [19:23<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time_squadv2 = time.time()\n",
    "\n",
    "questions_squadv2, predicted_squadv2, _ = get_relevant_ans(benchmarks_df['squadv2'], reader, cnt, False)\n",
    "targets_squadv2 = benchmarks_df['squadv2']['answer'].to_list()[:cnt]\n",
    "\n",
    "time_execute_squadv2 = time.time() - start_time_squadv2\n",
    "\n",
    "q_and_a_squadv2 = {\n",
    "    'question': questions_squadv2,\n",
    "    'predicted_answer': predicted_squadv2,\n",
    "    'target': targets_squadv2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>Beyoncé started gaining popularity in the late...</td>\n",
       "      <td>in the late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>As a child, Beyoncé competed in dance and musi...</td>\n",
       "      <td>singing and dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>Beyoncé left Destiny's Child in 2000 to pursue...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>Beyoncé grew up in Houston, Texas.</td>\n",
       "      <td>Houston, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>The 2000s!</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In what R&amp;B group was she the lead singer?</td>\n",
       "      <td>En Vogue!</td>\n",
       "      <td>Destiny's Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What album made her a worldwide known artist?</td>\n",
       "      <td>The album that made Lady Gaga a worldwide know...</td>\n",
       "      <td>Dangerously in Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who managed the Destiny's Child group?</td>\n",
       "      <td>Mathew Knowles.</td>\n",
       "      <td>Mathew Knowles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When did Beyoncé rise to fame?</td>\n",
       "      <td>Beyoncé rose to fame in the late 1990s as a me...</td>\n",
       "      <td>late 1990s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What role did Beyoncé have in Destiny's Child?</td>\n",
       "      <td>Beyoncé was the lead vocalist and one of the f...</td>\n",
       "      <td>lead singer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           When did Beyonce start becoming popular?   \n",
       "1  What areas did Beyonce compete in when she was...   \n",
       "2  When did Beyonce leave Destiny's Child and bec...   \n",
       "3      In what city and state did Beyonce  grow up?    \n",
       "4         In which decade did Beyonce become famous?   \n",
       "5         In what R&B group was she the lead singer?   \n",
       "6      What album made her a worldwide known artist?   \n",
       "7             Who managed the Destiny's Child group?   \n",
       "8                     When did Beyoncé rise to fame?   \n",
       "9     What role did Beyoncé have in Destiny's Child?   \n",
       "\n",
       "                                    predicted_answer               target  \n",
       "0  Beyoncé started gaining popularity in the late...    in the late 1990s  \n",
       "1  As a child, Beyoncé competed in dance and musi...  singing and dancing  \n",
       "2  Beyoncé left Destiny's Child in 2000 to pursue...                 2003  \n",
       "3                 Beyoncé grew up in Houston, Texas.       Houston, Texas  \n",
       "4                                         The 2000s!           late 1990s  \n",
       "5                                          En Vogue!      Destiny's Child  \n",
       "6  The album that made Lady Gaga a worldwide know...  Dangerously in Love  \n",
       "7                                    Mathew Knowles.       Mathew Knowles  \n",
       "8  Beyoncé rose to fame in the late 1990s as a me...           late 1990s  \n",
       "9  Beyoncé was the lead vocalist and one of the f...          lead singer  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squadv2 = pd.DataFrame(q_and_a_squadv2)\n",
    "df_squadv2.to_csv(SAVE_CSVFILE_2)\n",
    "df_squadv2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sberquad \n",
      "\n",
      "rouge:  0.2015\n",
      "bleu:  0.15456\n",
      "meteor:  0.54695\n",
      "exact_match:  0.02 \n",
      "\n",
      "Dataset squadv2 \n",
      "\n",
      "rouge:  0.17474\n",
      "bleu:  0.02093\n",
      "meteor:  0.1766\n",
      "exact_match:  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmarks_score = {}\n",
    "def metric(predicted: list[str], targets: list[str], name:str) -> None:\n",
    "    \n",
    "    length = len(predicted)\n",
    "\n",
    "    print('Dataset', name, '\\n')\n",
    "    rouge_score = metrics.rouge(predicted, targets[:length])\n",
    "    print(\"rouge: \", rouge_score)\n",
    "\n",
    "    bleu_score = metrics.bleu(predicted, targets[:length])\n",
    "    print(\"bleu: \", bleu_score)\n",
    "\n",
    "    meteor = metrics.meteor(predicted, targets[:length])\n",
    "    print(\"meteor: \", meteor)\n",
    "\n",
    "    exact_match = metrics.exact_match(predicted, targets[:length])\n",
    "    print(\"exact_match: \", exact_match, '\\n')\n",
    "\n",
    "    # посчитать метрики \n",
    "    score = {\n",
    "        'rouge': float(rouge_score),\n",
    "        'bleu': float(bleu_score),\n",
    "        'meteor': float(meteor),\n",
    "        'exact_match': float(exact_match)\n",
    "    }\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "score = metric(predicted_sberquad, targets_sberquad,'sberquad')\n",
    "benchmarks_score['sberquad'] = score\n",
    "\n",
    "score = metric(predicted_squadv2, targets_squadv2, 'squadv2')\n",
    "benchmarks_score['squadv2'] = score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# сохранить результат\n",
    "if os.path.exists(SAVE_LOGFILE):\n",
    "    print(\"Файл существует!\")\n",
    "    raise ValueError\n",
    "\n",
    "log_data = {'info': BENCHMARKS_INFO, 'time_execute_sberquad': float(time_execute_sberquad), 'time_execute_squadv2': float(time_execute_squadv2),\n",
    "            'hyperp': {\n",
    "                'model_path': MODEL_PATH, \n",
    "                'tech_params': config.tech_config.__dict__, 'hyper_params': config.strat_config.__dict__,'benchmark_sizes': BENCHES_SIZE},\n",
    "                'scores': benchmarks_score}\n",
    "\n",
    "with open(SAVE_LOGFILE, 'w', encoding='utf-8') as fd:\n",
    "    fd.write(json.dumps(log_data, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
