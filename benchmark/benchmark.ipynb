{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/aisummer/ssemenov_workspace/nlp-service\")\n",
    "\n",
    "import pandas as pd \n",
    "import ast\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "from src.DocumentsParser.utils import DBS_DIR_DENSE_VECTORDB_NAME, DBS_DIR_SPARSE_VECTORDB_NAME\n",
    "from src.evaluation_metrics import ReaderMetrics\n",
    "from src.DocumentsSummarizer.Summarizer import SummarizerModule\n",
    "from src.LLM_build.utils import llmConfig\n",
    "from src.utils import DialogueState\n",
    "from src.logger import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Создаём объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SummarizerModule()\n",
    "config = DialogueState()\n",
    "configLLM = llmConfig()\n",
    "\n",
    "options = {\n",
    "\"num_keep\": configLLM.num_keep,\n",
    "\"seed\": configLLM.seed,\n",
    "\"num_predict\": configLLM.num_predict,\n",
    "\"top_k\": configLLM.top_k,\n",
    "\"top_p\": configLLM.top_p,\n",
    "\"tfs_z\": configLLM.tfs_z,\n",
    "\"typical_p\": configLLM.typical_p,\n",
    "\"repeat_last_n\": configLLM.repeat_last_n,\n",
    "\"temperature\": configLLM.temperature,\n",
    "\"repeat_penalty\": configLLM.repeat_penalty,\n",
    "\"presence_penalty\": configLLM.presence_penalty,\n",
    "\"frequency_penalty\": configLLM.frequency_penalty,\n",
    "\"mirostat\": configLLM.mirostat,\n",
    "\"mirostat_tau\": configLLM.mirostat_tau,\n",
    "\"mirostat_eta\": configLLM.mirostat_eta,\n",
    "\"penalize_newline\": configLLM.penalize_newline,\n",
    "#\"stop\": config.stop,\n",
    "\"numa\": configLLM.numa,\n",
    "\"num_ctx\": configLLM.num_ctx,\n",
    "\"num_batch\": configLLM.num_batch,\n",
    "\"num_gpu\": configLLM.num_gpu,\n",
    "\"main_gpu\": configLLM.main_gpu,\n",
    "\"low_vram\": configLLM.low_vram,\n",
    "\"f16_kv\": configLLM.f16_kv,\n",
    "\"vocab_only\": configLLM.vocab_only,\n",
    "\"use_mmap\": configLLM.use_mmap,\n",
    "\"use_mlock\": configLLM.use_mlock,\n",
    "\"num_thread\": configLLM.num_thread\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Указываем инфо для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARKS_INFO = {'sberquad': 'v1', 'squadv2': 'v1'}\n",
    "SAVE_LOGFILE = './logs/trial1.json'\n",
    "\n",
    "banchmark_paths = {}\n",
    "for name, version in BENCHMARKS_INFO.items():\n",
    "    banchmark_paths[name] = {\n",
    "        'table': f\"../data/{name}/tables/{version}/benchmark.csv\",\n",
    "        'dense_db': f\"../data/{name}/dbs/{version}/{DBS_DIR_DENSE_VECTORDB_NAME}\",\n",
    "        'sparse_db':  f\"../data/{name}/dbs/{version}/{DBS_DIR_SPARSE_VECTORDB_NAME}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteor...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find a module script at /home/aisummer/ssemenov_workspace/nlp-service/src/metrics/meteor/meteor.py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# инициализировать класс с метриками\u001b[39;00m\n\u001b[1;32m      7\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/aisummer/ssemenov_workspace/nlp-service\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mReaderMetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# logging\u001b[39;00m\n\u001b[1;32m     11\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ssemenov_workspace/nlp-service/src/evaluation_metrics.py:61\u001b[0m, in \u001b[0;36mReaderMetrics.__init__\u001b[0;34m(self, base_dir)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbleu_obj \u001b[38;5;241m=\u001b[39m BLEUScore(n_gram\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Meteor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeteor_obj \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/src/metrics/meteor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading ExactMatch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem_obj \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/src/metrics/exact_match\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.nlp_env/lib/python3.12/site-packages/evaluate/loading.py:748\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m download_mode \u001b[38;5;241m=\u001b[39m DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode\u001b[38;5;241m.\u001b[39mREUSE_DATASET_IF_EXISTS)\n\u001b[0;32m--> 748\u001b[0m evaluation_module \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m evaluation_cls \u001b[38;5;241m=\u001b[39m import_main_class(evaluation_module\u001b[38;5;241m.\u001b[39mmodule_path)\n\u001b[1;32m    752\u001b[0m evaluation_instance \u001b[38;5;241m=\u001b[39m evaluation_cls(\n\u001b[1;32m    753\u001b[0m     config_name\u001b[38;5;241m=\u001b[39mconfig_name,\n\u001b[1;32m    754\u001b[0m     process_id\u001b[38;5;241m=\u001b[39mprocess_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minit_kwargs,\n\u001b[1;32m    761\u001b[0m )\n",
      "File \u001b[0;32m~/.nlp_env/lib/python3.12/site-packages/evaluate/loading.py:686\u001b[0m, in \u001b[0;36mevaluation_module_factory\u001b[0;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    682\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    683\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hugging Face Hub either.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a module script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find a module script at /home/aisummer/ssemenov_workspace/nlp-service/src/metrics/meteor/meteor.py."
     ]
    }
   ],
   "source": [
    "# загрузить benchmark-датасет\n",
    "benchmarks_df = {}\n",
    "for name, bench_path in banchmark_paths.items():\n",
    "    benchmarks_df[name] = pd.read_csv(banchmark_paths[name]['table'], sep=';')\n",
    "\n",
    "# инициализировать класс с метриками\n",
    "base_dir = '/home/aisummer/ssemenov_workspace/nlp-service'\n",
    "metrics = ReaderMetrics(base_dir)\n",
    "\n",
    "# logging\n",
    "logger = Logger(False)\n",
    "log = logger.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_ans(df, reader):\n",
    "    relevant_ans = []\n",
    "    for i in range(df.shape[0]):\n",
    "        reader.create_answer(config, configLLM, df['question'][i], df['contexts'][i])\n",
    "        relevant_ans.append(config.answer)\n",
    "        if i==5:\n",
    "            break\n",
    "    return relevant_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Органические останки в протерозойских отложениях представлены известковыми выделениями сине-зелёных водорослей, ходами червей и остатками кишечнополостными.\n",
      "известковыми выделениями сине-зелёных водорослей\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m rouge_score \u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mrouge(predicted, targets)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouge: \u001b[39m\u001b[38;5;124m\"\u001b[39m, rouge_score)\n\u001b[1;32m     12\u001b[0m bleu_score \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mbleu(predicted, targets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "benchmarks_score = []\n",
    "for i, name in enumerate(benchmarks_df.keys()):\n",
    "    predicted = get_relevant_ans(benchmarks_df[name], reader)\n",
    "    targets = benchmarks_df[name]['answer'].to_list()\n",
    "\n",
    "    print(predicted[0])\n",
    "    print(targets[0])\n",
    "\n",
    "    rouge_score = metrics.rouge(predicted, targets)\n",
    "    print(\"rouge: \", rouge_score)\n",
    "\n",
    "    bleu_score = metrics.bleu(predicted, targets)\n",
    "    print(\"bleu: \", bleu_score)\n",
    "\n",
    "    meteor = metrics.meteor(predicted, targets)\n",
    "    print(\"meteor: \", meteor)\n",
    "\n",
    "    exact_match = metrics.exact_match(predicted, targets)\n",
    "    print(\"exact_match: \", exact_match)\n",
    "\n",
    "    # посчитать метрики \n",
    "    score = {\n",
    "        'MRR': rouge_score,\n",
    "        'mAP': bleu_score,\n",
    "        'Recall': meteor,\n",
    "        'Precision': exact_match\n",
    "    }\n",
    "\n",
    "    benchmarks_score.append(score)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # сохранить результат\n",
    "if os.path.exists(SAVE_LOGFILE):\n",
    "    print(\"Файл существует!\")\n",
    "    raise ValueError\n",
    "\n",
    "log_data = {'info': BENCHMARKS_INFO, 'params': options.items}\n",
    "\n",
    "with open(SAVE_LOGFILE, 'w', encoding='utf-8') as fd:\n",
    "    fd.write(json.dumps(log_data, indent=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
