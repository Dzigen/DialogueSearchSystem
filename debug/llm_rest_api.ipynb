{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/dzigen/Desktop/nlp_service/\")\n",
    "from src.DocumentsSummarizer.utils import SummarizerConfig\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_question(config: SummarizerConfig) -> str:\n",
    "\n",
    "    url = 'http://localhost:11434/api/chat'\n",
    "    data = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Ты ассистент, который позволяет группировать слова по их смыслу и давать каждой группе её общее название. Все ответы ты генерируешь на русском языке и без грамматических ошибок. Давать ответ ты должен в следующем формате: \\\n",
    "                1. <общая тема 1>: <слово 1>, ..., <слово k>; \\\n",
    "                2. <общая тема 2>: <слово k+1>, ..., <слово k+m>; \\\n",
    "                ...\\\n",
    "                N. <общая тема N>: <слово k+m+1>, ..., <слово k+m+t>.\\\n",
    "                \\\n",
    "                Пример: \\\n",
    "                    Запрос: \\\n",
    "                    1. яблоко;\\\n",
    "                    2. помидор;\\\n",
    "                    3. апельсин;\\\n",
    "                    4. огурец.\\\n",
    "                    Ответ:\\\n",
    "                    1. фрукт: яблоко, апельсин;\\\n",
    "                    2. овощ: помидор, огурец.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": '''\n",
    "                1. колбаса;\n",
    "                2. туалетная бумага;\n",
    "                3. хлеб;\n",
    "                4. зубная щётка;\n",
    "                5. экскаватор;\n",
    "                6. Пушкин;\n",
    "                7. Черчилль;\n",
    "                8. Есенин;\n",
    "                9. Гитлер;\n",
    "                10. Гоголь;\n",
    "                11. Сталин.\n",
    "                '''\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": config.stream,\n",
    "        \"options\": {\n",
    "            \"num_keep\": config.num_keep,\n",
    "            \"seed\": config.seed,\n",
    "            \"num_predict\": config.num_predict,\n",
    "            \"top_k\": config.top_k,\n",
    "            \"top_p\": config.top_p,\n",
    "            \"tfs_z\": config.tfs_z,\n",
    "            \"typical_p\": config.typical_p,\n",
    "            \"repeat_last_n\": config.repeat_last_n,\n",
    "            \"temperature\": config.temperature,\n",
    "            \"repeat_penalty\": config.repeat_penalty,\n",
    "            \"presence_penalty\": config.presence_penalty,\n",
    "            \"frequency_penalty\": config.frequency_penalty,\n",
    "            \"mirostat\": config.mirostat,\n",
    "            \"mirostat_tau\": config.mirostat_tau,\n",
    "            \"mirostat_eta\": config.mirostat_eta,\n",
    "            \"penalize_newline\": config.penalize_newline,\n",
    "            #\"stop\": config.stop,\n",
    "            \"numa\": config.numa,\n",
    "            \"num_ctx\": config.num_ctx,\n",
    "            \"num_batch\": config.num_batch,\n",
    "            \"num_gpu\": config.num_gpu,\n",
    "            \"main_gpu\": config.main_gpu,\n",
    "            \"low_vram\": config.low_vram,\n",
    "            \"f16_kv\": config.f16_kv,\n",
    "            \"vocab_only\": config.vocab_only,\n",
    "            \"use_mmap\": config.use_mmap,\n",
    "            \"use_mlock\": config.use_mlock,\n",
    "            \"num_thread\": config.num_thread\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=data, stream=True)\n",
    "    result = ''\n",
    "    if response.status_code == 200:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                string_response = chunk.decode('utf-8')\n",
    "                json_data = json.loads(string_response)\n",
    "\n",
    "                # Извлечение значения content из JSON-данных\n",
    "                if 'message' in json_data and 'content' in json_data['message']:\n",
    "                    content = json_data['message']['content']\n",
    "                    result += json_data['message']['content']\n",
    "                    print(content, end='')\n",
    "                else:\n",
    "                    print(\"Content field not found in JSON response.\")\n",
    "        print('\\n')\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to get a successful response. Status code:\", response.status_code)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. историческая личность: Пушкин, Черчилль, Есенин, Гитлер;\n",
      "2. хлебобулочное изделие и бытовая вещь: колбаса, хлеб, зубная щётка;\n",
      "3. строительное оборудование: экскаватор;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = SummarizerConfig()\n",
    "result = llm_question(config)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
