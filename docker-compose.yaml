version: '1'
services:
  #
  nlp_service:
    image: nlp_service:v1
    build: .
    container_name: nlpservice_cntname
    hostname: nlpservice_api
    ports:
      - 8008:8008
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes: 
      - ./models:/nlp_service/models
    depends_on:
      - ollama_service
  
  ollama_service:
    image: ollama/ollama
    container_name: ollama
    ports:
      - 11434:11434
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes: 
      - /home/aisummer/mikhail_workspace/ollama:/root/.ollama


